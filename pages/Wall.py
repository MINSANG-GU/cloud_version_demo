#####################################################
##êµ¬ì¡°ë„ë©´ ë²½ì²´ ì‹œì‘

import os
import subprocess
import tempfile
import streamlit as st
from pdf2image import convert_from_bytes
from PIL import Image
from streamlit_drawable_canvas import st_canvas
import json
import cv2
import numpy as np
from scipy.signal import find_peaks
from scipy.stats import mode
from scipy.ndimage import gaussian_filter1d
import shutil
from tqdm import tqdm
from PIL import Image, ImageDraw
import cv2
import glob
import concurrent.futures
import time
import pandas as pd
from concurrent.futures import ProcessPoolExecutor  # ë³€ê²½ëœ ë¶€ë¶„
import matplotlib.pyplot as plt
from collections import defaultdict
from sklearn.cluster import DBSCAN
import pickle
import os
import random
import joblib
import torch
import numpy as np
from PIL import Image
from collections import Counter
from pdf2image import convert_from_bytes
from doclayout_yolo import YOLOv10
from huggingface_hub import hf_hub_download
import streamlit as st
import shutil
import json
import os
import subprocess
import json
import streamlit as st
from PIL import Image, ImageDraw, ImageFont
import glob
import re
from collections import defaultdict
import numpy as np
import matplotlib.pyplot as plt
from ultralytics import YOLO
from ultralytics.engine.results import Boxes
import cv2
from tqdm import tqdm
import os, glob, json, re, csv
import pandas as pd
import sys, os


sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from app_config import get_base_dir, get_ocr_results_folder

BASE_DIR = get_base_dir()
SURYA_RESULTS_FOLDER =get_ocr_results_folder()





Wall_rawdata_SD = os.path.join(BASE_DIR,"wall", "Wall_raw_data_SD")
Wall_line = os.path.join(BASE_DIR,"wall", "Wall_line")
Wall_column_label = os.path.join(BASE_DIR,"wall", "Wall_column_label")
Wall_table_region =os.path.join(BASE_DIR,"wall", "Wall_table_region")
Wall_OCR =os.path.join(BASE_DIR,"wall", "Wall_OCR")
Wall_cell =os.path.join(BASE_DIR,"wall", "Wall_cell")
Wall_cell_crop_ocr =os.path.join(BASE_DIR,"wall", "Wall_cell_crop_ocr")
STRUCTURED_EXCEL_DIR = os.path.join(BASE_DIR,"wall", "Wall_cell_structure")



os.makedirs(BASE_DIR,exist_ok= True)
os.makedirs(Wall_rawdata_SD, exist_ok=True)
os.makedirs(Wall_column_label, exist_ok=True)
os.makedirs(Wall_table_region, exist_ok=True)
os.makedirs(Wall_OCR, exist_ok=True)
os.makedirs(Wall_cell, exist_ok=True)
os.makedirs(Wall_cell_crop_ocr, exist_ok=True)
os.makedirs(STRUCTURED_EXCEL_DIR, exist_ok=True)




def convert_pdf_to_png(pdf_bytes: bytes) -> list[str]:
    """
    Convert PDF bytes to PNG images using pdf2image.convert_from_bytes.
    Saves each page as a PNG in OUTPUT_FOLDER and returns list of file paths.
    """
    os.makedirs(Wall_rawdata_SD, exist_ok=True)
    images = convert_from_bytes(pdf_bytes, dpi=300)
    paths = []
    for idx, img in enumerate(images, start=1):
        filename = f"page_{idx}.png"
        path = os.path.join(Wall_rawdata_SD, filename)
        img.save(path, "PNG")
        paths.append(path)
    return paths

def draw_and_save_bounding_boxes(canvas_key: str = "box_saver") -> None:
    """
    â€¢ RAW_DATA_FOLDERì—ì„œ ì´ë¯¸ì§€ë¥¼ ì„ íƒ
    â€¢ ì„ íƒëœ ì´ë¯¸ì§€ë¥¼ ì£¼ì–´ì§„ MAX í¬ê¸°ì— ë§ì¶° ì¶•ì†Œí•´ ìº”ë²„ìŠ¤ ë°°ê²½ìœ¼ë¡œ ë„ìš°ê³ 
    â€¢ ì‚¬ê°í˜•ì„ ê·¸ë ¤ ì›ë³¸ ì¢Œí‘œë¡œ ì—­ìŠ¤ì¼€ì¼í•˜ì—¬ BOX_COORD_FOLDERì— ì €ì¥
    """
    os.makedirs(Wall_column_label, exist_ok=True)
    imgs = [f for f in os.listdir(Wall_rawdata_SD) if f.lower().endswith((".png", ".jpg", ".jpeg"))]
    if not imgs:
        st.warning(f"ì´ë¯¸ì§€ ì—†ìŒ: {Wall_rawdata_SD}")
        return

    # ì´ë¯¸ì§€ ì„ íƒ
    selected = st.selectbox("ì´ë¯¸ì§€ ì„ íƒ", imgs, key=canvas_key + "_sel")
    img_path = os.path.join(Wall_rawdata_SD, selected)
    image = Image.open(img_path).convert("RGB")

    # í‘œì‹œìš© ì¶•ì†Œ ê³„ì‚°
    MAX_W, MAX_H = 800, 600
    scale = min(1.0, MAX_W / image.width, MAX_H / image.height)
    disp_w, disp_h = int(image.width * scale), int(image.height * scale)
    img_small = image.resize((disp_w, disp_h), Image.LANCZOS)

    # offset ê³„ì‚° (ìº”ë²„ìŠ¤ ì¤‘ì•™ ì •ë ¬ ì‹œ)
    offset_x = (MAX_W - disp_w) // 2
    offset_y = (MAX_H - disp_h) // 2

    # ìº”ë²„ìŠ¤ ìƒì„±
    canvas_res = st_canvas(
        background_image=img_small,
        drawing_mode="rect",
        stroke_width=2,
        stroke_color="#FF0000",
        fill_color="rgba(255,0,0,0.3)",
        update_streamlit=True,
        key=canvas_key,
        width=MAX_W,
        height=MAX_H
    )

    # ë°•ìŠ¤ ì €ì¥ (offset ë° scale ì—­ë³€í™˜ ì ìš©)
    if canvas_res and canvas_res.json_data and canvas_res.json_data.get("objects"):
        boxes = []
        for o in canvas_res.json_data["objects"]:
            if o.get("type") == "rect":
                boxes.append({
                    "left": round((o["left"] - offset_x) / scale, 2),
                    "top": round((o["top"] - offset_y) / scale, 2),
                    "width": round(o["width"] / scale, 2),
                    "height": round(o["height"] / scale, 2)
                })
        out_file = os.path.join(Wall_column_label, f"{os.path.splitext(selected)[0]}_boxes.json")
        with open(out_file, "w", encoding="utf-8") as f:
            json.dump(boxes, f, ensure_ascii=False, indent=2)
        st.success(f"âœ… {len(boxes)}ê°œ ì¢Œí‘œ ì €ì¥ë¨: {out_file}")



# def detect_lines_and_intersections():
#     """
#     RAW_DATA_FOLDERì—ì„œ ì´ë¯¸ì§€ ì„ íƒ í›„ ê°€ë¡œ/ì„¸ë¡œ ì„  ê²€ì¶œ, êµì°¨ì  ê³„ì‚° ë° ì‹œê°í™”
#     """
#     imgs = [f for f in os.listdir(Wall_rawdata_SD) if f.lower().endswith((".png", ".jpg", ".jpeg"))]
#     if not imgs:
#         st.warning(f"ì´ë¯¸ì§€ ì—†ìŒ: {Wall_rawdata_SD}")
#         return
#     selected = st.selectbox("ê²€ì¶œí•  ì´ë¯¸ì§€ ì„ íƒ", imgs, key="line_sel")
#     img_path = os.path.join(Wall_rawdata_SD, selected)
#     pil_img = Image.open(img_path).convert("RGB")
#     img_np = np.array(pil_img)
#     gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)
#     edges = cv2.Canny(gray, 50, 150, apertureSize=3)
#     lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100, minLineLength=50, maxLineGap=10)
#     horiz, vert = [], []
#     if lines is not None:
#         for l in lines:
#             x1, y1, x2, y2 = l[0]
#             if abs(y1 - y2) < abs(x1 - x2) * 0.1:
#                 horiz.append((x1, y1, x2, y2))
#             if abs(x1 - x2) < abs(y1 - y2) * 0.1:
#                 vert.append((x1, y1, x2, y2))
#     intersections = []
#     for x1, y1, x2, y2 in horiz:
#         for x3, y3, x4, y4 in vert:
#             # êµì°¨ì  (x3, y1)
#             intersections.append((x3, y1))
#     overlay = img_np.copy()
#     for x1, y1, x2, y2 in horiz:
#         cv2.line(overlay, (x1, y1), (x2, y2), (0, 255, 0), 2)
#     for x1, y1, x2, y2 in vert:
#         cv2.line(overlay, (x1, y1), (x2, y2), (255, 0, 0), 2)
#     for x, y in intersections:
#         cv2.circle(overlay, (x, y), 5, (0, 0, 255), -1)
#     st.image(overlay, caption=f"Lines & Intersections ({selected})", use_column_width=True)
#     st.write("êµì°¨ì  ì¢Œí‘œ:", intersections)






def apply_surya_ocr_Wall_SD():
    surya_output_folder = Wall_OCR

    os.makedirs(surya_output_folder, exist_ok=True)

    # âœ… ê¸°ì¡´ OCR ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìƒëµ
    existing_jsons = [f for f in os.listdir(surya_output_folder) if f.endswith(".json")]
    if existing_jsons:
        st.info(f"â„¹ï¸ ì´ë¯¸ {len(existing_jsons)}ê°œì˜ OCR ê²°ê³¼ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. Surya OCR ìƒëµ.")
        return

    # âœ… ì…ë ¥ ì´ë¯¸ì§€ í™•ì¸
    image_files = [f for f in os.listdir(Wall_rawdata_SD) if f.lower().endswith(('.jpg', '.png'))]
    if not image_files:
        st.error("âŒ plain text ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    st.write("ğŸ”OCR ì‹¤í–‰ ì¤‘...")
    progress_bar = st.progress(0)
    status_text = st.empty()


    for idx, image_file in enumerate(image_files):
        input_path = os.path.join(Wall_rawdata_SD, image_file)
        command = ["surya_ocr", input_path]
        result = subprocess.run(command, capture_output=True, text=True)

        stderr = result.stderr.strip()
        if stderr and all(x not in stderr for x in ["Detecting bboxes", "Recognizing Text"]):
            st.warning(f"âš ï¸ ì˜¤ë¥˜: {image_file} â†’ {stderr}")

        progress = int((idx + 1) / len(image_files) * 100)
        progress_bar.progress(progress)
        status_text.write(f"ğŸ–¼ï¸ OCR ì‹¤í–‰ ì¤‘: {image_file} ({progress}%)")

    progress_bar.empty()
    status_text.write("âœ… OCR ì™„ë£Œ. ê²°ê³¼ ì´ë™ ì¤‘...")

    # âœ… ê²°ê³¼ ì´ë™
    moved, skipped = 0, 0
    for folder_name in os.listdir(SURYA_RESULTS_FOLDER):
        folder_path = os.path.join(SURYA_RESULTS_FOLDER, folder_name)
        if os.path.isdir(folder_path):
            json_file = os.path.join(folder_path, "results.json")
            if os.path.exists(json_file):
                dst_file = os.path.join(surya_output_folder, f"{folder_name}.json")
                try:
                    shutil.move(json_file, dst_file)
                    moved += 1
                except Exception as e:
                    st.error(f"âŒ Move Error: {folder_name} â†’ {e}")
            else:
                skipped += 1

    st.success(f"ğŸ“ OCR ê²°ê³¼ {moved}ê°œ ì´ë™ ì™„ë£Œ ({skipped}ê°œëŠ” ëˆ„ë½ë¨)")








def process_all_and_show_one(tol=100):
    img_dir = Wall_rawdata_SD
    ocr_dir = Wall_OCR
    boxes_dir = Wall_column_label
    result_dir = Wall_table_region

    os.makedirs(result_dir, exist_ok=True)
    example_img = None
    example_path = None

    img_files = sorted([f for f in os.listdir(img_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])

    for img_filename in img_files:
        img_path = os.path.join(img_dir, img_filename)
        ocr_path = os.path.join(ocr_dir, f"{os.path.splitext(img_filename)[0]}.json")
        boxes_path = os.path.join(boxes_dir, f"{os.path.splitext(img_filename)[0]}_boxes.json")
        save_path = os.path.join(result_dir, f"highlighted_{img_filename}")

        if not (os.path.exists(img_path) and os.path.exists(ocr_path) and os.path.exists(boxes_path)):
            continue

        img = cv2.imread(img_path)
        with open(boxes_path, 'r', encoding='utf-8') as f:
            boxes = json.load(f)
        with open(ocr_path, 'r', encoding='utf-8') as f:
            ocr_data = json.load(f)

        ref_xs = [box['left'] + box['width']/2 for box in boxes]

        # ---- OCR êµ¬ì¡° ìë™ ê°ì§€ ----
        # case1: {'blocks': [...]}
        if isinstance(ocr_data, dict) and 'blocks' in ocr_data:
            blocks = ocr_data['blocks']
        # case2: {'page_1': [...]}
        elif isinstance(ocr_data, dict) and 'page_1' in ocr_data:
            blocks = ocr_data['page_1']
        # case3: ë°”ë¡œ ë¦¬ìŠ¤íŠ¸
        elif isinstance(ocr_data, list):
            blocks = ocr_data
        else:
            continue

        # text_lines key ìë™ ê°ì§€
        for block in blocks:
            text_lines = block.get('text_lines') if isinstance(block, dict) and 'text_lines' in block else []
            for line in text_lines:
                bbox = line.get('bbox')
                if bbox and len(bbox) == 4:
                    x_min, y_min, x_max, y_max = bbox
                    center_x = (x_min + x_max) / 2
                    if any(abs(center_x - ref_x) <= tol for ref_x in ref_xs):
                        cv2.rectangle(img, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0,255,0), 2)
                        cv2.putText(img, line.get('text', ''), (int(x_min), int(y_min)-5),
                                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,0,255), 2)
        cv2.imwrite(save_path, img)

        if example_img is None:
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            example_img = img_rgb
            example_path = save_path

    return example_img, example_path








# def extract_table_cells_from_image(img_path, debug_dir=None):
#     img = cv2.imread(img_path)
#     if img is None:
#         st.error("ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨")
#         return []

#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
#     binary = cv2.adaptiveThreshold(~gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, -2)
#     h_struct = cv2.getStructuringElement(cv2.MORPH_RECT, (binary.shape[1]//30, 1))
#     v_struct = cv2.getStructuringElement(cv2.MORPH_RECT, (1, binary.shape[0]//30))
#     horizontal = cv2.dilate(cv2.erode(binary.copy(), h_struct), h_struct)
#     vertical = cv2.dilate(cv2.erode(binary.copy(), v_struct), v_struct)
#     mask = cv2.bitwise_and(horizontal, vertical)
#     coords = cv2.findNonZero(mask)
#     if coords is None:
#         st.warning("êµì°¨ì  ì—†ìŒ")
#         return []

#     pts = [tuple(pt[0]) for pt in coords]
#     pts_set = set(pts)

#     # ëª¨ë“  êµì°¨ì  ì¡°í•©ìœ¼ë¡œ ì…€ í›„ë³´ ìƒì„±
#     raw_cells = []
#     progress = st.progress(0)
#     total = len(pts)
#     idx = 0
#     for x1, y1 in pts:
#         idx += 1
#         progress.progress(idx / total)
#         for x2, y2 in pts:
#             if x2 > x1 and y2 > y1 and (x1, y2) in pts_set and (x2, y1) in pts_set:
#                 raw_cells.append({"x1": x1, "y1": y1, "x2": x2, "y2": y2})
#     progress.empty()

#     # ì¤‘ì²©ëœ í° ì…€ ì œê±°, ê°€ì¥ ì‘ì€ ì…€ë§Œ ë‚¨ê¹€
#     cells = []
#     progress = st.progress(0)
#     total = len(raw_cells)
#     for i, cell in enumerate(raw_cells):
#         progress.progress(i / total)
#         contained = False
#         area_cell = (cell['x2'] - cell['x1']) * (cell['y2'] - cell['y1'])
#         for other in raw_cells:
#             if other is cell:
#                 continue
#             area_other = (other['x2'] - other['x1']) * (other['y2'] - other['y1'])
#             if (other['x1'] <= cell['x1'] <= other['x2'] and other['y1'] <= cell['y1'] <= other['y2']
#                 and other['x2'] >= cell['x2'] and other['y2'] >= cell['y2']
#                 and area_other < area_cell):
#                 contained = True
#                 break
#         if not contained:
#             cells.append(cell)
#     progress.empty()

#     # êµì°¨ì  ë° ì…€ ì‹œê°í™”
#     if debug_dir:
#         os.makedirs(debug_dir, exist_ok=True)
#         vis = img.copy()
#         for x, y in pts:
#             cv2.circle(vis, (x, y), 5, (0, 0, 255), -1)
#         for cell in cells:
#             cv2.rectangle(vis, (cell['x1'], cell['y1']), (cell['x2'], cell['y2']), (0, 255, 0), 2)
#         cv2.imwrite(os.path.join(debug_dir, f"debug_{os.path.basename(img_path)}.png"), vis)

#     return cells

# # í…ìŠ¤íŠ¸ í¬í•¨ ì…€ í¬ë¡­ í•¨ìˆ˜
# def run_find_vertical_texts_and_cells_batch(img_path):
#     base = os.path.splitext(os.path.basename(img_path))[0]
#     box_json_path = os.path.join(Wall_column_label, f"{base}_boxes.json")
#     ocr_json_path = os.path.join(Wall_OCR, f"{base}.json")
#     if not (os.path.exists(box_json_path) and os.path.exists(ocr_json_path)):
#         st.warning("box ë˜ëŠ” ocr jsonì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
#         return 0

#     with open(box_json_path, encoding='utf-8') as f:
#         boxes = json.load(f)
#     with open(ocr_json_path, encoding='utf-8') as f:
#         ocr = json.load(f)

#     text_lines = []
#     for page in ocr.values():
#         for line in page:
#             for t in line['text_lines']:
#                 text_lines.append({'bbox': t['bbox']})

#     cells = extract_table_cells_from_image(img_path)
#     image = cv2.imread(img_path)

#     count = 0
#     progress = st.progress(0)
#     total = len(boxes)
#     for idx, b in enumerate(boxes):
#         progress.progress((idx+1) / total)
#         x_c = b['left'] + b['width'] / 2
#         tlines = [t for t in text_lines if t['bbox'][0] <= x_c <= t['bbox'][2]]
#         if not tlines:
#             continue
#         t = tlines[0]
#         cx = (t['bbox'][0] + t['bbox'][2]) / 2
#         cy = (t['bbox'][1] + t['bbox'][3]) / 2

#         best = None
#         min_area = float('inf')
#         for cell in cells:
#             if cell['x1'] <= cx <= cell['x2'] and cell['y1'] <= cy <= cell['y2']:
#                 area = (cell['x2'] - cell['x1']) * (cell['y2'] - cell['y1'])
#                 if area < min_area:
#                     min_area = area
#                     best = cell
#         if best:
#             x1, y1, x2, y2 = best['x1'], best['y1'], best['x2'], best['y2']
#             crop = image[y1:y2, x1:x2]
#             cv2.imwrite(os.path.join(Wall_cell, f"{base}_cell_{idx}.png"), crop)
#             count += 1
#     progress.empty()
#     return count








def visualize_lines_batch():
    IMG_DIR = Wall_rawdata_SD  # ì²˜ë¦¬í•  ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
    DEBUG_DIR =Wall_cell    # ë””ë²„ê·¸ ê²°ê³¼ ì €ì¥ í´ë”
    BOXES_DIR =Wall_column_label   # boxes json í´ë” ê²½ë¡œ
    OCR_DIR = Wall_OCR        # OCR json í´ë” ê²½ë¡œ
    img_files = [f for f in os.listdir(IMG_DIR)
                 if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    if not img_files:
        st.warning("ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ IMG_DIRì— ì—†ìŠµë‹ˆë‹¤.")
        return

    for fname in img_files:
        base = os.path.splitext(fname)[0]
        img_path = os.path.join(IMG_DIR, fname)
        boxes_path = os.path.join(BOXES_DIR, f"{base}_boxes.json")
        ocr_path = os.path.join(OCR_DIR, f"{base}.json")

        img = cv2.imread(img_path)
        if img is None:
            st.error(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}")
            continue

        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë° ì´ì§„í™”
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        binary = cv2.adaptiveThreshold(~gray, 255,
                                       cv2.ADAPTIVE_THRESH_MEAN_C,
                                       cv2.THRESH_BINARY, 15, -2)

        # ìˆ˜í‰ ì„  ê²€ì¶œ
        horizontal = binary.copy()
        horizontalsize = max(1, horizontal.shape[1] // 30)
        hor_structure = cv2.getStructuringElement(cv2.MORPH_RECT, (horizontalsize, 1))
        horizontal = cv2.erode(horizontal, hor_structure)
        horizontal = cv2.dilate(horizontal, hor_structure)

        # ìˆ˜ì§ ì„  ê²€ì¶œ
        vertical = binary.copy()
        verticalsize = max(1, vertical.shape[0] // 30)
        ver_structure = cv2.getStructuringElement(cv2.MORPH_RECT, (1, verticalsize))
        vertical = cv2.erode(vertical, ver_structure)
        vertical = cv2.dilate(vertical, ver_structure)

        # êµì°¨ì  ê²€ì¶œ
        mask = cv2.bitwise_and(horizontal, vertical)
        pts = cv2.findNonZero(mask)

        # ì‹œê°í™”
        vis = img.copy()
        # ìˆ˜í‰ ì»¨íˆ¬ì–´ ê·¸ë¦¬ê¸°
        contours_h, _ = cv2.findContours(horizontal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for cnt in contours_h:
            x, y, w, h = cv2.boundingRect(cnt)
            cv2.line(vis, (x, y + h // 2), (x + w, y + h // 2), (0, 255, 0), 2)
        # ìˆ˜ì§ ì»¨íˆ¬ì–´ ê·¸ë¦¬ê¸°
        contours_v, _ = cv2.findContours(vertical, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for cnt in contours_v:
            x, y, w, h = cv2.boundingRect(cnt)
            cv2.line(vis, (x + w // 2, y), (x + w // 2, y + h), (255, 0, 0), 2)
        # êµì°¨ì  ì‹œê°í™”
        intersect_count = 0
        if pts is not None:
            for p in pts:
                x_i, y_i = p[0]
                cv2.circle(vis, (x_i, y_i), 5, (0, 0, 255), -1)
            intersect_count = len(pts)

                # íƒ€ê²Ÿ í…ìŠ¤íŠ¸ ì‹œê°í™”
        text_count = 0
        if os.path.exists(boxes_path) and os.path.exists(ocr_path):
            with open(boxes_path, encoding='utf-8') as f:
                boxes = json.load(f)
            with open(ocr_path, encoding='utf-8') as f:
                ocr = json.load(f)
            # ì „ì²´ í…ìŠ¤íŠ¸ ë¼ì¸ ì¶”ì¶œ
            text_lines = []
            for page in ocr.values():
                for line in page:
                    for t in line['text_lines']:
                        text_lines.append({'text': t['text'], 'bbox': t['bbox']})
            # boxes ê¸°ì¤€ xì¶•ìœ¼ë¡œ í•„í„°ë§
            for bx in boxes:
                x_center = bx['left'] + bx['width']/2
                # ì¼ì¹˜í•˜ëŠ” í…ìŠ¤íŠ¸ ì°¾ê¸°
                for tl in text_lines:
                    x1, y1, x2, y2 = tl['bbox']
                    if x1 <= x_center <= x2:
                        # í…ìŠ¤íŠ¸ ë°•ìŠ¤ì™€ ë¬¸ìì—´ í‘œì‹œ (ì •ìˆ˜ë¡œ ë³€í™˜)
                        pt1 = (int(x1), int(y1))
                        pt2 = (int(x2), int(y2))
                        cv2.rectangle(vis, pt1, pt2, (255, 255, 0), 2)
                        text_pos = (int(x1), max(0, int(y1)-10))
                        cv2.putText(vis, tl['text'], text_pos,
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
                        text_count += 1

        # Streamlit ì¶œë ¥
        st.subheader(f"{fname} - ìˆ˜í‰ì„  {len(contours_h)}ê°œ, ìˆ˜ì§ì„  {len(contours_v)}ê°œ, êµì°¨ì  {intersect_count}ê°œ, í…ìŠ¤íŠ¸ {text_count}ê°œ ê²€ì¶œ")
        st.image(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB), caption=fname)

        # ë””ë²„ê·¸ ì €ì¥
        if DEBUG_DIR:
            out_dir = os.path.join(DEBUG_DIR, 'visualized')
            os.makedirs(out_dir, exist_ok=True)
            out_path = os.path.join(out_dir, f"vis_{fname}")
            out_path = os.path.join(out_dir, f"vis_{fname}.png")
            cv2.imwrite(out_path, vis)
            st.write(f"ì €ì¥ë¨: {out_path}")

# Streamlit UI
        st.subheader(f"{fname} - ìˆ˜í‰ì„  {len(contours_h)}ê°œ, ìˆ˜ì§ì„  {len(contours_v)}ê°œ, êµì°¨ì  {intersect_count}ê°œ, í…ìŠ¤íŠ¸ {text_count}ê°œ ê²€ì¶œ")
        st.image(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB), caption=fname)

        # ë””ë²„ê·¸ ì €ì¥
        if DEBUG_DIR:
            out_dir = os.path.join(DEBUG_DIR, 'visualized')
            os.makedirs(out_dir, exist_ok=True)
            out_path = os.path.join(out_dir, f"vis_{fname}")
            cv2.imwrite(out_path, vis)
            st.write(f"ì €ì¥ë¨: {out_path}")

#-----------------------------------------------------------




# def detect_intersections(img):
#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
#     binary = cv2.adaptiveThreshold(~gray, 255,
#                                    cv2.ADAPTIVE_THRESH_MEAN_C,
#                                    cv2.THRESH_BINARY, 15, -2)
#     hsize = max(1, binary.shape[1]//30)
#     vsize = max(1, binary.shape[0]//30)
#     hor_struct = cv2.getStructuringElement(cv2.MORPH_RECT, (hsize,1))
#     vert_struct = cv2.getStructuringElement(cv2.MORPH_RECT, (1,vsize))
#     horizontal = cv2.dilate(cv2.erode(binary, hor_struct), hor_struct)
#     vertical   = cv2.dilate(cv2.erode(binary, vert_struct), vert_struct)
#     mask = cv2.bitwise_and(horizontal, vertical)
#     pts = cv2.findNonZero(mask)
#     if pts is None:
#         return [], horizontal, vertical
#     intersections = [tuple(p[0]) for p in pts]
#     return intersections, horizontal, vertical

# # 2) OCR í…ìŠ¤íŠ¸ ë¡œë“œ
# def load_text_boxes(base, BOXES_DIR, OCR_DIR):
#     boxes_path = os.path.join(BOXES_DIR, f"{base}_boxes.json")
#     ocr_path   = os.path.join(OCR_DIR, f"{base}.json")
#     if not os.path.exists(boxes_path) or not os.path.exists(ocr_path):
#         return []
#     with open(boxes_path, encoding='utf-8') as f:
#         boxes = json.load(f)
#     with open(ocr_path, encoding='utf-8') as f:
#         ocr = json.load(f)
#     text_centers = []
#     for b in boxes:
#         x_center = b['left'] + b['width']/2
#         for page in ocr.values():
#             for line in page:
#                 for t in line['text_lines']:
#                     x1,y1,x2,y2 = t['bbox']
#                     if x1 <= x_center <= x2:
#                         cx = (x1+x2)/2; cy = (y1+y2)/2
#                         text_centers.append({'text': t['text'], 'center': (int(cx), int(cy))})
#     return text_centers

# # 3) í…ìŠ¤íŠ¸ë¥¼ ê°ì‹¸ëŠ” ìµœì†Œ ì‚¬ê°í˜• ì°¾ê¸°
# def find_min_rectangles(intersections, horizontal, vertical, text_centers):
#     rects = []
#     pts_set = set(intersections)
#     xs = sorted({x for x,y in intersections})
#     ys = sorted({y for x,y in intersections})
#     for tc in text_centers:
#         cx, cy = tc['center']
#         best = None
#         min_area = float('inf')
#         for i in range(len(xs)):
#             for j in range(i+1, len(xs)):
#                 xl, xr = xs[i], xs[j]
#                 if not (xl <= cx <= xr): continue
#                 for u in range(len(ys)):
#                     for v in range(u+1, len(ys)):
#                         yt, yb = ys[u], ys[v]
#                         if not (yt <= cy <= yb): continue
#                         if (xl, yt) in pts_set and (xl, yb) in pts_set and (xr, yt) in pts_set and (xr, yb) in pts_set:
#                             top = horizontal[yt, xl:xr+1]
#                             bot = horizontal[yb, xl:xr+1]
#                             left = vertical[yt:yb+1, xl]
#                             right= vertical[yt:yb+1, xr]
#                             if top.all() and bot.all() and left.all() and right.all():
#                                 area = (xr-xl)*(yb-yt)
#                                 if area < min_area:
#                                     min_area = area
#                                     best = (xl, yt, xr, yb)
#         if best:
#             rects.append({'text': tc['text'], 'rect': best})
#     return rects

# # 4) ë°°ì¹˜ ì²˜ë¦¬ ë° í¬ë¡­
# def process_batch():
#     # ì…ì¶œë ¥ ê²½ë¡œ í•¨ìˆ˜ ë‚´ ì •ì˜
#     IMG_DIR = Wall_rawdata_SD          # ì²˜ë¦¬í•  ì´ë¯¸ì§€ í´ë”
#     BOXES_DIR = Wall_column_label     # boxes json í´ë” ê²½ë¡œ
#     OCR_DIR = Wall_OCR                # OCR json í´ë” ê²½ë¡œ
#     CELL_OUT_DIR = Wall_table_region  # í¬ë¡­ëœ ì…€ ì €ì¥ í´ë”

#     img_files = [f for f in os.listdir(IMG_DIR) if f.lower().endswith(('.png','.jpg','.jpeg'))]
#     if not img_files:
#         st.warning("ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
#         return

#     progress = st.progress(0)
#     total = len(img_files)

#     for idx, fname in enumerate(img_files):
#         img_path = os.path.join(IMG_DIR, fname)
#         img = cv2.imread(img_path)
#         if img is None:
#             st.error(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}")
#             progress.progress((idx+1)/total)
#             continue

#         intersections, hor, ver = detect_intersections(img)
#         text_centers = load_text_boxes(os.path.splitext(fname)[0], BOXES_DIR, OCR_DIR)
#         rects = find_min_rectangles(intersections, hor, ver, text_centers)

#         vis = img.copy()
#         for x,y in intersections:
#             cv2.circle(vis, (x,y), 4, (0,0,255), -1)
#         for r in rects:
#             x1,y1,x2,y2 = r['rect']
#             cv2.rectangle(vis, (x1,y1), (x2,y2), (0,255,0), 2)
#             cv2.putText(vis, r['text'], (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1)

#         st.subheader(f"{fname} - Rects: {len(rects)}")
#         st.image(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB), caption=fname)

#         os.makedirs(CELL_OUT_DIR, exist_ok=True)
#         for j, r in enumerate(rects):
#             x1,y1,x2,y2 = r['rect']
#             crop = img[y1:y2, x1:x2]
#             outp = os.path.join(CELL_OUT_DIR, f"{os.path.splitext(fname)[0]}_cell_{j}.png")
#             cv2.imwrite(outp, crop)

#         progress.progress((idx+1)/total)
# 1) êµì°¨ì  ê²€ì¶œ
# 0) ì»¬ëŸ¼ ë°•ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°
def load_column_boxes(base, BOXES_DIR):
    boxes_path = os.path.join(BOXES_DIR, f"{base}_boxes.json")
    if not os.path.exists(boxes_path):
        return []
    with open(boxes_path, encoding='utf-8') as f:
        return json.load(f)

# 0) ì¸ì ‘ ë°•ìŠ¤ ê°„ ìˆ˜í‰ ê±°ë¦¬ í‰ê·  ê³„ì‚°
def compute_avg_offset(column_boxes):
    if len(column_boxes) < 2:
        return 0
    # left ê°’ ê¸°ì¤€ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
    sorted_boxes = sorted(column_boxes, key=lambda b: b['left'])
    lefts = [b['left'] for b in sorted_boxes]
    # ì¸ì ‘ ê°„ ì°¨ì´ ê³„ì‚°
    diffs = [lefts[i+1] - lefts[i] for i in range(len(lefts)-1)]
    return int(sum(diffs) / len(diffs))

# 1) êµì°¨ì  ê²€ì¶œ
def detect_intersections(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    binary = cv2.adaptiveThreshold(
        ~gray, 255,
        cv2.ADAPTIVE_THRESH_MEAN_C,
        cv2.THRESH_BINARY, 15, -2
    )
    hsize = max(1, binary.shape[1] // 30)
    vsize = max(1, binary.shape[0] // 30)
    hor_struct = cv2.getStructuringElement(cv2.MORPH_RECT, (hsize, 1))
    vert_struct = cv2.getStructuringElement(cv2.MORPH_RECT, (1, vsize))
    horizontal = cv2.dilate(cv2.erode(binary, hor_struct), hor_struct)
    vertical   = cv2.dilate(cv2.erode(binary, vert_struct), vert_struct)
    mask = cv2.bitwise_and(horizontal, vertical)
    pts = cv2.findNonZero(mask)
    if pts is None:
        return [], horizontal, vertical
    intersections = [tuple(p[0]) for p in pts]
    return intersections, horizontal, vertical

# 2) OCR í…ìŠ¤íŠ¸ ë¡œë“œ
def load_text_boxes(base, BOXES_DIR, OCR_DIR):
    boxes_path = os.path.join(BOXES_DIR, f"{base}_boxes.json")
    ocr_path   = os.path.join(OCR_DIR, f"{base}.json")
    if not os.path.exists(boxes_path) or not os.path.exists(ocr_path):
        return []
    with open(boxes_path, encoding='utf-8') as f:
        boxes = json.load(f)
    with open(ocr_path, encoding='utf-8') as f:
        ocr = json.load(f)

    centers = []
    for b in boxes:
        x_center = b['left'] + b['width'] / 2
        for page in ocr.values():
            for line in page:
                for t in line['text_lines']:
                    x1, y1, x2, y2 = t['bbox']
                    if x1 <= x_center <= x2:
                        cx = int((x1 + x2) / 2)
                        cy = int((y1 + y2) / 2)
                        centers.append({'text': t['text'], 'center': (cx, cy)})
    return centers

# 3) í…ìŠ¤íŠ¸ë¥¼ ê°ì‹¸ëŠ” ìµœì†Œ ì‚¬ê°í˜• ì°¾ê¸°
def find_min_rectangles(intersections, horizontal, vertical, text_centers):
    rects = []
    pts_set = set(intersections)
    xs = sorted({x for x, y in intersections})
    ys = sorted({y for x, y in intersections})

    for tc in text_centers:
        cx, cy = tc['center']
        best = None
        min_area = float('inf')
        for i in range(len(xs)):
            for j in range(i+1, len(xs)):
                xl, xr = xs[i], xs[j]
                if not (xl <= cx <= xr): continue
                for u in range(len(ys)):
                    for v in range(u+1, len(ys)):
                        yt, yb = ys[u], ys[v]
                        if not (yt <= cy <= yb): continue
                        corners = {(xl, yt), (xl, yb), (xr, yt), (xr, yb)}
                        if corners.issubset(pts_set):
                            if (horizontal[yt, xl:xr+1].all() and
                                horizontal[yb, xl:xr+1].all() and
                                vertical[yt:yb+1, xl].all() and
                                vertical[yt:yb+1, xr].all()):
                                area = (xr - xl) * (yb - yt)
                                if area < min_area:
                                    min_area = area
                                    best = (xl, yt, xr, yb)
        if best:
            rects.append({'text': tc['text'], 'rect': best})
    return rects

# 4) ì´ë¯¸ì§€ í•˜ë‚˜ ì²˜ë¦¬ í•¨ìˆ˜
def process_image(fname, IMG_DIR, BOXES_DIR, OCR_DIR, DEBUG_DIR, CELL_OUT_DIR, margin=5):  # margin íŒŒë¼ë¯¸í„° ì¶”ê°€
    base = os.path.splitext(fname)[0]
    img_path = os.path.join(IMG_DIR, fname)
    img = cv2.imread(img_path)
    if img is None:
        return fname, None, 0

    # í…Œì´ë¸” ê·¸ë¦¬ë“œ ê²€ì¶œ & OCR ë§¤ì¹­
    intersections, hor, ver = detect_intersections(img)
    text_centers = load_text_boxes(base, BOXES_DIR, OCR_DIR)
    rects = find_min_rectangles(intersections, hor, ver, text_centers)

    # í‰ê·  ì»¬ëŸ¼ ê°„ê²© ê³„ì‚°
    column_boxes = load_column_boxes(base, BOXES_DIR)
    avg_offset   = compute_avg_offset(column_boxes)

    # ì‹œê°í™”(Debug) ì €ì¥
    vis = img.copy()
    for x, y in intersections:
        cv2.circle(vis, (x, y), 4, (0, 0, 255), -1)
    for r in rects:
        x1, y1, x2, y2 = r['rect']
        cv2.rectangle(vis, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(vis, r['text'], (x1, y1-5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1)
    os.makedirs(DEBUG_DIR, exist_ok=True)
    cv2.imwrite(os.path.join(DEBUG_DIR, f"vis_{fname}.png"), vis)

    # ì…€ + í™•ì¥ ì˜ì—­ í¬ë¡­ ì €ì¥
    os.makedirs(CELL_OUT_DIR, exist_ok=True)
    for idx, r in enumerate(rects):
        x1, y1, x2, y2 = r['rect']
        cell_w = x2 - x1
        ext = max(0, avg_offset - cell_w)
        x2_ext = min(x2 + ext, img.shape[1] - 1)

        # ì—¬ê¸°ì„œ ë§ˆì§„ ì ìš©!
        x1_crop = max(x1 - margin, 0)
        y1_crop = max(y1 - margin, 0)
        x2_crop = min(x2_ext + margin, img.shape[1] - 1)
        y2_crop = min(y2 + margin, img.shape[0] - 1)

        crop = img[y1_crop:y2_crop, x1_crop:x2_crop]  # ë§ˆì§„ ì ìš©ëœ í¬ë¡­

        text_label = r['text'].replace(' ', '_')
        out_name = f"{base}_{text_label}_{idx}.png"
        cv2.imwrite(os.path.join(CELL_OUT_DIR, out_name), crop)

    return fname, vis, len(rects)

# 5) ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜
def process_batch():
    IMG_DIR      = Wall_rawdata_SD
    DEBUG_DIR    = Wall_cell
    BOXES_DIR    = Wall_column_label
    OCR_DIR      = Wall_OCR
    CELL_OUT_DIR = Wall_table_region

    img_files = [f for f in os.listdir(IMG_DIR)
                 if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    if not img_files:
        st.warning("ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    total = len(img_files)
    progress = st.progress(0)
    with concurrent.futures.ThreadPoolExecutor() as executor:
        futures = {
            executor.submit(process_image, fname,
                            IMG_DIR, BOXES_DIR, OCR_DIR,
                            DEBUG_DIR, CELL_OUT_DIR): fname
            for fname in img_files
        }
        with st.spinner("ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤, ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."):
            for i, future in enumerate(concurrent.futures.as_completed(futures)):
                fname, vis, cnt = future.result()
                if vis is not None:
                    st.subheader(f"{fname} - Rects: {cnt}")
                    st.image(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB),
                             caption=fname)
                progress.progress((i+1)/total)
                time.sleep(0)








def apply_surya_ocr_Wall_Crop_SD():

    surya_output_folder = Wall_cell_crop_ocr

    os.makedirs(surya_output_folder, exist_ok=True)

    # âœ… ê¸°ì¡´ OCR ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìƒëµ
    existing_jsons = [f for f in os.listdir(surya_output_folder) if f.endswith(".json")]
    if existing_jsons:
        st.info(f"â„¹ï¸ ì´ë¯¸ {len(existing_jsons)}ê°œì˜ OCR ê²°ê³¼ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. Surya OCR ìƒëµ.")
        return

    # âœ… ì…ë ¥ ì´ë¯¸ì§€ í™•ì¸
    image_files = [f for f in os.listdir(Wall_table_region) if f.lower().endswith(('.jpg', '.png'))]
    if not image_files:
        st.error("âŒ plain text ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    st.write("ğŸ”OCR ì‹¤í–‰ ì¤‘...")
    progress_bar = st.progress(0)
    status_text = st.empty()


    for idx, image_file in enumerate(image_files):
        input_path = os.path.join(Wall_table_region, image_file)
        command = ["surya_ocr", input_path]
        result = subprocess.run(command, capture_output=True, text=True)

        stderr = result.stderr.strip()
        if stderr and all(x not in stderr for x in ["Detecting bboxes", "Recognizing Text"]):
            st.warning(f"âš ï¸ ì˜¤ë¥˜: {image_file} â†’ {stderr}")

        progress = int((idx + 1) / len(image_files) * 100)
        progress_bar.progress(progress)
        status_text.write(f"ğŸ–¼ï¸ OCR ì‹¤í–‰ ì¤‘: {image_file} ({progress}%)")

    progress_bar.empty()
    status_text.write("âœ… OCR ì™„ë£Œ. ê²°ê³¼ ì´ë™ ì¤‘...")

    # âœ… ê²°ê³¼ ì´ë™
    moved, skipped = 0, 0
    for folder_name in os.listdir(SURYA_RESULTS_FOLDER):
        folder_path = os.path.join(SURYA_RESULTS_FOLDER, folder_name)
        if os.path.isdir(folder_path):
            json_file = os.path.join(folder_path, "results.json")
            if os.path.exists(json_file):
                dst_file = os.path.join(surya_output_folder, f"{folder_name}.json")
                try:
                    shutil.move(json_file, dst_file)
                    moved += 1
                except Exception as e:
                    st.error(f"âŒ Move Error: {folder_name} â†’ {e}")
            else:
                skipped += 1

    st.success(f"ğŸ“ OCR ê²°ê³¼ {moved}ê°œ ì´ë™ ì™„ë£Œ ({skipped}ê°œëŠ” ëˆ„ë½ë¨)")


#---------------------------------------------------------------------------------------------
# def detect_and_draw_lines_batch(
#     img_dir, save_dir=None,
#     min_line_length=80, max_line_gap=10,
#     hough_threshold=100, morph_kernel_scale=30,
#     resize_scale=0.7,
#     max_examples=5, return_imgs=False,
#     mode="contour",
#     block_size=15, C=-2
# ):
#     img_files = [f for f in os.listdir(img_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
#     out_imgs = []
#     for i, img_file in enumerate(img_files):
#         if (max_examples is not None) and (i >= max_examples):
#             break
#         img_path = os.path.join(img_dir, img_file)
#         img = cv2.imread(img_path)
#         if img is None:
#             continue

#         # 1. ë¦¬ì‚¬ì´ì¦ˆ (ì¶•ì†Œ)
#         if resize_scale != 1.0:
#             img_small = cv2.resize(img, dsize=None, fx=resize_scale, fy=resize_scale, interpolation=cv2.INTER_AREA)
#         else:
#             img_small = img.copy()
#         gray = cv2.cvtColor(img_small, cv2.COLOR_BGR2GRAY)
#         binary = cv2.adaptiveThreshold(~gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, block_size, C)
#         horizontalsize = max(1, binary.shape[1] // morph_kernel_scale)
#         verticalsize = max(1, binary.shape[0] // morph_kernel_scale)
#         hor_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (horizontalsize, 1))
#         ver_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, verticalsize))
#         horizontal = cv2.erode(binary, hor_kernel)
#         horizontal = cv2.dilate(horizontal, hor_kernel)
#         vertical = cv2.erode(binary, ver_kernel)
#         vertical = cv2.dilate(vertical, ver_kernel)

#         result_img = img_small.copy()

#         if mode == "hough":
#             # ---- HoughLinesP ë°©ì‹ (ì´ì „ê³¼ ë™ì¼) ----
#             lines_h = cv2.HoughLinesP(horizontal, 1, np.pi/180, hough_threshold,
#                                       minLineLength=min_line_length, maxLineGap=max_line_gap)
#             if lines_h is not None:
#                 for l in lines_h:
#                     x1, y1, x2, y2 = l[0]
#                     cv2.line(result_img, (x1, y1), (x2, y2), (255,0,0), 2)
#             lines_v = cv2.HoughLinesP(vertical, 1, np.pi/180, hough_threshold,
#                                       minLineLength=min_line_length, maxLineGap=max_line_gap)
#             if lines_v is not None:
#                 for l in lines_v:
#                     x1, y1, x2, y2 = l[0]
#                     cv2.line(result_img, (x1, y1), (x2, y2), (0,255,0), 2)
#         else:
#             # ---- Contour ê¸°ë°˜ ë°©ì‹ ----
#             contours_h, _ = cv2.findContours(horizontal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
#             for cnt in contours_h:
#                 x, y, w, h = cv2.boundingRect(cnt)
#                 if w > min_line_length and h < (binary.shape[0] // 10):
#                     cv2.line(result_img, (x, y + h // 2), (x + w, y + h // 2), (255, 0, 0), 2)
#             contours_v, _ = cv2.findContours(vertical, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
#             for cnt in contours_v:
#                 x, y, w, h = cv2.boundingRect(cnt)
#                 if h > min_line_length and w < (binary.shape[1] // 10):
#                     cv2.line(result_img, (x + w // 2, y), (x + w // 2, y + h), (0, 255, 0), 2)

#         # 2. êµì°¨ì  ê²€ì¶œ ë° í‘œì‹œ
#         mask = cv2.bitwise_and(horizontal, vertical)
#         pts = cv2.findNonZero(mask)
#         intersect_count = 0
#         if pts is not None:
#             for p in pts:
#                 x_i, y_i = p[0]
#                 cv2.circle(result_img, (x_i, y_i), 4, (0,0,255), -1) # ë¹¨ê°„ìƒ‰ êµì°¨ì 
#             intersect_count = len(pts)

#         # ì €ì¥ ë° ë°˜í™˜
#         if save_dir:
#             os.makedirs(save_dir, exist_ok=True)
#             out_path = os.path.join(save_dir, f"lines_{img_file}")
#             cv2.imwrite(out_path, result_img)
#         if return_imgs:
#             out_imgs.append((img_file, result_img, intersect_count))
#     return out_imgs if return_imgs else None











# def batch_ocr_json_to_excel(margin=5):
#     # ê²½ë¡œë¥¼ í•¨ìˆ˜ ì•ˆì—ì„œ ì§€ì • (ì›í•˜ëŠ” í´ë”ëª…ìœ¼ë¡œ ë°”ê¿”ë„ ë¨)
#     input_folder = 'D:\wall_drawing\Wall_cell_crop_ocr'
#     output_folder = './Excel_Results'
#     os.makedirs(output_folder, exist_ok=True)

#     files = [f for f in os.listdir(input_folder) if f.lower().endswith('.json')]
#     if not files:
#         print('ì…ë ¥ í´ë”ì— json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.')
#         return
#     for fname in files:
#         input_json_path = os.path.join(input_folder, fname)
#         output_excel_path = os.path.join(
#             output_folder, os.path.splitext(fname)[0] + '.xlsx'
#         )
#         print(f"ì²˜ë¦¬ ì¤‘: {fname}")
#         try:
#             ocr_json_to_excel(input_json_path, output_excel_path, margin)
#         except Exception as e:
#             print(f"[ì—ëŸ¬] {fname} ì²˜ë¦¬ ì‹¤íŒ¨:", e)
#     print(f"\nì „ì²´ {len(files)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!")

# def ocr_json_to_excel(input_json_path, output_excel_path='output.xlsx', margin=5):
#     with open(input_json_path, encoding='utf-8') as f:
#         ocr_data = json.load(f)
#     ocr_boxes = []
#     for page in ocr_data.values():
#         for textline in page[0]['text_lines']:
#             text = textline['text'].strip()
#             bbox = textline['bbox']
#             ocr_boxes.append({'text': text, 'rect': bbox})
#     floor_keywords = ['F', 'B', 'PIT']
#     floor_boxes = [
#         box for box in ocr_boxes if any(kw in box['text'] for kw in floor_keywords)
#     ]
#     floor_boxes = sorted(floor_boxes, key=lambda b: b['rect'][1])
#     sorted_by_x = sorted(ocr_boxes, key=lambda b: b['rect'][0])
#     col_xs, col_names = [], []
#     col_num = 0
#     for box in sorted_by_x:
#         x1 = box['rect'][0]
#         if all(abs(x1 - cx) > 10 for cx in col_xs):
#             col_xs.append(x1)
#             col_names.append(chr(65+col_num))
#             col_num += 1
#     for box in ocr_boxes:
#         x1 = box['rect'][0]
#         idx = min(range(len(col_xs)), key=lambda i: abs(col_xs[i] - x1))
#         box['col'] = col_names[idx]
#     extracted_rows = []
#     for floor_box in floor_boxes:
#         fy1, fy2 = floor_box['rect'][1], floor_box['rect'][3]
#         row = {floor_box['col']: floor_box['text']}
#         for box in ocr_boxes:
#             if box == floor_box:
#                 continue
#             by1, by2 = box['rect'][1], box['rect'][3]
#             if (by2 > fy1 - margin) and (by1 < fy2 + margin):
#                 row[box['col']] = box['text']
#         extracted_rows.append(row)
#     all_cols = sorted(list(set(col_names)))
#     df = pd.DataFrame(extracted_rows)
#     df = df.reindex(columns=all_cols)
#     df.to_excel(output_excel_path, index=False)
#     print(f"[ì €ì¥ ì™„ë£Œ] {os.path.abspath(output_excel_path)}")
#     return df





# def detect_and_draw_lines_batch(
#     img_dir, save_dir=None,
#     min_line_length=80, max_line_gap=10,
#     hough_threshold=100, morph_kernel_scale=30,
#     resize_scale=0.7,
#     max_examples=5, return_imgs=False,
#     mode="contour",
#     block_size=15, C=-2,
#     tol=2  # â†” êµì°¨ì  í—ˆìš© ì˜¤ì°¨ (í”½ì…€)
# ):
#     img_files = [f for f in os.listdir(img_dir)
#                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
#     out_imgs = []
#     for i, img_file in enumerate(img_files):
#         if max_examples is not None and i >= max_examples:
#             break
#         img_path = os.path.join(img_dir, img_file)
#         img = cv2.imread(img_path)
#         if img is None:
#             continue

#         # 1. ë¦¬ì‚¬ì´ì¦ˆ + ì´ì§„í™”
#         if resize_scale != 1.0:
#             img_small = cv2.resize(img, None, fx=resize_scale, fy=resize_scale,
#                                    interpolation=cv2.INTER_AREA)
#         else:
#             img_small = img.copy()
#         gray = cv2.cvtColor(img_small, cv2.COLOR_BGR2GRAY)
#         binary = cv2.adaptiveThreshold(
#             ~gray, 255,
#             cv2.ADAPTIVE_THRESH_MEAN_C,
#             cv2.THRESH_BINARY,
#             int(block_size) | 1, C
#         )

#         # 2. ìˆ˜í‰/ìˆ˜ì§ ì„  ì¶”ì¶œ
#         hs = max(1, binary.shape[1] // morph_kernel_scale)
#         vs = max(1, binary.shape[0] // morph_kernel_scale)
#         hor_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (hs, 1))
#         ver_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, vs))
#         horizontal = cv2.dilate(cv2.erode(binary, hor_kernel), hor_kernel)
#         vertical   = cv2.dilate(cv2.erode(binary, ver_kernel), ver_kernel)

#         result_img = img_small.copy()

#         # 3. ì„  ê·¸ë¦¬ê¸° (ê¸°ì¡´ Hough / contour)
#         if mode == "hough":
#             lines_h = cv2.HoughLinesP(horizontal, 1, np.pi/180, hough_threshold,
#                                       minLineLength=min_line_length, maxLineGap=max_line_gap)
#             if lines_h is not None:
#                 for l in lines_h:
#                     x1, y1, x2, y2 = l[0]
#                     cv2.line(result_img, (x1, y1), (x2, y2), (255,0,0), 2)
#             lines_v = cv2.HoughLinesP(vertical, 1, np.pi/180, hough_threshold,
#                                       minLineLength=min_line_length, maxLineGap=max_line_gap)
#             if lines_v is not None:
#                 for l in lines_v:
#                     x1, y1, x2, y2 = l[0]
#                     cv2.line(result_img, (x1, y1), (x2, y2), (0,255,0), 2)
#         else:
#             contours_h, _ = cv2.findContours(horizontal, cv2.RETR_EXTERNAL,
#                                              cv2.CHAIN_APPROX_SIMPLE)
#             for cnt in contours_h:
#                 x, y, w, h = cv2.boundingRect(cnt)
#                 if w > min_line_length and h < (binary.shape[0] // 10):
#                     cv2.line(result_img, (x, y + h//2), (x + w, y + h//2),
#                              (255, 0, 0), 2)
#             contours_v, _ = cv2.findContours(vertical, cv2.RETR_EXTERNAL,
#                                              cv2.CHAIN_APPROX_SIMPLE)
#             for cnt in contours_v:
#                 x, y, w, h = cv2.boundingRect(cnt)
#                 if h > min_line_length and w < (binary.shape[1] // 10):
#                     cv2.line(result_img, (x + w//2, y), (x + w//2, y + h),
#                              (0, 255, 0), 2)

#         # 4. êµì°¨ì  ê²€ì¶œ: tol í”½ì…€ ì´ë‚´ì˜ ì„ ë„ ì—°ê²°í•´ì„œ ê²€ì¶œ
#         #    4.1 ìˆ˜í‰ì„ /ìˆ˜ì§ì„  ë§ˆìŠ¤í¬ íŒ½ì°½
#         kh = np.ones((1, 2*tol+1), np.uint8)
#         kv = np.ones((2*tol+1, 1), np.uint8)
#         hor_dil = cv2.dilate(horizontal, kh)
#         ver_dil = cv2.dilate(vertical, kv)
#         #    4.2 íŒ½ì°½ëœ ë§ˆìŠ¤í¬ AND
#         mask = cv2.bitwise_and(hor_dil, ver_dil)
#         pts = cv2.findNonZero(mask)

#         # 5. êµì°¨ì  ì‹œê°í™” ë° ë¦¬ìŠ¤íŠ¸ ì¶•ì 
#         intersect_count = 0
#         intersections = []
#         if pts is not None:
#             intersect_count = len(pts)
#             for p in pts:
#                 x_i, y_i = p[0]
#                 cv2.circle(result_img, (x_i, y_i), 4, (0,0,255), -1)
#                 intersections.append((int(x_i), int(y_i)))

#         # 6. ê²°ê³¼ ì €ì¥ (pkl + ì´ë¯¸ì§€)
#         if save_dir:
#             os.makedirs(save_dir, exist_ok=True)
#             base = os.path.splitext(img_file)[0]
#             with open(os.path.join(save_dir, f"{base}_lines.pkl"), "wb") as f:
#                 pickle.dump({
#                     "horizontal": horizontal,
#                     "vertical":   vertical,
#                     "intersections": intersections
#                 }, f)
#             cv2.imwrite(os.path.join(save_dir, f"lines_{img_file}"), result_img)

#         if return_imgs:
#             out_imgs.append((img_file, result_img, intersect_count))

#     return out_imgs if return_imgs else None
def detect_and_draw_lines_batch(
    img_dir, save_dir=None,
    min_line_length=80, max_line_gap=10,
    hough_threshold=100, morph_kernel_scale=30,
    resize_scale=0.7,
    max_examples=5, return_imgs=False,
    mode="contour",
    block_size=15, C=-2,
    tol=2
):
    img_files = [f for f in os.listdir(img_dir)
                 if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    out_imgs = []
    for i, img_file in enumerate(img_files):
        if max_examples is not None and i >= max_examples:
            break
        img_path = os.path.join(img_dir, img_file)
        img = cv2.imread(img_path)
        if img is None:
            continue

        # 1. ë¦¬ì‚¬ì´ì¦ˆ + ì´ì§„í™”
        if resize_scale != 1.0:
            img_small = cv2.resize(img, None, fx=resize_scale, fy=resize_scale,
                                   interpolation=cv2.INTER_AREA)
        else:
            img_small = img.copy()
        gray = cv2.cvtColor(img_small, cv2.COLOR_BGR2GRAY)
        binary = cv2.adaptiveThreshold(
            ~gray, 255,
            cv2.ADAPTIVE_THRESH_MEAN_C,
            cv2.THRESH_BINARY,
            int(block_size) | 1, C
        )

        # 2. ìˆ˜í‰/ìˆ˜ì§ ì„  ì¶”ì¶œ
        hs = max(1, binary.shape[1] // morph_kernel_scale)
        vs = max(1, binary.shape[0] // morph_kernel_scale)
        hor_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (hs, 1))
        ver_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, vs))
        horizontal = cv2.dilate(cv2.erode(binary, hor_kernel), hor_kernel)
        vertical   = cv2.dilate(cv2.erode(binary, ver_kernel), ver_kernel)

        result_img = img_small.copy()

        # 3. ì„  ê·¸ë¦¬ê¸°
        if mode == "hough":
            lines_h = cv2.HoughLinesP(horizontal, 1, np.pi/180, hough_threshold,
                                      minLineLength=min_line_length, maxLineGap=max_line_gap)
            if lines_h is not None:
                for l in lines_h:
                    x1, y1, x2, y2 = l[0]
                    cv2.line(result_img, (x1, y1), (x2, y2), (255,0,0), 2)
            lines_v = cv2.HoughLinesP(vertical, 1, np.pi/180, hough_threshold,
                                      minLineLength=min_line_length, maxLineGap=max_line_gap)
            if lines_v is not None:
                for l in lines_v:
                    x1, y1, x2, y2 = l[0]
                    cv2.line(result_img, (x1, y1), (x2, y2), (0,255,0), 2)
        else:
            contours_h, _ = cv2.findContours(horizontal, cv2.RETR_EXTERNAL,
                                             cv2.CHAIN_APPROX_SIMPLE)
            for cnt in contours_h:
                x, y, w, h = cv2.boundingRect(cnt)
                if w > min_line_length and h < (binary.shape[0] // 10):
                    cv2.line(result_img, (x, y + h//2), (x + w, y + h//2), (255,0,0), 2)
            contours_v, _ = cv2.findContours(vertical, cv2.RETR_EXTERNAL,
                                             cv2.CHAIN_APPROX_SIMPLE)
            for cnt in contours_v:
                x, y, w, h = cv2.boundingRect(cnt)
                if h > min_line_length and w < (binary.shape[1] // 10):
                    cv2.line(result_img, (x + w//2, y), (x + w//2, y + h), (0,255,0), 2)

        # 4. êµì°¨ì  ê²€ì¶œ
        kh = np.ones((1, 2*tol+1), np.uint8)
        kv = np.ones((2*tol+1, 1), np.uint8)
        hor_dil = cv2.dilate(horizontal, kh)
        ver_dil = cv2.dilate(vertical, kv)
        mask = cv2.bitwise_and(hor_dil, ver_dil)
        pts = cv2.findNonZero(mask)

        # 5. ì‹œê°í™” ë° ë¦¬ìŠ¤íŠ¸ ì¶•ì 
        intersections = []
        if pts is not None:
            for p in pts:
                x_i, y_i = p[0]
                cv2.circle(result_img, (x_i, y_i), 4, (0,0,255), -1)
                intersections.append((int(x_i), int(y_i)))

        # 6. ê²°ê³¼ ì €ì¥ (ì›ë³¸ í•´ìƒë„ë¡œ ë³´ì •)
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
            base = os.path.splitext(img_file)[0]
            h0, w0 = img.shape[:2]

            if resize_scale != 1.0:
                horizontal_full = cv2.resize(horizontal, (w0, h0), interpolation=cv2.INTER_NEAREST)
                vertical_full = cv2.resize(vertical, (w0, h0), interpolation=cv2.INTER_NEAREST)
                intersections_full = [(int(x/resize_scale), int(y/resize_scale))
                                      for x, y in intersections]
            else:
                horizontal_full = horizontal
                vertical_full = vertical
                intersections_full = intersections

            with open(os.path.join(save_dir, f"{base}_lines.pkl"), "wb") as f:
                pickle.dump({
                    "horizontal": horizontal_full,
                    "vertical":   vertical_full,
                    "intersections": intersections_full
                }, f)

            cv2.imwrite(os.path.join(save_dir, f"lines_{img_file}"), result_img)

        if return_imgs:
            out_imgs.append((img_file, result_img, len(intersections)))

    return out_imgs if return_imgs else None


# ---------- (2) í‘œ ì…€ ì¶”ì¶œ/ì—‘ì…€í™” ----------

def find_min_rectangles(intersections, horizontal, vertical, text_centers):
    rects = []
    pts_set = set(intersections)
    xs = sorted({x for x, y in intersections})
    ys = sorted({y for x, y in intersections})
    for tc in text_centers:
        cx, cy = tc['center']
        best = None
        min_area = float('inf')
        for i in range(len(xs)):
            for j in range(i+1, len(xs)):
                xl, xr = xs[i], xs[j]
                if not (xl <= cx <= xr):
                    continue
                for u in range(len(ys)):
                    for v in range(u+1, len(ys)):
                        yt, yb = ys[u], ys[v]
                        if not (yt <= cy <= yb):
                            continue
                        corners = {(xl, yt), (xl, yb), (xr, yt), (xr, yb)}
                        if corners.issubset(pts_set):
                            if (horizontal[yt, xl:xr+1].all() and
                                horizontal[yb, xl:xr+1].all() and
                                vertical[yt:yb+1, xl].all() and
                                vertical[yt:yb+1, xr].all()):
                                area = (xr - xl) * (yb - yt)
                                if area < min_area:
                                    min_area = area
                                    best = (xl, yt, xr, yb)
        if best:
            rects.append({'text': tc['text'], 'rect': best})
    return rects


# -------------------------------------------------------------
# 3) xì¶• í´ëŸ¬ìŠ¤í„°ë§ ì—´ ì¸ë±ìŠ¤ í• ë‹¹
# -------------------------------------------------------------
def assign_col_idx_by_cx(rects, margin=None):
    cxs = sorted([(r['rect'][0] + r['rect'][2]) / 2 for r in rects])
    if margin is None and len(cxs) > 1:
        diffs = [cxs[i+1] - cxs[i] for i in range(len(cxs)-1)]
        margin = (sum(diffs) / len(diffs)) / 2
    margin = margin or 10

    clusters = []
    for x in cxs:
        if not clusters or abs(x - clusters[-1]) > margin:
            clusters.append(x)
        else:
            clusters[-1] = (clusters[-1] + x) / 2

    for r in rects:
        cx = (r['rect'][0] + r['rect'][2]) / 2
        idx = int(np.argmin([abs(cx - c) for c in clusters]))
        r['col'] = idx

    return clusters


# -------------------------------------------------------------
# 4) rects ê¸°ë°˜ í‘œ ì¶”ì¶œ/ì—‘ì…€í™”
# -------------------------------------------------------------
def extract_table_dynamic(base, ocr_dir, line_dir):
    # (ê¸°ì¡´ extract_table_dynamic ì˜ 1~6ë‹¨ê³„ê¹Œì§€ ë™ì¼í•˜ê²Œ ìˆ˜í–‰í•˜ê³  DataFrame ë°˜í™˜)
    # 1) OCR centers
    with open(os.path.join(ocr_dir, f"{base}.json"), encoding='utf-8') as f:
        ocr = json.load(f)
    centers = []
    for page in ocr.values():
        for ln in page[0]['text_lines']:
            x1,y1,x2,y2 = ln['bbox']
            centers.append({'text':ln['text'].strip(),
                            'center':((x1+x2)/2,(y1+y2)/2)})
    # 2) load lines.pkl
    with open(os.path.join(line_dir, f"{base}_lines.pkl"), "rb") as f:
        data = pickle.load(f)
    inters, hor, ver = data['intersections'], data['horizontal'], data['vertical']
    # 3) rects
    rects = find_min_rectangles(inters, hor, ver, centers)
    # 4) col clustering
    clusters = assign_col_idx_by_cx(rects)
    # 5) floor rows
    floors = sorted([r for r in rects if any(k in r['text'] for k in ('F','B','PIT'))],
                    key=lambda r: r['rect'][1])
    # 6) build
    byh = sorted(rects, key=lambda r: r['rect'][3]-r['rect'][1])
    cols = [chr(65+i) for i in range(len(clusters))]
    rows = []
    for fr in floors:
        fy1,fy2 = fr['rect'][1], fr['rect'][3]
        row = {c:"" for c in cols}
        row[cols[fr['col']]] = fr['text']
        for r in byh:
            y1,y2 = r['rect'][1], r['rect'][3]
            if y1 <= fy1 and fy2 <= y2:
                cname = cols[r['col']]
                if not row[cname]:
                    row[cname] = r['text']
        rows.append(row)
    return pd.DataFrame(rows, columns=cols)

def batch_extract_consolidated(img_dir, save_line_dir, ocr_dir, consolidated_path,
                               **line_kwargs):
    """
    1) img_dir â†’ detect_and_draw_lines_batch â†’ PKL ìƒì„±
    2) ocr_dir & save_line_dir â†’ extract_table_dynamic â†’ ê°œë³„ DF ì¶”ì¶œ
    3) ëª¨ë“  DF í•©ì³ì„œ í•˜ë‚˜ì˜ ì—‘ì…€ íŒŒì¼ì— ì €ì¥
    """
    # 1) lines.pkl ìƒì„±
    detect_and_draw_lines_batch(
        img_dir=img_dir, save_dir=save_line_dir,
        max_examples=None, return_imgs=False, **line_kwargs
    )

    # 2) OCRâ†’DF ë°˜ë³µ ì¶”ì¶œ
    all_dfs = []
    for fn in os.listdir(ocr_dir):
        if not fn.lower().endswith(".json"):
            continue
        base = os.path.splitext(fn)[0]
        df = extract_table_dynamic(base, ocr_dir, save_line_dir)
        if not df.empty:
            df.insert(0, "íŒŒì¼ëª…", base)  # í•„ìš”ì‹œ êµ¬ë¶„ìš© ì»¬ëŸ¼ ì¶”ê°€
            all_dfs.append(df)

    if not all_dfs:
        print("ì¶”ì¶œëœ í‘œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 3) í•©ì¹˜ê¸° & ì €ì¥
    combined = pd.concat(all_dfs, ignore_index=True)
    os.makedirs(os.path.dirname(consolidated_path), exist_ok=True)
    combined.to_excel(consolidated_path, index=False)
    print(f"[í†µí•© ì—‘ì…€ ì €ì¥ ì™„ë£Œ] {consolidated_path}")


#######################################################################################################
########################################################################################################
#ë²½ì²´ êµ¬ì¡°ë„ë©´ ë ì•„ë˜ë¶€í„° êµ¬ì¡°ê³„ì‚°ì„œ ë²½ì²´####################################################################
##########################################################################################################
##########################################################################################################





WALL_IMAGE_DIR = os.path.join(BASE_DIR, "raw_data_WALL_SCD")

# ìƒìœ„ í´ë˜ìŠ¤ í´ë”ë“¤
MIDAS_DIR = os.path.join(BASE_DIR,"wall", "MIDAS")
BEST_DIR = os.path.join(BASE_DIR,"wall", "BeST")
TABLE_DIR = os.path.join(BASE_DIR,"wall", "Table")
MIDAS_INPUT_DIR = os.path.join(BASE_DIR,"wall", "MIDAS", "raw_data_classification_MIDAS")
MIDAS_OUTPUT_JSON_DIR = os.path.join(BASE_DIR,"wall", "MIDAS", "layout_results_json")
MIDAS_OUTPUT_VIS_DIR = os.path.join(BASE_DIR,"wall", "MIDAS", "layout_visualized")
MIDAS_OUTPUT_CROP_DIR = os.path.join(BASE_DIR,"wall", "MIDAS", "layout_crops")
MIDAS_OUTPUT_figure_DIR = os.path.join(BASE_DIR,"wall", "MIDAS", "layout_crops",'figure')
MIDAS_OUTPUT_plain_text_DIR = os.path.join(BASE_DIR,"wall", "MIDAS" ,"layout_crops","plain text")
MIDAS_OUTPUT_table_DIR = os.path.join(BASE_DIR,"wall", "MIDAS","layout_crops", "table")
Plain_text_ocr = os.path.join(MIDAS_OUTPUT_CROP_DIR,"plain_text_OCR")
Figure_ocr = os.path.join(MIDAS_OUTPUT_CROP_DIR,"figure_OCR")

Plain_text_elements_extraction = os.path.join(MIDAS_OUTPUT_CROP_DIR,"plain text elements")
BEST_INPUT_DIR = os.path.join(BASE_DIR,"wall", "BeST", "raw_data_classification_BeST")
BEST_OUTPUT_VIS_DIR = os.path.join(BASE_DIR,"wall", "BeST", "layout_visualized")
TABLE_INPUT_DIR = os.path.join(BASE_DIR,"wall", "TABLE", "raw_data_classification_Table")
TABLE_LATOUT = os.path.join(BASE_DIR,"wall", "TABLE", "layout_visualized")
BEST_OCR = os.path.join(BASE_DIR,"wall", "BeST", "BeST_OCR")
Table_crop = os.path.join(BASE_DIR,"wall", "TABLE", "crop")
Table_OCR = os.path.join(TABLE_DIR, "table_OCR")
BeST_plain_text = os.path.join(BEST_DIR,"wall","plain_text")
BeST_figure = os.path.join(BEST_DIR,"wall","figure")
BeST_table = os.path.join(BEST_DIR,"wall","table")




# ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(BASE_DIR, exist_ok=True)
os.makedirs(MIDAS_DIR, exist_ok=True)
os.makedirs(BEST_DIR, exist_ok=True)
os.makedirs(MIDAS_INPUT_DIR, exist_ok=True)
os.makedirs(MIDAS_OUTPUT_JSON_DIR, exist_ok=True)
os.makedirs(MIDAS_OUTPUT_VIS_DIR, exist_ok=True)
os.makedirs(MIDAS_OUTPUT_figure_DIR, exist_ok=True)
os.makedirs(MIDAS_OUTPUT_plain_text_DIR, exist_ok=True)
os.makedirs(MIDAS_OUTPUT_table_DIR, exist_ok=True)
os.makedirs(MIDAS_OUTPUT_CROP_DIR, exist_ok=True)
os.makedirs(Plain_text_ocr, exist_ok=True)
os.makedirs(Figure_ocr, exist_ok=True)
os.makedirs(Plain_text_elements_extraction, exist_ok=True)
os.makedirs(BEST_INPUT_DIR, exist_ok=True)
os.makedirs(BEST_OUTPUT_VIS_DIR, exist_ok=True)
os.makedirs(BEST_OCR, exist_ok=True)
os.makedirs(TABLE_INPUT_DIR, exist_ok=True)
os.makedirs(Table_crop, exist_ok=True)
os.makedirs(TABLE_LATOUT, exist_ok=True)
os.makedirs(Table_OCR, exist_ok=True)
os.makedirs(Table_crop, exist_ok=True)
os.makedirs(TABLE_LATOUT, exist_ok=True)
os.makedirs(Table_OCR, exist_ok=True)
os.makedirs(BeST_plain_text, exist_ok=True)
os.makedirs(BeST_table, exist_ok=True)
os.makedirs(BeST_figure, exist_ok=True)


# -------------------- ì„¤ì • --------------------


CONF_THRESH = 0.3
IOU_THRESH = 0.2
IMAGE_SIZE = 1024

# -------------------- ëª¨ë¸ ë¡œë”© --------------------
model_file = hf_hub_download(
    repo_id="juliozhao/DocLayout-YOLO-DocStructBench",
    filename="doclayout_yolo_docstructbench_imgsz1024.pt"
)
yolo_model = YOLOv10(model_file)

# -------------------- ê¸°ëŠ¥ í•¨ìˆ˜ --------------------
def convert_pdf_to_images(uploaded_pdf, output_dir=WALL_IMAGE_DIR):
    
    os.makedirs(output_dir, exist_ok=True)
    images = convert_from_bytes(uploaded_pdf.read(), dpi=300)
    image_paths = []

    for idx, image in enumerate(images):
        img_path = os.path.join(output_dir, f"page_{idx + 1}.png")
        image.save(img_path, "PNG")
        image_paths.append(img_path)

    return image_paths

def extract_yolo_features(results):
    boxes = results.boxes
    names = results.names
    labels = [names[int(b.cls.item())] for b in boxes]

    counts = Counter(labels)
    total = len(labels)
    widths = [b.xyxy[0][2] - b.xyxy[0][0] for b in boxes]
    heights = [b.xyxy[0][3] - b.xyxy[0][1] for b in boxes]

    feats = {}
    for t in ['text', 'table', 'figure', 'title', 'list']:
        feats[f"{t}_count"] = counts.get(t, 0)
        feats[f"{t}_ratio"] = counts.get(t, 0) / total if total else 0

    feats['box_count'] = total
    feats['avg_height'] = float(np.mean(heights)) if heights else 0
    feats['avg_width'] = float(np.mean(widths)) if widths else 0
    feats['std_height'] = float(np.std(heights)) if heights else 0
    feats['std_width'] = float(np.std(widths)) if widths else 0
    return feats

def predict_document_type(image_paths, conf_thresh):
    conf_folder = f"thresh_{str(conf_thresh).replace('.', '')}"
    model_dir = os.path.join("D:/wall_slabe_data/model", conf_folder)

    # ëª¨ë¸ ìë™ ì„ íƒ
    model_files = [f for f in os.listdir(model_dir) if f.startswith("best_model")]
    if not model_files:
        raise FileNotFoundError(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_dir}")

    model_file = os.path.join(model_dir, model_files[0])
    rf_model = joblib.load(model_file)
    label_encoder = joblib.load(os.path.join(model_dir, "label_encoder.pkl"))

    predictions = []

    for img_path in image_paths:
        results = yolo_model.predict(img_path, imgsz=IMAGE_SIZE, conf=conf_thresh, iou=IOU_THRESH)[0]
        features = extract_yolo_features(results)

        df_feat = np.array([list(features.values())])
        label_idx = rf_model.predict(df_feat)[0]
        label = label_encoder.inverse_transform([label_idx])[0]

        predictions.append({
            "image_path": img_path,
            "label": label
        })

    return predictions



def save_images_by_prediction(results):
    class_counters = {}

    for item in results:
        src_path = item["image_path"]
        label = item["label"]

        # ìƒˆë¡œìš´ êµ¬ì¡°: D:/Slabe_Wall/{label}/raw_data_classification_{label}/
        upper_dir = os.path.join(BASE_DIR, label)
        save_dir = os.path.join(upper_dir, f"raw_data_classification_{label}")
        os.makedirs(save_dir, exist_ok=True)

        # íŒŒì¼ëª… êµ¬ì„±
        original_name = os.path.splitext(os.path.basename(src_path))[0]
        ext = os.path.splitext(src_path)[1]

        class_counters[label] = class_counters.get(label, 0) + 1
        count = class_counters[label]

        new_filename = f"{original_name}_{label}_{count}{ext}"
        dst_path = os.path.join(save_dir, new_filename)

        shutil.copy(src_path, dst_path)

######################################################################################################
#MIDAS ì• ë“¤ ì •ë³´ ì¶”ì¶œ

def analyze_and_crop_midas():
    image_files = [
        f for f in os.listdir(MIDAS_INPUT_DIR)
        if f.lower().endswith((".png", ".jpg", ".jpeg"))
    ]

    for img_file in image_files:
        img_path = os.path.join(MIDAS_INPUT_DIR, img_file)

        # YOLO ë¶„ì„
        results = yolo_model.predict(
            img_path, imgsz=IMAGE_SIZE, conf=CONF_THRESH, iou=IOU_THRESH
        )[0]

        # ê²°ê³¼ ì €ì¥í•  JSON ë¦¬ìŠ¤íŠ¸
        json_list = []

        # ì´ë¯¸ì§€ ë¡œë“œ
        image = Image.open(img_path)

        for idx, box in enumerate(results.boxes):
            label = results.names[int(box.cls.item())]
            xyxy = [round(x, 2) for x in box.xyxy[0].tolist()]
            json_list.append({"label": label, "box": xyxy})

            # ğŸ¯ í¬ë¡­ ëŒ€ìƒ í´ë˜ìŠ¤ë§Œ ì €ì¥
            if label in ["plain text", "table", "figure"]:
                x1, y1, x2, y2 = map(int, xyxy)
                cropped = image.crop((x1, y1, x2, y2))

                class_folder = os.path.join(MIDAS_OUTPUT_CROP_DIR, label.replace(" ", "_"))
                crop_filename = f"{os.path.splitext(img_file)[0]}_{label.replace(' ', '_')}_{idx+1}.png"
                crop_path = os.path.join(class_folder, crop_filename)
                cropped.save(crop_path)

        # JSON ì €ì¥
        json_name = os.path.splitext(img_file)[0] + ".json"
        json_path = os.path.join(MIDAS_OUTPUT_JSON_DIR, json_name)
        with open(json_path, "w") as jf:
            json.dump(json_list, jf, indent=2)

        # ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥
        vis_np = results.plot()
        vis_img = Image.fromarray(vis_np)
        vis_img.save(os.path.join(MIDAS_OUTPUT_VIS_DIR, img_file))

    print(f"âœ… MIDAS ë¶„ì„ ë° í¬ë¡­ ì™„ë£Œ: ì´ {len(image_files)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ë¨")



def run_midas_analysis():
    print("ğŸ“ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ:", model_file)
    print("ğŸ“Œ ëª¨ë¸ ë¼ë²¨ ëª©ë¡:", yolo_model.names)

    image_files = [
        f for f in os.listdir(MIDAS_INPUT_DIR)
        if f.lower().endswith((".png", ".jpg", ".jpeg"))
    ]
    total = len(image_files)

    progress_bar = st.progress(0)
    status_text = st.empty()

    label_names = yolo_model.names
    MIN_HEIGHT_THRESHOLD = 200

    for idx, img_file in enumerate(image_files):
        img_path = os.path.join(MIDAS_INPUT_DIR, img_file)
        image = Image.open(img_path).convert("RGB")
        base_name = os.path.splitext(img_file)[0]

        results = yolo_model.predict(
            img_path, imgsz=IMAGE_SIZE, conf=CONF_THRESH, iou=IOU_THRESH
        )[0]

        print(f"[{base_name}] ë°•ìŠ¤ ê°œìˆ˜: {len(results.boxes)}")
        if hasattr(results, "boxes"):
            label_set = set([label_names[int(box.cls.item())] for box in results.boxes])
            print(f"[{base_name}] ğŸ“Œ Detected labels: {label_set}")
        if not hasattr(results, "boxes") or len(results.boxes) == 0:
            print(f"[{base_name}] â— No boxes detected")
            continue

        boxes = results.boxes
        cropped_items = []

        for i, box in enumerate(boxes):
            label = label_names[int(box.cls.item())]
            xyxy = [round(x, 2) for x in box.xyxy[0].tolist()]
            height = xyxy[3] - xyxy[1]

            if label == "plain text":
                print(f"[{base_name}] plain text height: {height}")
                if height < MIN_HEIGHT_THRESHOLD:
                    print(f"â›” Skipping plain text due to small height: {height}")
                    continue

            cropped_items.append({"label": label, "box": xyxy})

        # figure ì¤‘ ìƒë‹¨ 1ê°œë§Œ ë‚¨ê¸°ê¸°
        figures = [item for item in cropped_items if item["label"] == "figure"]
        if figures:
            top_figure = sorted(figures, key=lambda x: x["box"][1])[0]
            cropped_items = [item for item in cropped_items if item["label"] != "figure"]
            cropped_items.append(top_figure)

        plain_count = table_count = figure_count = 0

        for item in cropped_items:
            label = item["label"]
            x1, y1, x2, y2 = map(int, item["box"])
            x1, y1 = max(x1, 0), max(y1, 0)
            x2, y2 = min(x2, image.width), min(y2, image.height)
            cropped_image = image.crop((x1, y1, x2, y2))
            height = y2 - y1

            if label == "plain text":
                print(f"[{base_name}] ğŸ“ plain_text height ê³„ì‚°: {height}")
                if height < MIN_HEIGHT_THRESHOLD:
                    print(f"[{base_name}] â›” Skipping plain_text: height {height} < THRESH {MIN_HEIGHT_THRESHOLD}")
                    continue
                else:
                    print(f"[{base_name}] âœ… plain_text height ì¡°ê±´ í†µê³¼")
                save_path = os.path.join(MIDAS_OUTPUT_plain_text_DIR, f"{base_name}_plain_{plain_count}.png")
                cropped_image.save(save_path)
                plain_count += 1

            elif label == "table":
                save_path = os.path.join(MIDAS_OUTPUT_table_DIR, f"{base_name}_table_{table_count}.png")
                cropped_image.save(save_path)
                table_count += 1

            elif label == "figure":
                save_path = os.path.join(MIDAS_OUTPUT_figure_DIR, f"{base_name}_figure_{figure_count}.png")
                cropped_image.save(save_path)
                figure_count += 1

        progress = (idx + 1) / total
        progress_bar.progress(progress)
        status_text.text(f"ğŸ”„ {idx + 1} / {total} ì²˜ë¦¬ ì¤‘: {img_file}")

    st.success("âœ… ë¶„ì„ ë° í¬ë¡­ ì™„ë£Œ!")


def apply_surya_ocr_to_plain_text():
    plain_text_folder = MIDAS_OUTPUT_plain_text_DIR
    surya_output_folder = os.path.join(MIDAS_OUTPUT_CROP_DIR, "plain_text_OCR")

    os.makedirs(surya_output_folder, exist_ok=True)

    # âœ… ê¸°ì¡´ OCR ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìƒëµ
    existing_jsons = [f for f in os.listdir(surya_output_folder) if f.endswith(".json")]
    if existing_jsons:
        st.info(f"â„¹ï¸ ì´ë¯¸ {len(existing_jsons)}ê°œì˜ OCR ê²°ê³¼ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. Surya OCR ìƒëµ.")
        return

    # âœ… ì…ë ¥ ì´ë¯¸ì§€ í™•ì¸
    image_files = [f for f in os.listdir(plain_text_folder) if f.lower().endswith(('.jpg', '.png'))]
    if not image_files:
        st.error("âŒ plain text ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    progress_bar = st.progress(0)
    status_text = st.empty()
    st.write("ğŸ”OCR ì‹¤í–‰ ì¤‘...")

    for idx, image_file in enumerate(image_files):
        input_path = os.path.join(plain_text_folder, image_file)
        command = ["surya_ocr", input_path]
        result = subprocess.run(command, capture_output=True, text=True)

        stderr = result.stderr.strip()
        if stderr and all(x not in stderr for x in ["Detecting bboxes", "Recognizing Text"]):
            st.warning(f"âš ï¸ ì˜¤ë¥˜: {image_file} â†’ {stderr}")

        progress = int((idx + 1) / len(image_files) * 100)
        progress_bar.progress(progress)
        status_text.write(f"ğŸ–¼ï¸ OCR ì‹¤í–‰ ì¤‘: {image_file} ({progress}%)")

    progress_bar.empty()
    status_text.write("âœ… OCR ì™„ë£Œ. ê²°ê³¼ ì´ë™ ì¤‘...")

    # âœ… ê²°ê³¼ ì´ë™
    moved, skipped = 0, 0
    for folder_name in os.listdir(SURYA_RESULTS_FOLDER):
        folder_path = os.path.join(SURYA_RESULTS_FOLDER, folder_name)
        if os.path.isdir(folder_path):
            json_file = os.path.join(folder_path, "results.json")
            if os.path.exists(json_file):
                dst_file = os.path.join(surya_output_folder, f"{folder_name}.json")
                try:
                    shutil.move(json_file, dst_file)
                    moved += 1
                except Exception as e:
                    st.error(f"âŒ Move Error: {folder_name} â†’ {e}")
            else:
                skipped += 1

    st.success(f"ğŸ“ OCR ê²°ê³¼ {moved}ê°œ ì´ë™ ì™„ë£Œ ({skipped}ê°œëŠ” ëˆ„ë½ë¨)")


def apply_surya_ocr_to_figure():
    figure_folder = MIDAS_OUTPUT_figure_DIR
    surya_output_folder = os.path.join(MIDAS_OUTPUT_CROP_DIR, "figure_OCR")

    os.makedirs(surya_output_folder, exist_ok=True)

    # âœ… ê¸°ì¡´ OCR ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìƒëµ
    existing_jsons = [f for f in os.listdir(surya_output_folder) if f.endswith(".json")]
    if existing_jsons:
        st.info(f"â„¹ï¸ ì´ë¯¸ {len(existing_jsons)}ê°œì˜ OCR ê²°ê³¼ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. Surya OCR ìƒëµ.")
        return

    # âœ… ì…ë ¥ ì´ë¯¸ì§€ í™•ì¸
    image_files = [f for f in os.listdir(figure_folder) if f.lower().endswith(('.jpg', '.png'))]
    if not image_files:
        st.error("âŒ plain text ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    progress_bar = st.progress(0)
    status_text = st.empty()
    st.write("ğŸ”OCR ì‹¤í–‰ ì¤‘...")

    for idx, image_file in enumerate(image_files):
        input_path = os.path.join(figure_folder, image_file)
        command = ["surya_ocr", input_path]
        result = subprocess.run(command, capture_output=True, text=True)

        stderr = result.stderr.strip()
        if stderr and all(x not in stderr for x in ["Detecting bboxes", "Recognizing Text"]):
            st.warning(f"âš ï¸ ì˜¤ë¥˜: {image_file} â†’ {stderr}")

        progress = int((idx + 1) / len(image_files) * 100)
        progress_bar.progress(progress)
        status_text.write(f"ğŸ–¼ï¸ OCR ì‹¤í–‰ ì¤‘: {image_file} ({progress}%)")

    progress_bar.empty()
    status_text.write("âœ… OCR ì™„ë£Œ. ê²°ê³¼ ì´ë™ ì¤‘...")

    # âœ… ê²°ê³¼ ì´ë™
    moved, skipped = 0, 0
    for folder_name in os.listdir(SURYA_RESULTS_FOLDER):
        folder_path = os.path.join(SURYA_RESULTS_FOLDER, folder_name)
        if os.path.isdir(folder_path):
            json_file = os.path.join(folder_path, "results.json")
            if os.path.exists(json_file):
                dst_file = os.path.join(surya_output_folder, f"{folder_name}.json")
                try:
                    shutil.move(json_file, dst_file)
                    moved += 1
                except Exception as e:
                    st.error(f"âŒ Move Error: {folder_name} â†’ {e}")
            else:
                skipped += 1

    st.success(f"ğŸ“ OCR ê²°ê³¼ {moved}ê°œ ì´ë™ ì™„ë£Œ ({skipped}ê°œëŠ” ëˆ„ë½ë¨)")
#####################################################

def render_keyword_based_ocr_extraction():
    image_list = sorted(glob.glob(os.path.join(MIDAS_OUTPUT_plain_text_DIR, "*.png")))
    json_list = sorted(glob.glob(os.path.join(MIDAS_OUTPUT_CROP_DIR, "plain_text_OCR", "*.json")))
    ocr_folder_path = os.path.join(MIDAS_OUTPUT_CROP_DIR, "plain_text_OCR")
    txt_save_dir = os.path.join(MIDAS_OUTPUT_CROP_DIR, "plain text elements")
    os.makedirs(txt_save_dir, exist_ok=True)

    if not image_list or not json_list:
        st.error("âŒ ì´ë¯¸ì§€ ë˜ëŠ” OCR ê²°ê³¼ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    def load_ocr_results(json_path):
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        first_key = next(iter(data))
        text_lines = data[first_key][0]['text_lines']
        return [{"text": item["text"], "box": item["bbox"]} for item in text_lines]

    def get_center(box):
        x = (box[0] + box[2]) / 2
        y = (box[1] + box[3]) / 2
        return x, y

    def draw_bounding_boxes_with_numbers(image_path, ocr_data, max_width=600):
        # 1) ì´ë¯¸ì§€ ë¡œë“œ ë° OCR ë°•ìŠ¤+ë²ˆí˜¸ ê·¸ë¦¬ê¸°
        image = Image.open(image_path).convert("RGB")
        draw = ImageDraw.Draw(image)
        try:
            font = ImageFont.truetype("arial.ttf", 24)
        except:
            font = ImageFont.load_default()

        for idx, item in enumerate(ocr_data):
            box = item["box"]
            draw.rectangle(box, outline="red", width=2)
            draw.text((box[0] + 5, box[1] + 5), str(idx), fill="blue", font=font)

        # 2) ìµœëŒ€ ë„ˆë¹„(max_width)ë³´ë‹¤ í¬ë©´ ë¹„ìœ¨ ìœ ì§€í•˜ë©° ì¶•ì†Œ
        if image.width > max_width:
            ratio = max_width / image.width
            new_height = int(image.height * ratio)
            # Pillow 10 ì´ìƒì—ì„œëŠ” Resampling.LANCZOS ê¶Œì¥
            try:
                resample = Image.Resampling.LANCZOS
            except AttributeError:
                resample = Image.LANCZOS
            image = image.resize((max_width, new_height), resample)

        return image



    def find_right_side_value(ocr_data, ref_box, y_tolerance=15):
        ref_x, ref_y = get_center(ref_box)
        candidates = []
        for item in ocr_data:
            x, y = get_center(item["box"])
            if abs(y - ref_y) < y_tolerance and x > ref_x:
                dist = abs(x - ref_x)
                candidates.append((dist, item["text"]))
        if not candidates:
            return None
        candidates.sort(key=lambda x: x[0])
        return candidates[0][1].lstrip(":ï¼š").strip()
    

    def normalize(s: str) -> str:
        return re.sub(r"\s+", "", s or "").lower()

    def find_reference_box(ocr_data, keyword):
        """í‚¤ì›Œë“œê°€ ë“¤ì–´ìˆëŠ” OCR ì•„ì´í…œì˜ boxë¥¼ ë°˜í™˜"""
        kw_norm = normalize(keyword)
        best = None
        best_len = 10**9

        for item in ocr_data:
            text = item.get("text", "")
            box = item.get("box")
            if not text or box is None:
                continue

            tnorm = normalize(text)
            if kw_norm in tnorm:
                # ë” ì§§ì€ í…ìŠ¤íŠ¸ì¼ìˆ˜ë¡ í‚¤ì›Œë“œ ì „ìš© ë¼ë²¨ì¼ ê°€ëŠ¥ì„±ì´ ì»¤ì„œ ìš°ì„ 
                if len(tnorm) < best_len:
                    best = box
                    best_len = len(tnorm)

        return best

    def extract_horizontal_rebar_patterns(text):
        pattern = r"\b(?:D|HD|SD|UHD|SUHD)[\s\-]*\d{1,2}[\s\-]*@[\s\-]*\d{2,4}\b"
        return re.findall(pattern, text)

    def clean_text_after_keyword(full_text, keyword):
        text = re.sub(r"\([^)]*\)", "", full_text)  # ê´„í˜¸ ì•ˆ ì œê±°
        pattern = re.escape(keyword) + r"\s*[:ï¼š.]?\s*"
        text = re.sub(pattern, "", text, flags=re.IGNORECASE)
        return text.strip()

    def extract_grouped_by_page(keywords):
        grouped_files = defaultdict(list)
        for path in glob.glob(os.path.join(ocr_folder_path, "*.json")):
            name = os.path.basename(path)
            page_group = "_".join(name.split("_")[:2])
            grouped_files[page_group].append(path)

        for group, file_list in grouped_files.items():
            combined_info = {}
            horizontal_rebars = set()
            vertical_rebar_at = None

            for json_path in file_list:
                ocr_data = load_ocr_results(json_path)

                for keyword in keywords:
                    if keyword in combined_info:
                        continue

                    ref_box = find_reference_box(ocr_data, keyword)
                    value = None

                    if ref_box:
                        value = find_right_side_value(ocr_data, ref_box)

                    # ğŸ”¥ ì˜¤ë¥¸ìª½ ê°’ì´ ì—†ì„ ë•Œ fallbackìœ¼ë¡œ ê°™ì€ ë°•ìŠ¤ ë‚´ë¶€ í…ìŠ¤íŠ¸ ì‚¬ìš©
                    if not value:
                        for item in ocr_data:
                            if keyword.lower() in item['text'].lower():
                                cleaned = clean_text_after_keyword(item['text'], keyword)
                                if re.search(r"[a-zA-Z0-9ê°€-í£]", cleaned):
                                    value = cleaned
                                    break

                    combined_info[keyword] = value.strip() if value else "(ê°’ ì—†ìŒ)"

                    if "wall dim" in keyword.lower() and "*" not in combined_info[keyword]:
                        combined_info[keyword] = "(ê°’ ì—†ìŒ)"

                    if "vertical rebar" in keyword.lower():
                        vertical_rebar_at = re.search(r"@[\s\-]*\d{2,4}", value or "")

                for item in ocr_data:
                    text = item["text"]
                    matches = extract_horizontal_rebar_patterns(text)
                    for match in matches:
                        if vertical_rebar_at and vertical_rebar_at.group(0).replace(" ", "") in match.replace(" ", ""):
                            continue
                        horizontal_rebars.add(match.strip())

            lines = [f"{k}: {v}" for k, v in combined_info.items()]
            if horizontal_rebars:
                lines.append("Horizontal Rebar: " + ", ".join(sorted(horizontal_rebars)))

            save_path = os.path.join(txt_save_dir, f"{group}.txt")
            with open(save_path, "w", encoding="utf-8") as f:
                f.write("\n".join(lines))

    # â”€â”€â”€â”€â”€ Streamlit UI â”€â”€â”€â”€â”€
# â”€â”€â”€â”€â”€ Streamlit UI â”€â”€â”€â”€â”€
    ocr_json_path = json_list[0]
    base = os.path.splitext(os.path.basename(ocr_json_path))[0]
    image_path = os.path.join(MIDAS_OUTPUT_plain_text_DIR, f"{base}.png")

    ocr_data = load_ocr_results(ocr_json_path)

    st.image(
        draw_bounding_boxes_with_numbers(image_path, ocr_data),
        caption=f"ğŸ–¼ï¸ {base}.png (OCR + ë²ˆí˜¸)",
        use_column_width=False,
        width=600
    )

    st.markdown("### âœï¸ ì¶”ì¶œí•  í‚¤ì›Œë“œ 5ê°œë¥¼ ì…ë ¥í•˜ì„¸ìš”")

    default_values = [
        "Wall ID",
        "Story",
        "Material Data",
        "Wall DIM",
        "Vertical Rebar"
    ]
    keywords = []
    for i in range(5):
        value = st.text_input(f"ğŸ”¹ í‚¤ì›Œë“œ {i+1}", value=default_values[i], key=f"kw_{i}")
        if value.strip():
            keywords.append(value.strip())

    if st.button("ğŸš€ ë¶€ì¬ ë‹¨ìœ„ë¡œ OCR ìë™ ì¶”ì¶œ ë° txt ì €ì¥"):
        extract_grouped_by_page(keywords)
        st.success(f"âœ… ëª¨ë“  ë¶€ì¬(page_xx)ë³„ txt ì €ì¥ ì™„ë£Œ! â†’ `{txt_save_dir}`")

##################################################################################################################
######################################################################################################################
#BeSTì²˜ë¦¬

def apply_best_layout_analysis():
    """
    BeST_INPUT_DIR ë‚´ ì´ë¯¸ì§€ì— ëŒ€í•´ DocLayout-YOLO ëª¨ë¸ë¡œ ë ˆì´ì•„ì›ƒ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ ,
    ê²€ì¶œëœ 'plain text', 'figure', 'table' ì˜ì—­ì„ ë³„ë„ í´ë”ì— í¬ë¡­í•˜ì—¬ ì €ì¥í•œë‹¤.
    ì‹œê°í™” ê²°ê³¼ëŠ” BEST_OUTPUT_VIS_DIRì— ì €ì¥ë¨
    """
    # ì…ë ¥/ì¶œë ¥ ë””ë ‰í† ë¦¬
    input_dir = BEST_INPUT_DIR
    out_text  = BeST_plain_text
    out_fig   = BeST_figure
    out_tab   = BeST_table
    vis_dir   = BEST_OUTPUT_VIS_DIR

    # ì¶œë ¥ í´ë” ìƒì„±
    os.makedirs(out_text, exist_ok=True)
    os.makedirs(out_fig, exist_ok=True)
    os.makedirs(out_tab, exist_ok=True)
    os.makedirs(vis_dir, exist_ok=True)

    # ì´ë¯¸ì§€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
    input_dir = BEST_INPUT_DIR
    out_text  = BeST_plain_text
    out_fig   = BeST_figure
    out_tab   = BeST_table

    # ì¶œë ¥ í´ë” ìƒì„±
    os.makedirs(out_text, exist_ok=True)
    os.makedirs(out_fig, exist_ok=True)
    os.makedirs(out_tab, exist_ok=True)

    # ì´ë¯¸ì§€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
    image_files = [f for f in os.listdir(input_dir)
                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    total = len(image_files)
    progress = st.progress(0)
    status = st.empty()

    # ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ë¶„ì„
    for idx, fname in enumerate(sorted(image_files)):
        path = os.path.join(input_dir, fname)
        im = Image.open(path).convert('RGB')

                # YOLO ëª¨ë¸ ì˜ˆì¸¡
        results = yolo_model.predict(path, imgsz=IMAGE_SIZE, conf=CONF_THRESH, iou=IOU_THRESH)[0]

        # ì‹œê°í™” ê²°ê³¼ ì €ì¥
        vis_np = results.plot()
        vis_img = Image.fromarray(vis_np)
        vis_path = os.path.join(vis_dir, f"{os.path.splitext(fname)[0]}_vis.png")
        vis_img.save(vis_path)

        # ë°•ìŠ¤ë³„ë¡œ í¬ë¡­ ì €ì¥
        counters = {'plain text': 0, 'figure': 0, 'table': 0}
        for box in results.boxes:
            label = results.names[int(box.cls.item())]
            if label not in counters:
                continue
            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
            crop = im.crop((x1, y1, x2, y2))

            # ì €ì¥ ê²½ë¡œ ê²°ì •
            if label == 'plain text':
                folder = out_text
            elif label == 'figure':
                folder = out_fig
            else:  # 'table'
                folder = out_tab

            os.makedirs(folder, exist_ok=True)
            count = counters[label]
            save_path = os.path.join(folder, f"{os.path.splitext(fname)[0]}_{label}_{count}.png")
            crop.save(save_path)
            counters[label] += 1

        # ì§„í–‰ í‘œì‹œ
        progress.progress((idx+1)/total)
        status.text(f"ğŸ”„ {idx+1}/{total} ì²˜ë¦¬: {fname}")

    st.success(f"âœ… BeST ë ˆì´ì•„ì›ƒ ë¶„ì„ ë° í¬ë¡­ ì™„ë£Œ: ì´ {total}ì¥ ì²˜ë¦¬ë¨")


def apply_surya_ocr_to_BeST():
    figure_folder = BEST_INPUT_DIR
    surya_output_folder = os.path.join(BEST_DIR, "BeST_OCR")

    os.makedirs(surya_output_folder, exist_ok=True)

    # âœ… ê¸°ì¡´ OCR ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìƒëµ
    existing_jsons = [f for f in os.listdir(surya_output_folder) if f.endswith(".json")]
    if existing_jsons:
        st.info(f"â„¹ï¸ ì´ë¯¸ {len(existing_jsons)}ê°œì˜ OCR ê²°ê³¼ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. Surya OCR ìƒëµ.")
        return

    # âœ… ì…ë ¥ ì´ë¯¸ì§€ í™•ì¸
    image_files = [f for f in os.listdir(figure_folder) if f.lower().endswith(('.jpg', '.png'))]
    if not image_files:
        st.error("âŒ plain text ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    st.write("ğŸ”OCR ì‹¤í–‰ ì¤‘...")
    progress_bar = st.progress(0)
    status_text = st.empty()


    for idx, image_file in enumerate(image_files):
        input_path = os.path.join(figure_folder, image_file)
        command = ["surya_ocr", input_path]
        result = subprocess.run(command, capture_output=True, text=True)

        stderr = result.stderr.strip()
        if stderr and all(x not in stderr for x in ["Detecting bboxes", "Recognizing Text"]):
            st.warning(f"âš ï¸ ì˜¤ë¥˜: {image_file} â†’ {stderr}")

        progress = int((idx + 1) / len(image_files) * 100)
        progress_bar.progress(progress)
        status_text.write(f"ğŸ–¼ï¸ OCR ì‹¤í–‰ ì¤‘: {image_file} ({progress}%)")

    progress_bar.empty()
    status_text.write("âœ… OCR ì™„ë£Œ. ê²°ê³¼ ì´ë™ ì¤‘...")

    # âœ… ê²°ê³¼ ì´ë™
    moved, skipped = 0, 0
    for folder_name in os.listdir(SURYA_RESULTS_FOLDER):
        folder_path = os.path.join(SURYA_RESULTS_FOLDER, folder_name)
        if os.path.isdir(folder_path):
            json_file = os.path.join(folder_path, "results.json")
            if os.path.exists(json_file):
                dst_file = os.path.join(surya_output_folder, f"{folder_name}.json")
                try:
                    shutil.move(json_file, dst_file)
                    moved += 1
                except Exception as e:
                    st.error(f"âŒ Move Error: {folder_name} â†’ {e}")
            else:
                skipped += 1

    st.success(f"ğŸ“ OCR ê²°ê³¼ {moved}ê°œ ì´ë™ ì™„ë£Œ ({skipped}ê°œëŠ” ëˆ„ë½ë¨)")

#---------------------------------------------------------------------------





















##########################################################################################################
###########################################################################################################
#ì—¬ê¸°ì„œë¶€í„°ëŠ” Midas_Table í˜•ì‹





# def compute_iou(b1, b2):
#     x1 = max(b1[0], b2[0]); y1 = max(b1[1], b2[1])
#     x2 = min(b1[2], b2[2]); y2 = min(b1[3], b2[3])
#     inter_w = max(0, x2 - x1); inter_h = max(0, y2 - y1)
#     inter = inter_w * inter_h
#     area1 = (b1[2]-b1[0]) * (b1[3]-b1[1])
#     area2 = (b2[2]-b2[0]) * (b2[3]-b2[1])
#     union = area1 + area2 - inter
#     return inter/union if union>0 else 0

# # ê²¹ì¹˜ëŠ” ë°•ìŠ¤ ì œê±° (IoU > 0 ì¼ ë•Œ ì‘ì€ ê²ƒ ì œê±°)
# def filter_overlaps(boxes):
#     # boxes: list of [x1,y1,x2,y2]
#     # ë„“ì´ ìˆœ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
#     boxes_sorted = sorted(boxes, key=lambda b: (b[2]-b[0])*(b[3]-b[1]), reverse=True)
#     keep = []
#     for b in boxes_sorted:
#         if all(compute_iou(b, k)==0 for k in keep):
#             keep.append(b)
#     return keep

# def analyze_table_docs(conf_thresh=0.3, top_margin=200):


#     image_files = [f for f in os.listdir(TABLE_INPUT_DIR)
#                    if f.lower().endswith((".png",".jpg",".jpeg"))]
#     total = len(image_files)
#     progress_bar = st.progress(0); status_text = st.empty()

#     for idx, img_file in enumerate(image_files):
#         base = os.path.splitext(img_file)[0]
#         img_path = os.path.join(TABLE_INPUT_DIR, img_file)
#         image = Image.open(img_path).convert("RGB")

#         # 1) ë ˆì´ì•„ì›ƒ ë¶„ì„
#         results = yolo_model.predict(
#             img_path, imgsz=IMAGE_SIZE, conf=conf_thresh, iou=IOU_THRESH
#         )[0]

#         # 2) table ë°•ìŠ¤ë§Œ ëª¨ì•„ì„œ ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
#         raw_boxes = []
#         for box in results.boxes:
#             if results.names[int(box.cls.item())] == "table":
#                 raw_boxes.append(list(map(int, box.xyxy[0].tolist())))

#         # 3) ê²¹ì¹˜ëŠ” ê±´ ë„“ì´ ì œì¼ í° ê²ƒë§Œ ë‚¨ê¹€
#         filtered = filter_overlaps(raw_boxes)

#         # 4) í•„í„°ëœ ë°•ìŠ¤ í¬ë¡­+ë§ˆì§„ ì €ì¥
#         for i, (x1,y1,x2,y2) in enumerate(filtered):
#             y1m = max(0, y1 - top_margin)
#             crop = image.crop((x1, y1m, x2, y2))
#             crop.save(os.path.join(Table_crop, f"{base}_table_{i}.png"))

#         # 5) ì „ì²´ ë°•ìŠ¤ ì‹œê°í™”
#         vis_np = results.plot()
#         Image.fromarray(vis_np).save(os.path.join(TABLE_LATOUT, img_file))

#         # 6) ì§„í–‰ í‘œì‹œ
#         progress = (idx+1)/total
#         progress_bar.progress(progress)
#         status_text.text(f"{idx+1}/{total} ì²˜ë¦¬ ì¤‘: {img_file} (í¬ë¡­ëœ í…Œì´ë¸” {len(filtered)}ê°œ)")

#     progress_bar.empty()
#     status_text.success(f"TABLE {total}ê°œ ì™„ë£Œ â†’ ì‹œê°í™”:{TABLE_LATOUT}, í¬ë¡­:{Table_crop}")


# #########



# # âœ… 3. Surya OCR ì ìš© (ì§„í–‰ìƒí™© + ìºì‹œ í™•ì¸ + ê²°ê³¼ ì´ë™)
# def apply_surya_ocr_table():
#     SURYA_RESULTS_FOLDER = r"D:\streamlit_app\app\results\surya"
#     table_folder = Table_crop
#     surya_output_folder = os.path.join(Table_OCR)
#     os.makedirs(surya_output_folder, exist_ok=True)

#     # âœ… ê²°ê³¼ JSON íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì¬ì‹¤í–‰ ìƒëµ
#     existing_jsons = [f for f in os.listdir(surya_output_folder) if f.endswith(".json")]
#     if existing_jsons:
#         st.info(f"â„¹ï¸ ì´ë¯¸ {len(existing_jsons)}ê°œì˜ OCR ê²°ê³¼ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. Surya OCR ìƒëµ.")
#         return

#     image_files = [f for f in os.listdir(table_folder) if f.endswith(('.jpg', '.png'))]
#     if not image_files:
#         st.error("âŒ No files to apply OCR")
#         return

#     progress_bar = st.progress(0)
#     status_text = st.empty()
#     st.write("ğŸ”Running OCR...")

#     for idx, image_file in enumerate(image_files):
#         input_path = os.path.join(table_folder, image_file)
#         command = ["surya_ocr", input_path]
#         result = subprocess.run(command, capture_output=True, text=True)

#         stderr = result.stderr.strip()
#         if stderr and all(x not in stderr for x in ["Detecting bboxes", "Recognizing Text"]):
#             st.warning(f"âš ï¸ ì˜¤ë¥˜: {image_file} â†’ {stderr}")

#         progress = int((idx + 1) / len(image_files) * 100)
#         progress_bar.progress(progress)
#         status_text.write(f"ğŸ–¼ï¸ running ocr: {image_file} ({progress}%)")

#     progress_bar.empty()
#     status_text.write("âœ… OCR complete! Result moving...")

#     moved, skipped = 0, 0
#     for folder_name in os.listdir(SURYA_RESULTS_FOLDER):
#         folder_path = os.path.join(SURYA_RESULTS_FOLDER, folder_name)
#         if os.path.isdir(folder_path):
#             json_file = os.path.join(folder_path, "results.json")
#             if os.path.exists(json_file):
#                 dst_file = os.path.join(surya_output_folder, f"{folder_name}.json")
#                 try:
#                     shutil.move(json_file, dst_file)
#                     moved += 1
#                 except Exception as e:
#                     st.error(f"âŒ Move Error: {folder_name} â†’ {e}")
#             else:
#                 skipped += 1

#     st.success(f"ğŸ“ OCR ê²°ê³¼ {moved}ê°œ ì´ë™ ì™„ë£Œ ({skipped}ê°œëŠ” ëˆ„ë½ë¨)")


# #--------------------------------------------------------------
# def split_by_keywords(json_path, keywords, output_dir):
#     """
#     json_path: ì²˜ë¦¬í•  OCR JSON íŒŒì¼ ê²½ë¡œ
#     keywords: ['MEMB=', 'Wall mark :', ...] í˜•íƒœì˜ ë¶„í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
#     output_dir: ë¶„í• ëœ JSONì„ ì €ì¥í•  í´ë”
#     """
#     with open(json_path, encoding='utf-8') as f:
#         data = json.load(f)
#     key = next(iter(data))
#     entry = data[key][0]
#     lines = entry['text_lines']

#     # boundaries: [(index, label_text), ...]
#     boundaries = []
#     for idx, item in enumerate(lines):
#         text = item['text']
#         for kw in keywords:
#             if kw in text:
#                 label = text.split(kw, 1)[1].strip()
#                 boundaries.append((idx, label))
#                 break

#     # í‚¤ì›Œë“œê°€ í•˜ë‚˜ë„ ì•ˆ ê±¸ë¦¬ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ ì €ì¥
#     if not boundaries:
#         base = os.path.splitext(os.path.basename(json_path))[0]
#         dst = os.path.join(output_dir, f"{base}_full.json")
#         os.makedirs(output_dir, exist_ok=True)
#         with open(dst, 'w', encoding='utf-8') as wf:
#             json.dump(data, wf, ensure_ascii=False, indent=2)
#         return

#     # ê° êµ¬ê°„ë³„ë¡œ slice & save
#     for i, (start, label) in enumerate(boundaries):
#         end = boundaries[i+1][0] if i+1 < len(boundaries) else len(lines)
#         segment = lines[start:end]

#         new_entry = {k: v for k, v in entry.items() if k != 'text_lines'}
#         new_entry['text_lines'] = segment
#         out_data = { key: [ new_entry ] }

#         safe_label = re.sub(r'[^\w\-]', '_', label)
#         base = os.path.splitext(os.path.basename(json_path))[0]
#         out_name = f"{base}_{safe_label}.json"

#         os.makedirs(output_dir, exist_ok=True)
#         with open(os.path.join(output_dir, out_name), 'w', encoding='utf-8') as wf:
#             json.dump(out_data, wf, ensure_ascii=False, indent=2)







# def process_table_ocr_splits(keywords, input_dir, output_dir, margin=0):
#     input_dir     = os.path.join(TABLE_DIR, "table_OCR")
#     output_dir    = os.path.join(TABLE_DIR, "table_OCR_split")       
#     os.makedirs(output_dir, exist_ok=True)
#     file_count = 0

#     # Gather and sort JSON files by page number
#     file_paths = sorted(
#         glob.glob(os.path.join(input_dir, "*.json")),
#         key=lambda fp: int(re.search(r"page_(\d+)", os.path.basename(fp), re.IGNORECASE).group(1))
#     )

#     # Pattern for extra info (floor, rebar)
#     extra_pattern = re.compile(r"\b(?:B\d+|PIT|\d+F)\b|@\d+", re.IGNORECASE)

#     carryover_id = None
#     carryover_lines = []
#     prev_base = None

#     for json_path in tqdm(file_paths, desc="Splitting OCR files"):
#         base = os.path.splitext(os.path.basename(json_path))[0]
#         with open(json_path, 'r', encoding='utf-8') as f:
#             data = json.load(f)
#         root = next(iter(data.values()))[0]
#         lines = root.get('text_lines', [])

#         # Detect boundary lines and identifiers
#         boundaries = []  # [(index, identifier), ...]
#         for idx_line, line in enumerate(lines):
#             text = line.get('text', '')
#             for kw in keywords:
#                 if re.search(rf"\b{re.escape(kw)}\b", text, re.IGNORECASE):
#                     parts = re.split(r"[:=]", text, 1)
#                     if len(parts) > 1:
#                         ident = parts[1].strip().split()[0]
#                         boundaries.append((idx_line, ident))
#                     break

#         # Collect prefix_extra indices and lines before first boundary
#         prefix_indices = []
#         prefix_extra = []
#         if boundaries:
#             first_idx = boundaries[0][0]
#             for i in range(first_idx):
#                 if extra_pattern.search(lines[i].get('text', '')):
#                     prefix_indices.append(i)
#                     prefix_extra.append(lines[i])
#         else:
#             # No boundary: if carryover exists, collect extra lines for next flush
#             if carryover_id:
#                 carryover_lines.extend([l for l in lines if extra_pattern.search(l.get('text',''))])
#             prev_base = base
#             continue

#         # Flush carryover if identifier changed
#         first_ident = boundaries[0][1]
#         if carryover_id and first_ident != carryover_id:
#             flush_lines = carryover_lines + prefix_extra
#             safe_label = re.sub(r"[^\w\-]", "_", carryover_id)
#             out_name = f"{prev_base}_{safe_label}.json"
#             with open(os.path.join(output_dir, out_name), 'w', encoding='utf-8') as wf:
#                 json.dump({prev_base:[{'text_lines':flush_lines}]}, wf, ensure_ascii=False, indent=2)
#             file_count += 1
#             carryover_id, carryover_lines = None, []

#         # Build segments for this file
#         idxs = [b[0] for b in boundaries] + [len(lines)]
#         segments = []
#         for i, (_, ident) in enumerate(boundaries):
#             start, end = idxs[i], idxs[i+1]
#             # exclude prefix_extra indices from first segment
#             seg_lines = [lines[j] for j in range(start, end) if j not in prefix_indices]
#             if seg_lines:
#                 segments.append((ident, seg_lines))

#         # Save all but last segment
#         for ident, seg_lines in segments[:-1]:
#             safe_label = re.sub(r"[^\w\-]", "_", ident)
#             out_name = f"{base}_{safe_label}.json"
#             with open(os.path.join(output_dir, out_name), 'w', encoding='utf-8') as wf:
#                 json.dump({base:[{'text_lines':seg_lines}]}, wf, ensure_ascii=False, indent=2)
#             file_count += 1

#         # Last segment becomes carryover
#         if segments:
#             carryover_id, carryover_lines = segments[-1]
#         prev_base = base

#     # Flush any remaining carryover
#     if carryover_id and carryover_lines:
#         safe_label = re.sub(r"[^\w\-]", "_", carryover_id)
#         out_name = f"{prev_base}_{safe_label}.json"
#         with open(os.path.join(output_dir, out_name), 'w', encoding='utf-8') as wf:
#             json.dump({prev_base:[{'text_lines':carryover_lines}]}, wf, ensure_ascii=False, indent=2)
#         file_count += 1

#     return file_count


# def extract_floor_info(split_dir, csv_path):
#     floor_pattern = re.compile(r"\b(?:\d+F|B\d+|PIT)\b", re.IGNORECASE)
#     rows = []
#     for fn in sorted(os.listdir(split_dir)):
#         if not fn.lower().endswith('.json'):
#             continue
#         fp = os.path.join(split_dir, fn)
#         with open(fp,'r',encoding='utf-8') as f:
#             data = json.load(f)
#         key = next(iter(data))
#         for entry in data[key]:
#             for line in entry.get('text_lines', []):
#                 text = line.get('text','')
#                 for m in floor_pattern.findall(text):
#                     rows.append({'file':fn,'floor':m,'text':text})
#     with open(csv_path,'w',newline='',encoding='utf-8') as csvfile:
#         writer = csv.DictWriter(csvfile, fieldnames=['file','floor','text'])
#         writer.writeheader()
#         writer.writerows(rows)
#     return len(rows)

# # â”€â”€â”€ 3) ì¤„ ë‹¨ìœ„ í…Œì´ë¸” ì¶”ì¶œ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# def extract_table_rows(json_path, y_tol=10):
#     """Extract rows from a single table JSON by clustering text_lines by y-center"""
#     with open(json_path, encoding='utf-8') as f:
#         data = json.load(f)
#     lines = next(iter(data.values()))[0]['text_lines']
#     # compute y-centers
#     items = []
#     for ln in lines:
#         x1,y1,x2,y2 = ln['bbox']
#         items.append({'y':(y1+y2)/2, 'x':x1, 'text':ln['text']})
#     if not items:
#         return []
#     # sort by y
#     items.sort(key=lambda i: i['y'])
#     rows = []
#     current = [items[0]]
#     for it in items[1:]:
#         avg_y = sum(i['y'] for i in current)/len(current)
#         if abs(it['y']-avg_y) <= y_tol:
#             current.append(it)
#         else:
#             rows.append(current)
#             current = [it]
#     rows.append(current)
#     # combine texts sorted by x
#     combined = []
#     for row in rows:
#         row.sort(key=lambda i: i['x'])
#         combined.append(' '.join(i['text'] for i in row))
#     return combined


# def smart_split(line: str) -> list:
#     """
#     Split a line by whitespace outside of parentheses,
#     so tokens like 'Vu(kN,LCB, iWAL, Lw)' stay intact.
#     """
#     tokens = []
#     buf = ''
#     depth = 0
#     for ch in line:
#         if ch == '(':
#             depth += 1
#             buf += ch
#         elif ch == ')':
#             depth -= 1
#             buf += ch
#         elif ch.isspace() and depth == 0:
#             if buf:
#                 tokens.append(buf)
#                 buf = ''
#         else:
#             buf += ch
#     if buf:
#         tokens.append(buf)
#     return tokens

# # ===================== ì£¼ìš” í•¨ìˆ˜ =====================
# def smart_split(line: str) -> list:
#     """
#     ê´„í˜¸ ë°– ê³µë°±ë§Œ ë¶„ë¦¬í•˜ì—¬ ( ) ë‚´ë¶€ëŠ” í•˜ë‚˜ì˜ í† í°ìœ¼ë¡œ ìœ ì§€
#     """
#     tokens, buf, depth = [], '', 0
#     for ch in line:
#         if ch == '(':
#             depth += 1; buf += ch
#         elif ch == ')':
#             depth -= 1; buf += ch
#         elif ch.isspace() and depth == 0:
#             if buf:
#                 tokens.append(buf)
#                 buf = ''
#         else:
#             buf += ch
#     if buf:
#         tokens.append(buf)
#     return tokens

# # ===================== ì£¼ìš” í•¨ìˆ˜ =====================
# def process_csv_to_excel(csv_path: str, excel_path: str) -> int:
#     """
#     CSVì—ì„œ í…Œì´ë¸” ë¸”ë¡(ë©”íƒ€ë°ì´í„°+í—¤ë”+ë°ì´í„°)ì„ ì¶”ì¶œí•˜ì—¬
#     ìŠ¤ë§ˆíŠ¸ ë¶„ë¦¬ í›„ ê´„í˜¸ì™€ ì  ì²˜ë¦¬ ê·œì¹™ ì ìš©, ì—‘ì…€ë¡œ ì €ì¥

#     Args:
#         csv_path: ì…ë ¥ CSV ê²½ë¡œ (text ì»¬ëŸ¼ í˜¹ì€ ë§ˆì§€ë§‰ ì»¬ëŸ¼ ì‚¬ìš©)
#         excel_path: ì¶œë ¥ Excel ê²½ë¡œ

#     Returns:
#         ì‘ì„±ëœ ì‹œíŠ¸ ìˆ˜
#     """
#     # CSV ë¡œë“œ ë° í…ìŠ¤íŠ¸ ë¼ì¸ í™•ë³´
#     df_raw = pd.read_csv(csv_path)
#     lines = df_raw['text'].astype(str).tolist() if 'text' in df_raw.columns else df_raw.iloc[:, -1].astype(str).tolist()

#     # íŒ¨í„´ ì •ì˜
#     header_pat = re.compile(r"STO\s+HTw", re.IGNORECASE)
#     eq_pat     = re.compile(r"\*\.\s*(.*?)\s*=\s*(.*)")
#     col_pat    = re.compile(r"\*\.\s*(.*?)\s*:\s*(.*)")
#     floor_pat  = re.compile(r'^(?:\d+F|B\d+|PIT)', re.IGNORECASE)

#     # í—¤ë” ìœ„ì¹˜ ì°¾ê¸°
#     header_idxs = [i for i, ln in enumerate(lines) if header_pat.search(ln)]
#     if not header_idxs:
#         raise ValueError("STO HTw í—¤ë”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

#     # ExcelWriter ì‚¬ìš©
#     with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:
#         sheet_count = 0
#         for idx_num, h_idx in enumerate(header_idxs):
#             # 1) í—¤ë” í† í°í™”
#             headers = smart_split(lines[h_idx].strip())

#                         # 2) ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘: í—¤ë”ëª…ê³¼ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” í‚¤ë§Œ, í—¤ë” ìœ„ ìµœëŒ€ 5ì¤„ ê²€ì‚¬
#             meta = {}
#             for lookback in range(max(0, h_idx-5), h_idx):
#                 line = lines[lookback].strip()
#                 m = eq_pat.match(line) or col_pat.match(line)
#                 if m:
#                     key, val = m.group(1).strip(), m.group(2).strip()
#                     if key not in headers:
#                         meta[key] = val

#             # 3) ë°ì´í„° ë¸”ë¡ ë²”ìœ„ ì„¤ì •
#             next_h = header_idxs[idx_num + 1] if idx_num + 1 < len(header_idxs) else len(lines)
#             data_rows = []

#             # 4) ë°ì´í„° í–‰ ì²˜ë¦¬
#             for ln in lines[h_idx + 1:next_h]:
#                 txt = ln.strip()
#                 if not txt or eq_pat.match(txt) or col_pat.match(txt) or header_pat.search(txt):
#                     continue
#                 parts = smart_split(txt)
#                 # (1) ë‹¨ë… ì  ì œê±°
#                 parts = [p for p in parts if p != '.']
#                 # (2) ê´„í˜¸ ì»¬ëŸ¼ ë³‘í•©
#                 for i, col in enumerate(headers):
#                     if '(' in col and ')' in col and i < len(parts) - 1 and parts[i + 1].startswith('('):
#                         parts[i] = f"{parts[i]} {parts[i+1]}"
#                         del parts[i+1]
#                 # (3) ì +ê´„í˜¸ ë³‘í•©
#                 k = 0
#                 while k < len(parts) - 1:
#                     if parts[k].endswith('.') and parts[k+1].startswith('('):
#                         parts[k] = f"{parts[k]} {parts[k+1]}"
#                         del parts[k+1]
#                         continue
#                     k += 1
#                 # (4) ë¶„ë¦¬ëœ ì  ë³‘í•© (400 . D10@300)
#                 i2 = 1
#                 while i2 < len(parts) - 1:
#                     if parts[i2] == '.':
#                         prev_tok, next_tok = parts[i2 - 1], parts[i2 + 1]
#                         if not next_tok.startswith(('(', ',')):
#                             parts[i2 - 1:i2 + 2] = [f"{prev_tok}.", next_tok]
#                             i2 += 2
#                             continue
#                     i2 += 1
#                 # (5) mid-word ì  ë¶„í• 
#                 j = 0
#                 while j < len(parts) - 1:
#                     tok = parts[j]
#                     if j < len(headers) - 1 and re.search(r"\w\.\w", tok):
#                         left, right = tok.split('.', 1)
#                         if not right.startswith(('(', ',')):
#                             parts[j:j+1] = [f"{left}." if tok.endswith('.') else left, right]
#                             j += 2
#                             continue
#                     j += 1
#                 # (6) ì¹¼ëŸ¼ ìˆ˜ ë§ì¶”ê¸°
#                 if len(parts) > len(headers):
#                     parts = parts[:len(headers) - 1] + [' '.join(parts[len(headers) - 1:])]
#                 elif len(parts) < len(headers):
#                     parts += [''] * (len(headers) - len(parts))
#                 # (7) ì¸µìˆ˜ ì—†ëŠ” í–‰ ìŠ¤í‚µ
#                 if not floor_pat.match(parts[0]):
#                     continue
#                 data_rows.append(parts)

#             # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
#             if not data_rows:
#                 continue

#             # DataFrame ìƒì„± ë° ë©”íƒ€ë°ì´í„° ê²°í•©
#             df = pd.DataFrame(data_rows, columns=headers)
#             for k, v in meta.items():
#                 df[k] = v

#             # 5) ì‹œíŠ¸ëª… ì„¤ì •: MEMB ìš°ì„ , ì—†ìœ¼ë©´ Wall Mark
#             memb_key = next((k for k in meta if k.lower() == 'memb'), None)
#             wm_key = next((k for k in meta if k.lower() == 'wall mark'), None)
#             if memb_key:
#                 sheet_name = meta[memb_key].split()[0].lower()
#             elif wm_key:
#                 sheet_name = meta[wm_key].split()[0]
#             else:
#                 sheet_name = f"Table{idx_num+1}"

#             # ì—‘ì…€ ì‹œíŠ¸ ì‘ì„±
#             df.to_excel(writer, sheet_name=sheet_name[:31], index=False)
#             sheet_count += 1

#         return sheet_count



# def export_summary_csv(excel_path: str, summary_csv_path: str) -> int:
#     """
#     ìƒì„±ëœ Excel íŒŒì¼ì„ ì½ì–´ ê° ì‹œíŠ¸ë³„ë¡œ ìš”ì•½ ì •ë³´ë¥¼ CSVë¡œ ì €ì¥
#     """
#     xls = pd.ExcelFile(excel_path)
#     rows = []
#     for sheet in xls.sheet_names:
#         df = pd.read_excel(xls, sheet_name=sheet)
#         if 'STO' in df.columns and 'hw' in df.columns and 'V-Rebar' in df.columns and 'H-Rebar' in df.columns and 'fy' in df.columns and 'fck' in df.columns:
#             for _, r in df.iterrows():
#                 rows.append({
#                     'ë¶€ì¬ëª…': sheet,
#                     'ì¸µìˆ˜': r['STO'],
#                     'ë‘ê»˜': r['hw'],
#                     'ìˆ˜ì§ì² ê·¼': r['V-Rebar'],
#                     'ìˆ˜í‰ì² ê·¼': r['H-Rebar'],
#                     'fy': r['fy'],
#                     'fck': r['fck'],
#                 })
#     pd.DataFrame(rows).to_csv(summary_csv_path, index=False)
#     return len(rows)





def compute_iou(b1, b2):
    x1 = max(b1[0], b2[0]); y1 = max(b1[1], b2[1])
    x2 = min(b1[2], b2[2]); y2 = min(b1[3], b2[3])
    inter_w = max(0, x2 - x1); inter_h = max(0, y2 - y1)
    inter = inter_w * inter_h
    area1 = (b1[2]-b1[0]) * (b1[3]-b1[1])
    area2 = (b2[2]-b2[0]) * (b2[3]-b2[1])
    union = area1 + area2 - inter
    return inter/union if union>0 else 0

# ê²¹ì¹˜ëŠ” ë°•ìŠ¤ ì œê±° (IoU > 0 ì¼ ë•Œ ì‘ì€ ê²ƒ ì œê±°)
def filter_overlaps(boxes):
    boxes_sorted = sorted(boxes, key=lambda b: (b[2]-b[0])*(b[3]-b[1]), reverse=True)
    keep = []
    for b in boxes_sorted:
        if all(compute_iou(b, k)==0 for k in keep):
            keep.append(b)
    return keep

# ìƒˆë¡œ ì¶”ê°€: ì‚¬ë¶„ë©´(ì¢Œìƒ, ì¢Œí•˜, ìš°ìƒ, ìš°í•˜) ìˆœ ì •ë ¬
def sort_by_quadrant(boxes, img_width, img_height):
    mid_x, mid_y = img_width / 2, img_height / 2

    def quadrant(b):
        x1, y1, x2, y2 = b
        cx, cy = (x1 + x2) / 2, (y1 + y2) / 2
        # 0: ì¢Œìƒ, 1: ì¢Œí•˜, 2: ìš°ìƒ, 3: ìš°í•˜
        if cx < mid_x and cy < mid_y:
            return 0
        if cx < mid_x and cy >= mid_y:
            return 1
        if cx >= mid_x and cy < mid_y:
            return 2
        return 3

    return sorted(boxes, key=lambda b: (quadrant(b), b[1], b[0]))

def analyze_table_docs(conf_thresh=0.3, top_margin=200):
    image_files = [f for f in os.listdir(TABLE_INPUT_DIR)
                   if f.lower().endswith((".png",".jpg",".jpeg"))]
    total = len(image_files)
    progress_bar = st.progress(0); status_text = st.empty()

    for idx, img_file in enumerate(image_files):
        base = os.path.splitext(img_file)[0]
        img_path = os.path.join(TABLE_INPUT_DIR, img_file)
        image = Image.open(img_path).convert("RGB")

        # 1) ë ˆì´ì•„ì›ƒ ë¶„ì„
        results = yolo_model.predict(
            img_path, imgsz=IMAGE_SIZE, conf=conf_thresh, iou=IOU_THRESH
        )[0]

        # 2) table ë°•ìŠ¤ë§Œ ëª¨ì•„ì„œ ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        raw_boxes = []
        for box in results.boxes:
            if results.names[int(box.cls.item())] == "table":
                raw_boxes.append(list(map(int, box.xyxy[0].tolist())))

        # 3) ê²¹ì¹˜ëŠ” ê±´ ë„“ì´ ì œì¼ í° ê²ƒë§Œ ë‚¨ê¹€
        filtered = filter_overlaps(raw_boxes)

        # â†’ 3.1) ì‚¬ë¶„ë©´ ìˆœìœ¼ë¡œ ì¬ì •ë ¬
        w, h = image.width, image.height
        ordered = sort_by_quadrant(filtered, w, h)

        # 4) ğŸ”¥ íŒŒì¼ëª… ì¼ê´€ì„± ê°œì„  ğŸ”¥
        page_num = idx + 1  # 1ë¶€í„° ì‹œì‘í•˜ëŠ” í˜ì´ì§€ ë²ˆí˜¸
        for i, (x1, y1, x2, y2) in enumerate(ordered, start=1):
            y1m = max(0, y1 - top_margin)
            crop = image.crop((x1, y1m, x2, y2))
            # ì¼ê´€ëœ íŒŒì¼ëª…: page_1_table_1.png
            filename = f"page_{page_num}_table_{i}.png"
            crop.save(os.path.join(Table_crop, filename))

        # 5) ì „ì²´ ë°•ìŠ¤ ì‹œê°í™”
        vis_np = results.plot()
        Image.fromarray(vis_np).save(os.path.join(TABLE_LATOUT, img_file))

        # 6) ì§„í–‰ í‘œì‹œ
        progress = (idx+1)/total
        progress_bar.progress(progress)
        status_text.text(f"{idx+1}/{total} ì²˜ë¦¬ ì¤‘: {img_file} (í¬ë¡­ëœ í…Œì´ë¸” {len(ordered)}ê°œ)")

    progress_bar.empty()
    status_text.success(f"TABLE {total}ê°œ ì™„ë£Œ â†’ ì‹œê°í™”:{TABLE_LATOUT}, í¬ë¡­:{Table_crop}")

#########



# âœ… 3. Surya OCR ì ìš© (ì§„í–‰ìƒí™© + ìºì‹œ í™•ì¸ + ê²°ê³¼ ì´ë™)
def apply_surya_ocr_table():
    table_folder = Table_crop
    surya_output_folder = os.path.join(Table_OCR)
    os.makedirs(surya_output_folder, exist_ok=True)

    # âœ… ê²°ê³¼ JSON íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì¬ì‹¤í–‰ ìƒëµ
    existing_jsons = [f for f in os.listdir(surya_output_folder) if f.endswith(".json")]
    if existing_jsons:
        st.info(f"â„¹ï¸ ì´ë¯¸ {len(existing_jsons)}ê°œì˜ OCR ê²°ê³¼ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. Surya OCR ìƒëµ.")
        return

    image_files = [f for f in os.listdir(table_folder) if f.endswith(('.jpg', '.png'))]
    if not image_files:
        st.error("âŒ No files to apply OCR")
        return

    progress_bar = st.progress(0)
    status_text = st.empty()
    st.write("ğŸ”Running OCR...")

    for idx, image_file in enumerate(image_files):
        input_path = os.path.join(table_folder, image_file)
        command = ["surya_ocr", input_path]
        result = subprocess.run(command, capture_output=True, text=True)

        stderr = result.stderr.strip()
        if stderr and all(x not in stderr for x in ["Detecting bboxes", "Recognizing Text"]):
            st.warning(f"âš ï¸ ì˜¤ë¥˜: {image_file} â†’ {stderr}")

        progress = int((idx + 1) / len(image_files) * 100)
        progress_bar.progress(progress)
        status_text.write(f"ğŸ–¼ï¸ running ocr: {image_file} ({progress}%)")

    progress_bar.empty()
    status_text.write("âœ… OCR complete! Result moving...")

    moved, skipped = 0, 0
    for folder_name in os.listdir(SURYA_RESULTS_FOLDER):
        folder_path = os.path.join(SURYA_RESULTS_FOLDER, folder_name)
        if os.path.isdir(folder_path):
            json_file = os.path.join(folder_path, "results.json")
            if os.path.exists(json_file):
                dst_file = os.path.join(surya_output_folder, f"{folder_name}.json")
                try:
                    shutil.move(json_file, dst_file)
                    moved += 1
                except Exception as e:
                    st.error(f"âŒ Move Error: {folder_name} â†’ {e}")
            else:
                skipped += 1

    st.success(f"ğŸ“ OCR ê²°ê³¼ {moved}ê°œ ì´ë™ ì™„ë£Œ ({skipped}ê°œëŠ” ëˆ„ë½ë¨)")


#--------------------------------------------------------------
def split_by_keywords(json_path, keywords, output_dir):
    """
    json_path: ì²˜ë¦¬í•  OCR JSON íŒŒì¼ ê²½ë¡œ
    keywords: ['MEMB=', 'Wall mark :', ...] í˜•íƒœì˜ ë¶„í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
    output_dir: ë¶„í• ëœ JSONì„ ì €ì¥í•  í´ë”
    """
    with open(json_path, encoding='utf-8') as f:
        data = json.load(f)
    key = next(iter(data))
    entry = data[key][0]
    lines = entry['text_lines']

    # boundaries: [(index, label_text), ...]
    boundaries = []
    for idx, item in enumerate(lines):
        text = item['text']
        for kw in keywords:
            if kw in text:
                label = text.split(kw, 1)[1].strip()
                boundaries.append((idx, label))
                break

    # í‚¤ì›Œë“œê°€ í•˜ë‚˜ë„ ì•ˆ ê±¸ë¦¬ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ ì €ì¥
    if not boundaries:
        base = os.path.splitext(os.path.basename(json_path))[0]
        dst = os.path.join(output_dir, f"{base}_full.json")
        os.makedirs(output_dir, exist_ok=True)
        with open(dst, 'w', encoding='utf-8') as wf:
            json.dump(data, wf, ensure_ascii=False, indent=2)
        return

    # ê° êµ¬ê°„ë³„ë¡œ slice & save
    for i, (start, label) in enumerate(boundaries):
        end = boundaries[i+1][0] if i+1 < len(boundaries) else len(lines)
        segment = lines[start:end]

        new_entry = {k: v for k, v in entry.items() if k != 'text_lines'}
        new_entry['text_lines'] = segment
        out_data = { key: [ new_entry ] }

        safe_label = re.sub(r'[^\w\-]', '_', label)
        base = os.path.splitext(os.path.basename(json_path))[0]
        out_name = f"{base}_{safe_label}.json"

        os.makedirs(output_dir, exist_ok=True)
        with open(os.path.join(output_dir, out_name), 'w', encoding='utf-8') as wf:
            json.dump(out_data, wf, ensure_ascii=False, indent=2)


#--------------------------------------------------------------------------------------

def filter_ocr_by_keywords(keywords, input_dir=None, output_dir=None):
    """
    ì‚¬ìš©ì í‚¤ì›Œë“œê°€ í¬í•¨ëœ OCR íŒŒì¼ë“¤ë§Œ í•„í„°ë§í•´ì„œ ë³„ë„ í´ë”ì— ì €ì¥
    
    Args:
        keywords: í•„í„°ë§í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['MEMB', 'Wall Mark'])
        input_dir: OCR JSON íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë” ê²½ë¡œ
        output_dir: í•„í„°ë§ëœ íŒŒì¼ë“¤ì„ ì €ì¥í•  í´ë” ê²½ë¡œ
    
    Returns:
        tuple: (í•„í„°ë§ëœ íŒŒì¼ ìˆ˜, ì „ì²´ íŒŒì¼ ìˆ˜)
    """
    if input_dir is None:
        input_dir = os.path.join(TABLE_DIR, "table_OCR")
    if output_dir is None:
        output_dir = os.path.join(TABLE_DIR, "table_OCR_filtered")
    
    # ì¶œë ¥ í´ë” ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    # ê¸°ì¡´ í•„í„°ë§ëœ íŒŒì¼ë“¤ ì‚­ì œ (ìƒˆë¡œìš´ í•„í„°ë§ ì‹œì‘)
    for existing_file in os.listdir(output_dir):
        if existing_file.endswith('.json'):
            os.remove(os.path.join(output_dir, existing_file))
    
    # JSON íŒŒì¼ë“¤ ê²€ì‚¬
    json_files = [f for f in os.listdir(input_dir) if f.endswith('.json')]
    filtered_count = 0
    total_count = len(json_files)
    
    print(f"ì´ {total_count}ê°œ íŒŒì¼ ê²€ì‚¬ ì‹œì‘...")
    print(f"í•„í„°ë§ í‚¤ì›Œë“œ: {keywords}")
    
    for json_file in json_files:
        json_path = os.path.join(input_dir, json_file)
        
        try:
            # JSON íŒŒì¼ ì½ê¸°
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
            all_text = ""
            for page_key, page_data in data.items():
                if isinstance(page_data, list) and len(page_data) > 0:
                    text_lines = page_data[0].get('text_lines', [])
                    for line in text_lines:
                        all_text += line.get('text', '') + " "
            
            # í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸
            has_keyword = False
            found_keywords = []
            
            for keyword in keywords:
                if re.search(rf"\b{re.escape(keyword)}\b", all_text, re.IGNORECASE):
                    has_keyword = True
                    found_keywords.append(keyword)
            
            # í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ í•„í„°ë§ëœ í´ë”ì— ë³µì‚¬
            if has_keyword:
                dest_path = os.path.join(output_dir, json_file)
                shutil.copy2(json_path, dest_path)
                filtered_count += 1
                print(f"âœ“ {json_file} -> í‚¤ì›Œë“œ ë°œê²¬: {found_keywords}")
            else:
                print(f"âœ— {json_file} -> í‚¤ì›Œë“œ ì—†ìŒ, ì œì™¸")
                
        except Exception as e:
            print(f"ì˜¤ë¥˜ - {json_file}: {e}")
            continue
    
    print(f"\ní•„í„°ë§ ì™„ë£Œ:")
    print(f"ì „ì²´ íŒŒì¼: {total_count}ê°œ")
    print(f"í•„í„°ë§ëœ íŒŒì¼: {filtered_count}ê°œ")
    print(f"ì œì™¸ëœ íŒŒì¼: {total_count - filtered_count}ê°œ")
    print(f"ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_dir}")
    
    return filtered_count, total_count





















def process_table_ocr_splits(keywords, input_dir=None, output_dir=None, margin=0):
    """
    ì—°ì†ëœ í…Œì´ë¸” ë²ˆí˜¸ì™€ ì½˜í…ì¸  ê¸°ë°˜ ì—°ì†ì„± ë¶„ì„ì„ í†µí•œ OCR ë³‘í•© í•¨ìˆ˜
    
    ë³‘í•© ê·œì¹™:
    1. ë™ì¼ í˜ì´ì§€: table_x â†’ table_x+1 ì—°ì† ë²ˆí˜¸
    2. í˜ì´ì§€ ê°„: page_y ë§ˆì§€ë§‰ table â†’ page_y+1 ì²« table
    3. ë©ì–´ë¦¬ ì¸ì‹ ì‹œ: ê°€ì¥ í•˜ë‹¨/ìƒë‹¨ ë¶€ì¬ í‚¤ì›Œë“œ ê¸°ì¤€ìœ¼ë¡œ ì—°ê²°ì  ì°¾ê¸°
    """
    
    if input_dir is None:
        input_dir = os.path.join(TABLE_DIR, "table_OCR_filtered")
    if output_dir is None:
        output_dir = os.path.join(TABLE_DIR, "table_OCR_split")
    
    os.makedirs(output_dir, exist_ok=True)
    
    def clean_math_tags(text):
        """MathML íƒœê·¸ ì œê±°"""
        text = re.sub(r'<math[^>]*>(.*?)</math>', r'\1', text)
        text = re.sub(r'<[^>]+>', '', text)
        text = re.sub(r'\\[a-zA-Z]+\{([^}]+)\}', r'\1', text)
        text = re.sub(r'\\[a-zA-Z]+', '', text)
        return text.strip()
    
    def parse_filename(filename):
        """íŒŒì¼ëª…ì—ì„œ í˜ì´ì§€, í…Œì´ë¸” ë²ˆí˜¸ ì¶”ì¶œ"""
        pattern = r"page_(\d+)_(?:Table_\d+_)?table_(\d+)"
        match = re.search(pattern, filename)
        if match:
            return {
                'page_num': int(match.group(1)),
                'table_num': int(match.group(2)),
                'filename': filename
            }
        return None
    
    def get_member_positions(json_path, keywords):
        """OCRì—ì„œ ë¶€ì¬ í‚¤ì›Œë“œ ìœ„ì¹˜ ì¶”ì¶œ"""
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        root = next(iter(data.values()))[0]
        lines = root.get('text_lines', [])
        
        member_positions = []
        data_lines = []
        
        for line in lines:
            text = clean_math_tags(line.get('text', ''))
            y_center = (line['bbox'][1] + line['bbox'][3]) / 2
            
            # ë¶€ì¬ í‚¤ì›Œë“œ ì°¾ê¸°
            member_found = None
            for kw in keywords:
                if re.search(rf"\b{re.escape(kw)}\b", text, re.IGNORECASE):
                    parts = re.split(r"[:=]", text, 1)
                    if len(parts) > 1:
                        member_id = parts[1].strip().split()[0]
                        if member_id:
                            member_found = member_id
                            break
            
            if member_found:
                member_positions.append({
                    'member_id': member_found,
                    'y_position': y_center,
                    'text': text
                })
            else:
                # í…Œì´ë¸” ë°ì´í„° ë¼ì¸
                if re.search(r'[A-Za-z0-9]', text) and len(text.strip()) > 3:
                    data_lines.append({
                        'y_position': y_center,
                        'text': text
                    })
        
        return member_positions, data_lines
    
    def check_connection(source_analysis, target_analysis):
        """ë‘ í…Œì´ë¸” ê°„ ì—°ê²° ê°€ëŠ¥ì„± í™•ì¸"""
        source_members, source_data = source_analysis
        target_members, target_data = target_analysis
        
        if not source_members or not target_members:
            return False, None, None
        
        # sourceì—ì„œ ê°€ì¥ í•˜ë‹¨ ë¶€ì¬ í‚¤ì›Œë“œ
        bottom_member = max(source_members, key=lambda x: x['y_position'])
        
        # targetì—ì„œ ê°€ì¥ ìƒë‹¨ ë¶€ì¬ í‚¤ì›Œë“œ  
        top_member = min(target_members, key=lambda x: x['y_position'])
        
        # 1. source í•˜ë‹¨ ë¶€ì¬ ì•„ë˜ì— ë°ì´í„° ìˆëŠ”ì§€
        data_after_bottom = [d for d in source_data 
                           if d['y_position'] > bottom_member['y_position']]
        
        # 2. source í•˜ë‹¨ ë¶€ì¬ ì•„ë˜ì— ë‹¤ë¥¸ ë¶€ì¬ í‚¤ì›Œë“œ ì—†ëŠ”ì§€
        other_members_below = [m for m in source_members 
                             if m['y_position'] > bottom_member['y_position']]
        
        # 3. target ìƒë‹¨ ë¶€ì¬ ìœ„ì— ë°ì´í„° ìˆëŠ”ì§€
        data_before_top = [d for d in target_data 
                         if d['y_position'] < top_member['y_position']]
        
        can_connect = (len(data_after_bottom) > 0 and 
                      len(other_members_below) == 0 and 
                      len(data_before_top) > 0)
        
        return can_connect, bottom_member['member_id'], top_member['member_id']
    
    # 1. ëª¨ë“  JSON íŒŒì¼ ìˆ˜ì§‘ ë° íŒŒì‹±
    json_files = [f for f in os.listdir(input_dir) if f.endswith('.json')]
    file_infos = []
    
    print(f"ë°œê²¬ëœ JSON íŒŒì¼: {len(json_files)}ê°œ")
    
    for json_file in json_files:
        parsed = parse_filename(json_file)
        if parsed:
            json_path = os.path.join(input_dir, json_file)
            member_positions, data_lines = get_member_positions(json_path, keywords)
            
            file_infos.append({
                **parsed,
                'json_path': json_path,
                'analysis': (member_positions, data_lines)
            })
            
            print(f"íŒŒì¼: {json_file}")
            print(f"  page_{parsed['page_num']}, table_{parsed['table_num']}")
            print(f"  ë¶€ì¬: {[m['member_id'] for m in member_positions]}")
        else:
            print(f"íŒŒì‹± ì‹¤íŒ¨: {json_file}")
    
    # 2. í˜ì´ì§€, í…Œì´ë¸” ë²ˆí˜¸ìˆœìœ¼ë¡œ ì •ë ¬
    file_infos.sort(key=lambda x: (x['page_num'], x['table_num']))
    
    # 3. ì—°ì†ì„± ì²´ì¸ êµ¬ì„±
    chains = []
    
    for i, current_file in enumerate(file_infos):
        # ìƒˆë¡œìš´ ì²´ì¸ ì‹œì‘
        if i == 0 or not chains:
            chains.append([current_file])
            continue
        
        # ì´ì „ íŒŒì¼ê³¼ ì—°ê²° ì‹œë„
        prev_file = chains[-1][-1]  # í˜„ì¬ ì²´ì¸ì˜ ë§ˆì§€ë§‰ íŒŒì¼
        
        can_connect = False
        connect_info = ""
        
        # ë™ì¼ í˜ì´ì§€ ë‚´ ì—°ì† í…Œì´ë¸”
        if (current_file['page_num'] == prev_file['page_num'] and 
            current_file['table_num'] == prev_file['table_num'] + 1):
            
            can_connect, source_member, target_member = check_connection(
                prev_file['analysis'], current_file['analysis'])
            connect_info = f"í˜ì´ì§€ë‚´ ì—°ê²°: {source_member} â†’ {target_member}"
        
        # í˜ì´ì§€ ê°„ ì—°ê²° (ë‹¤ìŒ í˜ì´ì§€ ì²« í…Œì´ë¸”)
        elif (current_file['page_num'] == prev_file['page_num'] + 1 and 
              current_file['table_num'] == 1):
            
            can_connect, source_member, target_member = check_connection(
                prev_file['analysis'], current_file['analysis'])
            connect_info = f"í˜ì´ì§€ê°„ ì—°ê²°: {source_member} â†’ {target_member}"
        
        if can_connect:
            chains[-1].append(current_file)
            print(f"ì—°ê²° ì„±ê³µ: {connect_info}")
        else:
            chains.append([current_file])
            print(f"ìƒˆ ì²´ì¸ ì‹œì‘: {current_file['filename']}")
    
    # 4. ê° ì²´ì¸ë³„ë¡œ ë³‘í•©ëœ JSON ìƒì„±
    file_count = 0
    
    for chain_idx, chain in enumerate(chains):
        if not chain:
            continue
        
        # ì²´ì¸ì˜ ëª¨ë“  ë¶€ì¬ ID ìˆ˜ì§‘
        all_members = set()
        for file_info in chain:
            members, _ = file_info['analysis']
            for member in members:
                all_members.add(member['member_id'])
        
        # ê° ë¶€ì¬ë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ ì €ì¥
        for member_id in all_members:
            all_lines = []
            first_metadata = {}
            member_files = []
            
            for file_info in chain:
                with open(file_info['json_path'], 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                root = next(iter(data.values()))[0]
                lines = root.get('text_lines', [])
                
                # í•´ë‹¹ ë¶€ì¬ê°€ ìˆëŠ” íŒŒì¼ë§Œ í¬í•¨
                members, _ = file_info['analysis']
                has_member = any(m['member_id'] == member_id for m in members)
                
                if has_member:
                    member_files.append(file_info)
                    
                    if not first_metadata:
                        first_metadata = {k: v for k, v in root.items() if k != 'text_lines'}
                    
                    # ì¶œì²˜ ì •ë³´ ì¶”ê°€
                    for line in lines:
                        line['source_file'] = file_info['filename']
                        line['source_page'] = file_info['page_num']
                        line['source_table'] = file_info['table_num']
                    
                    all_lines.extend(lines)
            
            if not member_files:
                continue
            
            # íŒŒì¼ëª… ìƒì„±
            first_file = member_files[0]
            last_file = member_files[-1]
            safe_member = re.sub(r'[^\w\-]', '_', member_id)
            
            if len(member_files) == 1:
                out_name = f"page_{first_file['page_num']}_table_{first_file['table_num']}_{safe_member}.json"
            else:
                out_name = (f"page_{first_file['page_num']}_table_{first_file['table_num']}_"
                           f"to_page_{last_file['page_num']}_table_{last_file['table_num']}_{safe_member}.json")
            
            # ë³‘í•©ëœ ë°ì´í„° êµ¬ì¡°
            merged_data = {
                f"merged_{safe_member}": [{
                    **first_metadata,
                    'text_lines': all_lines,
                    'member_id': member_id,
                    'chain_info': {
                        'start': f"page_{first_file['page_num']}_table_{first_file['table_num']}",
                        'end': f"page_{last_file['page_num']}_table_{last_file['table_num']}",
                        'source_files': [f['filename'] for f in member_files],
                        'total_lines': len(all_lines),
                        'merge_type': 'sequential_continuity'
                    }
                }]
            }
            
            # íŒŒì¼ ì €ì¥
            out_path = os.path.join(output_dir, out_name)
            with open(out_path, 'w', encoding='utf-8') as wf:
                json.dump(merged_data, wf, ensure_ascii=False, indent=2)
            
            file_count += 1
            print(f"ë³‘í•© ì™„ë£Œ: {out_name}")
            print(f"  ë¶€ì¬: {member_id}")
            print(f"  íŒŒì¼: {len(member_files)}ê°œ")
            print(f"  í…ìŠ¤íŠ¸ ë¼ì¸: {len(all_lines)}ê°œ")
            print("-" * 40)
    
    return file_count


def extract_floor_info(split_dir, csv_path):
    floor_pattern = re.compile(r"\b(?:\d+F|B\d+|PIT)\b", re.IGNORECASE)
    rows = []
    for fn in sorted(os.listdir(split_dir)):
        if not fn.lower().endswith('.json'):
            continue
        fp = os.path.join(split_dir, fn)
        with open(fp,'r',encoding='utf-8') as f:
            data = json.load(f)
        key = next(iter(data))
        for entry in data[key]:
            for line in entry.get('text_lines', []):
                text = line.get('text','')
                for m in floor_pattern.findall(text):
                    rows.append({'file':fn,'floor':m,'text':text})
    with open(csv_path,'w',newline='',encoding='utf-8') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=['file','floor','text'])
        writer.writeheader()
        writer.writerows(rows)
    return len(rows)

# â”€â”€â”€ 3) ì¤„ ë‹¨ìœ„ í…Œì´ë¸” ì¶”ì¶œ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def clean_math_tags(text):
    """ëª¨ë“  ìˆ˜í•™ í‘œê¸°ë²•ì„ ì •ë¦¬"""
    # LaTeX ëª…ë ¹ì–´ë“¤
    latex_patterns = [
        (r'\\mathbf\{([^}]+)\}', r'\1'),      # êµµì€ ê¸€ì”¨
        (r'\\mathrm\{([^}]+)\}', r'\1'),      # ë¡œë§Œì²´
        (r'\\mathit\{([^}]+)\}', r'\1'),      # ì´íƒ¤ë¦­
        (r'\\text\{([^}]+)\}', r'\1'),        # ì¼ë°˜ í…ìŠ¤íŠ¸
        (r'\\textbf\{([^}]+)\}', r'\1'),      # êµµì€ í…ìŠ¤íŠ¸
        (r'\\[a-zA-Z]+\{([^}]+)\}', r'\1'),   # ê¸°íƒ€ LaTeX ëª…ë ¹ì–´
    ]
    
    for pattern, replacement in latex_patterns:
        text = re.sub(pattern, replacement, text)
    
    # MathML íƒœê·¸
    text = re.sub(r'<math>(.*?)</math>', r'\1', text)
    text = re.sub(r'<[^>]+>', '', text)
    
    # ê³µë°± ì •ë¦¬
    text = re.sub(r'\s+', ' ', text)
    
    return text.strip()

def extract_table_rows(json_path, y_tol=20):
    """Extract rows from a single table JSON by clustering text_lines by y-center"""
    with open(json_path, encoding='utf-8') as f:
        data = json.load(f)
    lines = next(iter(data.values()))[0]['text_lines']
    
    # compute y-centers
    items = []
    for ln in lines:
        x1, y1, x2, y2 = ln['bbox']
        # MathML íƒœê·¸ ì •ë¦¬ ì¶”ê°€
        cleaned_text = clean_math_tags(ln['text'])
        height = y2 - y1  # í…ìŠ¤íŠ¸ ë†’ì´ ê³„ì‚°
        items.append({
            'y': (y1 + y2) / 2, 
            'x': x1, 
            'text': cleaned_text,
            'height': height
        })
    
    if not items:
        return []
    
    # sort by y
    items.sort(key=lambda i: i['y'])
    rows = []
    current = [items[0]]
    
    for it in items[1:]:
        avg_y = sum(i['y'] for i in current) / len(current)
        avg_height = sum(i['height'] for i in current) / len(current)
        
        # ì ì‘ì  í—ˆìš©ì˜¤ì°¨: í…ìŠ¤íŠ¸ ë†’ì´ì˜ 50%ì™€ ê¸°ë³¸ê°’ ì¤‘ í° ê°’ ì‚¬ìš©
        adaptive_tol = max(y_tol, avg_height * 0.5)
        
        if abs(it['y'] - avg_y) <= adaptive_tol:
            current.append(it)
        else:
            rows.append(current)
            current = [it]
    
    rows.append(current)
    
    # combine texts sorted by x
    combined = []
    for row in rows:
        row.sort(key=lambda i: i['x'])
        combined.append(' '.join(i['text'] for i in row))
    
    return combined


def smart_split(line: str) -> list:
    """
    Split a line by whitespace outside of parentheses,
    so tokens like 'Vu(kN,LCB, iWAL, Lw)' stay intact.
    """
    tokens = []
    buf = ''
    depth = 0
    for ch in line:
        if ch == '(':
            depth += 1
            buf += ch
        elif ch == ')':
            depth -= 1
            buf += ch
        elif ch.isspace() and depth == 0:
            if buf:
                tokens.append(buf)
                buf = ''
        else:
            buf += ch
    if buf:
        tokens.append(buf)
    return tokens

# ===================== ì£¼ìš” í•¨ìˆ˜ =====================


def clean_math_tags(text):
    """ëª¨ë“  ìˆ˜í•™ í‘œê¸°ë²•ì„ ì •ë¦¬"""
    # LaTeX ëª…ë ¹ì–´ë“¤
    latex_patterns = [
        (r'\\mathbf\{([^}]+)\}', r'\1'),      # êµµì€ ê¸€ì”¨
        (r'\\mathrm\{([^}]+)\}', r'\1'),      # ë¡œë§Œì²´
        (r'\\mathit\{([^}]+)\}', r'\1'),      # ì´íƒ¤ë¦­
        (r'\\text\{([^}]+)\}', r'\1'),        # ì¼ë°˜ í…ìŠ¤íŠ¸
        (r'\\textbf\{([^}]+)\}', r'\1'),      # êµµì€ í…ìŠ¤íŠ¸
        (r'\\[a-zA-Z]+\{([^}]+)\}', r'\1'),   # ê¸°íƒ€ LaTeX ëª…ë ¹ì–´
    ]
    
    for pattern, replacement in latex_patterns:
        text = re.sub(pattern, replacement, text)
    
    # MathML íƒœê·¸
    text = re.sub(r'<math>(.*?)</math>', r'\1', text)
    text = re.sub(r'<[^>]+>', '', text)
    
    # ê³µë°± ì •ë¦¬
    text = re.sub(r'\s+', ' ', text)
    
    return text.strip()


def smart_split(line: str) -> list:
    """
    ê´„í˜¸ ë°– ê³µë°±ë§Œ ë¶„ë¦¬í•˜ì—¬ ( ) ë‚´ë¶€ëŠ” í•˜ë‚˜ì˜ í† í°ìœ¼ë¡œ ìœ ì§€
    """
    tokens, buf, depth = [], '', 0
    for ch in line:
        if ch == '(':
            depth += 1
            buf += ch
        elif ch == ')':
            depth -= 1
            buf += ch
        elif ch.isspace() and depth == 0:
            if buf:
                tokens.append(buf)
                buf = ''
        else:
            buf += ch
    if buf:
        tokens.append(buf)
    return tokens

def create_table_rows_csv():
    """OCR ë¶„í•  ê²°ê³¼ì—ì„œ í…Œì´ë¸” í–‰ì„ ì¶”ì¶œí•˜ì—¬ table_rows.csv ìƒì„±"""
    split_dir = os.path.join(TABLE_DIR, "table_OCR_split")
    csv_path = os.path.join(TABLE_DIR, "table_rows.csv")
    
    all_rows = []
    
    for filename in os.listdir(split_dir):
        if filename.endswith('.json'):
            json_path = os.path.join(split_dir, filename)
            rows = extract_table_rows(json_path)
            
            # ë¶€ì¬ëª… ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ)
            member_match = re.search(r'_([^_]+)\.json$', filename)
            member_id = member_match.group(1) if member_match else 'unknown'
            
            for row_text in rows:
                all_rows.append({
                    'file': filename,
                    'member_id': member_id,  # ğŸ”¥ ë¶€ì¬ëª… ì»¬ëŸ¼ ì¶”ê°€
                    'text': row_text
                })
    
    # CSVë¡œ ì €ì¥
    df = pd.DataFrame(all_rows)
    df.to_csv(csv_path, index=False, encoding='utf-8-sig')  # ğŸ”¥ í•œê¸€ ì¸ì½”ë”© ìˆ˜ì •
    
    return len(all_rows)


def preview_member_data_for_header_selection(csv_path: str, keywords: list) -> dict:
    """
    ì²« ë²ˆì§¸ ë¶€ì¬ì˜ í…ìŠ¤íŠ¸ ë¼ì¸ë“¤ì„ ë³´ì—¬ì£¼ê³  ì‚¬ìš©ìê°€ í—¤ë” í–‰ì„ ì„ íƒí•  ìˆ˜ ìˆë„ë¡ í•¨
    """
    import pandas as pd
    import re
    
    df_raw = pd.read_csv(csv_path, encoding='utf-8-sig')
    
    # ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
    all_text_lines = []
    for _, row in df_raw.iterrows():
        cleaned_text = clean_math_tags(str(row['text']))
        all_text_lines.append(cleaned_text)
    
    # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¼ì¸ ì°¾ê¸°
    member_boundaries = []
    for i, line in enumerate(all_text_lines):
        for keyword in keywords:
            if keyword.lower() in line.lower() and '=' in line:
                parts = line.split('=', 1)
                if len(parts) > 1:
                    member_name = parts[1].strip().split()[0]
                    member_boundaries.append({
                        'line_index': i,
                        'member_name': member_name,
                        'keyword': keyword
                    })
                    break
    
    if not member_boundaries:
        return {}
    
    # ì²« ë²ˆì§¸ ë¶€ì¬ì˜ í…ìŠ¤íŠ¸ ë¼ì¸ë“¤ ì¶”ì¶œ
    first_boundary = member_boundaries[0]
    start_line = first_boundary['line_index']
    end_line = member_boundaries[1]['line_index'] if len(member_boundaries) > 1 else len(all_text_lines)
    
    member_lines = all_text_lines[start_line:end_line]
    
    return {
        'member_name': first_boundary['member_name'],
        'lines': member_lines,
        'total_members': len(member_boundaries)
    }

def process_csv_to_excel_with_custom_header(csv_path: str, excel_path: str, keywords: list, header_pattern: str) -> int:
    """
    CSVì—ì„œ ì‚¬ìš©ì ì§€ì • í‚¤ì›Œë“œì™€ ì»¤ìŠ¤í…€ í—¤ë” íŒ¨í„´ìœ¼ë¡œ ë¶€ì¬ë¥¼ êµ¬ë¶„í•˜ì—¬ Excel ì €ì¥
    """
    import pandas as pd
    import re
    
    # CSV ë¡œë“œ
    df_raw = pd.read_csv(csv_path, encoding='utf-8-sig')
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    if not all(col in df_raw.columns for col in ['file', 'member_id', 'text']):
        raise ValueError("CSVì— í•„ìˆ˜ ì»¬ëŸ¼(file, member_id, text)ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸° (ìˆœì„œ ìœ ì§€)
    all_text_lines = []
    for _, row in df_raw.iterrows():
        cleaned_text = clean_math_tags(str(row['text']))
        all_text_lines.append(cleaned_text)
    
    # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¼ì¸ ì°¾ê¸°
    member_boundaries = []
    
    print(f"ì „ì²´ ë¼ì¸ ìˆ˜: {len(all_text_lines)}")
    print(f"ì°¾ì„ í‚¤ì›Œë“œ: {keywords}")
    print(f"í—¤ë” íŒ¨í„´: {header_pattern}")
    
    for i, line in enumerate(all_text_lines):
        for keyword in keywords:
            if keyword.lower() in line.lower() and '=' in line:
                parts = line.split('=', 1)
                if len(parts) > 1:
                    member_name = parts[1].strip().split()[0]
                    member_boundaries.append({
                        'line_index': i,
                        'member_name': member_name,
                        'keyword': keyword,
                        'original_line': line
                    })
                    print(f"ì°¾ì€ íŒ¨í„´ - ë¼ì¸ {i}: {line.strip()}")
                    print(f"ì¶”ì¶œëœ ë¶€ì¬ëª…: {member_name}")
                    break
    
    if not member_boundaries:
        print("Warning: í‚¤ì›Œë“œ íŒ¨í„´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return 0
    
    # ì»¤ìŠ¤í…€ í—¤ë” íŒ¨í„´ìœ¼ë¡œ í—¤ë” ì°¾ê¸°
    header_words = header_pattern.split()[:2]
    header_pat = re.compile(r"\s+".join(re.escape(word) for word in header_words), re.IGNORECASE)
    
    eq_pat = re.compile(r"\*\.\s*(.*?)\s*=\s*(.*)")
    col_pat = re.compile(r"\*\.\s*(.*?)\s*:\s*(.*)")
    floor_pat = re.compile(r'^(?:\d+F|B\d+|PIT)', re.IGNORECASE)
    
    with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:
        sheet_count = 0
        
        for idx, boundary in enumerate(member_boundaries):
            start_line = boundary['line_index']
            end_line = member_boundaries[idx + 1]['line_index'] if idx + 1 < len(member_boundaries) else len(all_text_lines)
            member_name = boundary['member_name']
            
            member_lines = all_text_lines[start_line:end_line]
            
            print(f"ì²˜ë¦¬ ì¤‘: {member_name} (ë¼ì¸ {start_line}~{end_line-1}, ì´ {len(member_lines)}ì¤„)")
            
            # ì»¤ìŠ¤í…€ í—¤ë” íŒ¨í„´ìœ¼ë¡œ í—¤ë” ìœ„ì¹˜ ì°¾ê¸°
            header_idxs = [i for i, ln in enumerate(member_lines) if header_pat.search(ln)]
            
            if not header_idxs:
                print(f"Warning: {member_name}ì—ì„œ í—¤ë” íŒ¨í„´ '{header_pattern}'ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                continue
            
            # ê° í—¤ë”ì— ëŒ€í•´ í…Œì´ë¸” ì²˜ë¦¬
            for table_idx, h_idx in enumerate(header_idxs):
                # 1) í—¤ë” í† í°í™” - session_stateì— ì €ì¥ëœ ìµœì¢… í—¤ë” ì‚¬ìš©

                if 'final_headers' in st.session_state:
                    headers = st.session_state.final_headers
                    print(f"ì‚¬ìš©ì ì •ì˜ í—¤ë” ì‚¬ìš©: {headers}")
                else:
                    headers = smart_split(member_lines[h_idx].strip())
                    print(f"ìë™ ë¶„í•  í—¤ë” ì‚¬ìš©: {headers}")
                
                # 2) ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
                meta = {}
                for lookback in range(max(0, h_idx-5), h_idx):
                    line = member_lines[lookback].strip()
                    m = eq_pat.match(line) or col_pat.match(line)
                    if m:
                        key, val = m.group(1).strip(), m.group(2).strip()
                        if key not in headers:
                            meta[key] = val
                
                # 3) ë°ì´í„° ë¸”ë¡ ë²”ìœ„ ì„¤ì •
                next_h = header_idxs[table_idx + 1] if table_idx + 1 < len(header_idxs) else len(member_lines)
                data_rows = []
                
                # 4) ë°ì´í„° í–‰ ì²˜ë¦¬ - ê°œì„ ëœ ë¶„í•  ë¡œì§
                for ln in member_lines[h_idx + 1:next_h]:
                    txt = ln.strip()
                    if not txt or eq_pat.match(txt) or col_pat.match(txt) or header_pat.search(txt):
                        continue
                    
                    # ê°œì„ ëœ ìŠ¤ë§ˆíŠ¸ ë¶„í•  ì‚¬ìš©
                    parts = improved_data_split(txt, headers)
                    
                    # ì¸µìˆ˜ ì—†ëŠ” í–‰ ìŠ¤í‚µ
                    if not floor_pat.match(parts[0]):
                        continue
                        
                    data_rows.append(parts)
                
                # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
                if not data_rows:
                    continue
                
                # DataFrame ìƒì„± ë° ë©”íƒ€ë°ì´í„° ê²°í•©
                df = pd.DataFrame(data_rows, columns=headers)
                for k, v in meta.items():
                    df[k] = v
                
                # ì‹œíŠ¸ëª… ì„¤ì •
                if len(header_idxs) > 1:
                    sheet_name = f"{member_name}_T{table_idx+1}"
                else:
                    sheet_name = str(member_name)
                
                sheet_name = re.sub(r'[^\w\-]', '_', sheet_name)[:31]
                
                # Excel ì‹œíŠ¸ ì‘ì„±
                try:
                    df.to_excel(writer, sheet_name=sheet_name, index=False)
                    sheet_count += 1
                    print(f"ì‹œíŠ¸ ìƒì„± ì™„ë£Œ: {sheet_name} ({len(data_rows)}í–‰)")
                except Exception as e:
                    print(f"ì‹œíŠ¸ ìƒì„± ì‹¤íŒ¨: {sheet_name} - {e}")
                    continue
    
    return sheet_count


def improved_data_split(line: str, headers: list) -> list:
    """
    í—¤ë”ì— ë§ì¶° ë°ì´í„°ë¥¼ ìŠ¤ë§ˆíŠ¸í•˜ê²Œ ë¶„í• 
    ë¹ˆ ì»¬ëŸ¼ì´ ìˆì–´ë„ ì •í™•í•œ ìœ„ì¹˜ì— ë§¤ì¹­
    ê´„í˜¸ê°€ ìˆëŠ” í—¤ë”ë¼ë„ ê´„í˜¸ ì—†ëŠ” ë°ì´í„°ë¥¼ ì²˜ë¦¬
    """
    import re
    
    # ì  ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ í† í° ë¶„í• 
    raw_tokens = line.strip().split()
    smart_tokens = []
    
    for token in raw_tokens:
        if '.' in token and not token.endswith('.'):
            # ì ì´ ì¤‘ê°„ì— ìˆëŠ” í† í°ì„ ì ì—ì„œ ë¶„í• 
            parts = token.split('.')
            for i, part in enumerate(parts[:-1]):
                smart_tokens.append(part + '.')
            smart_tokens.append(parts[-1])
        else:
            smart_tokens.append(token)
    
    # ì  ë’¤ ê´„í˜¸ ì—°ê²° ì²˜ë¦¬
    final_tokens = []
    i = 0
    while i < len(smart_tokens):
        current = smart_tokens[i]
        
        # ì ìœ¼ë¡œ ëë‚˜ê³  ë‹¤ìŒ í† í°ì´ ê´„í˜¸ë¡œ ì‹œì‘í•˜ë©´ ì—°ê²°
        if (current.endswith('.') and 
            i + 1 < len(smart_tokens) and 
            smart_tokens[i + 1].startswith('(')):
            
            # ê´„í˜¸ê°€ ì™„ì „íˆ ë‹«í ë•Œê¹Œì§€ ì—°ê²°
            combined = current + ' ' + smart_tokens[i + 1]
            i += 2
            while i < len(smart_tokens) and combined.count('(') > combined.count(')'):
                combined += ' ' + smart_tokens[i]
                i += 1
            final_tokens.append(combined)
        else:
            final_tokens.append(current)
            i += 1
    
    parts = []
    tokens = final_tokens
    token_idx = 0
    
    for i, header in enumerate(headers):
        if token_idx >= len(tokens):
            parts.append("")
            continue
        
        if '(' in header and ')' in header:
            # ê´„í˜¸ê°€ ìˆëŠ” ì»¬ëŸ¼: ì´ë¯¸ í•©ì³ì§„ í† í°ì´ê±°ë‚˜ ì¼ë°˜ ê´„í˜¸ íŒ¨í„´ ì²˜ë¦¬
            current_token = tokens[token_idx]
            
            # ì´ë¯¸ ì +ê´„í˜¸ë¡œ í•©ì³ì§„ í† í°ì¸ì§€ í™•ì¸
            if '(' in current_token and ')' in current_token:
                parts.append(current_token)
                token_idx += 1
            else:
                # ê¸°ì¡´ ë¡œì§: ì—¬ëŸ¬ í† í°ì— ê±¸ì¹œ ê´„í˜¸ íŒ¨í„´ ì°¾ê¸°
                remaining_text = ' '.join(tokens[token_idx:])
                pattern = r'^(\S+\.?)\s*(\([^)]*\))'
                match = re.search(pattern, remaining_text)
                
                if match:
                    # ê´„í˜¸ íŒ¨í„´ì´ ìˆëŠ” ê²½ìš°
                    value = f"{match.group(1)} {match.group(2)}"
                    parts.append(value.strip())
                    
                    # ì‚¬ìš©ëœ í† í° ìˆ˜ ê³„ì‚°
                    used_tokens = len(match.group(0).split())
                    token_idx += used_tokens
                else:
                    # ê´„í˜¸ íŒ¨í„´ì´ ì—†ì–´ë„ ì²« ë²ˆì§¸ í† í°ì„ ê°€ì ¸ê° (ì˜ˆ: -23.)
                    parts.append(tokens[token_idx])
                    token_idx += 1
        else:
            # ê´„í˜¸ ì—†ëŠ” ì»¬ëŸ¼
            if token_idx < len(tokens):
                parts.append(tokens[token_idx])
                token_idx += 1
            else:
                parts.append("")
    
    # ë‚¨ì€ í† í°ë“¤ì„ ë§ˆì§€ë§‰ ì»¬ëŸ¼ì— í•©ì¹˜ê¸°
    if token_idx < len(tokens):
        remaining = ' '.join(tokens[token_idx:])
        if parts:
            parts[-1] += ' ' + remaining
    
    return parts




def export_summary_csv(excel_input: str, summary_csv: str) -> int:
    """
    Excel íŒŒì¼ì˜ ëª¨ë“  ì‹œíŠ¸ë¥¼ ì½ì–´ì„œ í•˜ë‚˜ì˜ CSVë¡œ í†µí•©
    ê° í–‰ì— ì‹œíŠ¸ëª…(ë¶€ì¬ëª…) ì»¬ëŸ¼ì„ ì¶”ê°€í•˜ì—¬ êµ¬ë¶„
    
    Args:
        excel_input: ì…ë ¥ Excel íŒŒì¼ ê²½ë¡œ
        summary_csv: ì¶œë ¥ CSV íŒŒì¼ ê²½ë¡œ
    
    Returns:
        í†µí•©ëœ ì´ í–‰ ìˆ˜
    """
    import pandas as pd
    
    try:
        # Excel íŒŒì¼ì˜ ëª¨ë“  ì‹œíŠ¸ ì½ê¸°
        xls = pd.ExcelFile(excel_input)
        all_dataframes = []
        
        for sheet_name in xls.sheet_names:
            # ê° ì‹œíŠ¸ ì½ê¸°
            df = pd.read_excel(xls, sheet_name=sheet_name)
            
            # ë¹ˆ DataFrame ê±´ë„ˆë›°ê¸°
            if df.empty:
                continue
            
            # ë¶€ì¬ëª… ì»¬ëŸ¼ ì¶”ê°€ (ë§¨ ì•ì—)
            df.insert(0, 'ë¶€ì¬ëª…', sheet_name)
            
            all_dataframes.append(df)
        
        if not all_dataframes:
            print("í†µí•©í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return 0
        
        # ëª¨ë“  DataFrame í†µí•©
        consolidated_df = pd.concat(all_dataframes, ignore_index=True)
        
        # CSVë¡œ ì €ì¥ (í•œê¸€ ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)
        consolidated_df.to_csv(summary_csv, index=False, encoding='utf-8-sig')
        
        total_rows = len(consolidated_df)
        print(f"í†µí•© ì™„ë£Œ: {len(all_dataframes)}ê°œ ì‹œíŠ¸, ì´ {total_rows}í–‰")
        print(f"ì €ì¥ ìœ„ì¹˜: {summary_csv}")
        
        return total_rows
        
    except Exception as e:
        print(f"í†µí•© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 0



































# ==========================




st.set_page_config(page_title="PDF to PNG Converter", layout="wide")
st.title("PDF to PNG Converter")
tab1, tab2, tab3 = st.tabs(["SCD Wall_info extraction", "SDD Wall_info extraction", "Human Error detection"])




with tab1:

    uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"])

    if uploaded_file:
        if st.button("ê³µí†µ - Step 0: PDF â†’ ì´ë¯¸ì§€ ë³€í™˜"):
            with st.spinner("ğŸ“„ PDF â†’ ì´ë¯¸ì§€ ë³€í™˜ ì¤‘..."):
                pdf_bytes = uploaded_file.read()
                images = convert_from_bytes(pdf_bytes, dpi=500)

                image_paths = []
                os.makedirs(WALL_IMAGE_DIR, exist_ok=True)
                for idx, image in enumerate(images):
                    img_path = os.path.join(WALL_IMAGE_DIR, f"page_{idx + 1}.png")
                    image.save(img_path, "PNG")
                    image_paths.append(img_path)

            st.success(f"âœ… ë³€í™˜ ì™„ë£Œ! ì´ {len(image_paths)} í˜ì´ì§€")


    conf_thresh = st.slider("ğŸ”§ CONF_THRESH (YOLO confidence threshold)", 0.1, 0.5, 0.3, 0.1)

    # Step 2: ë¬¸ì„œ ìœ í˜• ì˜ˆì¸¡
    if st.button("ê³µí†µ - Step 1: ë¬¸ì„œ ìœ í˜• ì˜ˆì¸¡ ë° ì €ì¥"):
        image_paths = sorted(glob.glob(os.path.join(WALL_IMAGE_DIR, "page_*.png")))
        if not image_paths:
            st.warning("âš ï¸ ë¨¼ì € PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner(f"ğŸ§  ë¬¸ì„œ ìœ í˜• ì˜ˆì¸¡ ì¤‘... (CONF_THRESH={conf_thresh})"):
                results = predict_document_type(image_paths, conf_thresh)
                save_images_by_prediction(results)

            sampled_results = random.sample(results, min(5, len(results)))
            st.success("âœ… ì˜ˆì¸¡ëœ ì´ë¯¸ì§€ë¥¼ ìœ í˜•ë³„ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            st.markdown("### ğŸ” ì˜ˆì¸¡ ê²°ê³¼ ì¹´ë“œ (ëœë¤ 5ì¥)")

            for result in sampled_results:
                with st.container():
                    col1, col2 = st.columns([1, 3])
                    with col1:
                        st.image(Image.open(result["image_path"]), width=200)
                    with col2:
                        st.markdown(f"#### ğŸ§¾ ì˜ˆì¸¡ëœ ë¬¸ì„œ ìœ í˜•: `{result['label']}`")
                        st.markdown(f"**íŒŒì¼ëª…:** `{os.path.basename(result['image_path'])}`")
                        st.markdown("---")


    with st.expander("MIDAS Step 1 : ì´ë¯¸ì§€ ë ˆì´ì•„ì›ƒ ì¶”ì¶œ"):
        if st.button("ğŸš€ ë¶„ì„ ë° í¬ë¡­ ì‹œì‘"):
            run_midas_analysis()


        
    with st.expander("MIDAS Step 2 : í¬ë¡­ëœ ì´ë¯¸ì§€ OCR(plain text)"):
        if st.button("Aplying OCR"):
            apply_surya_ocr_to_plain_text()
            apply_surya_ocr_to_figure()
    


    with st.expander("MIDAS Step 3 : OCR ë°”ìš´ë”©ë°•ìŠ¤ ê¸°ë°˜ ì •ë³´ ì¶”ì¶œ"):
        render_keyword_based_ocr_extraction()
    ###################################################################################################
    #BeST

    with st.expander("BeST Step 1: ë ˆì´ì•„ì›ƒ ë¶„ì„ & í¬ë¡­"):
        if st.button("ğŸš€ ë¶„ì„ ì‹œì‘ (BeST)"):
            apply_best_layout_analysis()

    with st.expander("BeST Step 2: OCR ì‹¤í–‰"):
        if st.button("ğŸš€ BeST OCR"):
            apply_surya_ocr_to_BeST()




    #######################################################################################################
    ######################################################################################################
    #Table í˜•ì‹£ã„±


    with st.expander("Table Step 1 : ë ˆì´ì•„ì›ƒ ë¶„ì„ ì‹¤í–‰"):
        if st.button("ğŸš€ TABLE ë ˆì´ì•„ì›ƒ ë¶„ì„ ì‹œì‘"):
            analyze_table_docs()
            st.success("âœ… TABLE ë¶„ì„ ë° ì‹œê°í™” ì™„ë£Œ!")


    with st.expander("Table Step 2 : OCR"):
        if st.button("ğŸš€ TABLE OCR ì‹œì‘"):
            apply_surya_ocr_table()
            st.success("âœ… DONE!")






# ê¸°ì¡´ Table Step 2 ë‹¤ìŒì— ì¶”ê°€
    with st.expander("Table Step 2.5 : OCR ê²°ê³¼ ì‚¬ì „ í•„í„°ë§"):
        st.write("ë¶„ì„í•  í‚¤ì›Œë“œê°€ í¬í•¨ëœ OCR íŒŒì¼ë“¤ë§Œ í•„í„°ë§í•˜ì—¬ ì²˜ë¦¬ ì‹œê°„ì„ ë‹¨ì¶•í•©ë‹ˆë‹¤.")
        st.write("í‚¤ì›Œë“œ ì…ë ¥ ì‹œ êµ¬ë¶„ì–´ë§Œ ì‘ì„±í•˜ì„¸ìš”. ì˜ˆ) MEMB, Wall Mark")
        
        # í‚¤ì›Œë“œ ì…ë ¥
        filter_kw1 = st.text_input("ì²« ë²ˆì§¸ í•„í„°ë§ í‚¤ì›Œë“œ", value="MEMB", key="filter_kw1")
        filter_kw2 = st.text_input("ë‘ ë²ˆì§¸ í•„í„°ë§ í‚¤ì›Œë“œ", value="Wall Mark", key="filter_kw2")
        
        # ì¶”ê°€ í‚¤ì›Œë“œë“¤ (ì„ íƒì‚¬í•­)
        additional_keywords = st.text_area(
            "ì¶”ê°€ í‚¤ì›Œë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„)", 
            placeholder="ì˜ˆ: keyword1, keyword2, keyword3",
            key="additional_filter_keywords"
        )
        
        # í´ë” ê²½ë¡œ ì„¤ì •
        filter_input_dir = st.text_input(
            "OCR JSON í´ë” ê²½ë¡œ", 
            value=os.path.join(TABLE_DIR, "table_OCR"),
            key="filter_input_dir"
        )
        filter_output_dir = st.text_input(
            "í•„í„°ë§ëœ íŒŒì¼ ì €ì¥ í´ë”", 
            value=os.path.join(TABLE_DIR, "table_OCR_filtered"),
            key="filter_output_dir"
        )
        
        if st.button("ğŸ” í‚¤ì›Œë“œ ê¸°ë°˜ í•„í„°ë§ ì‹¤í–‰"):
            # í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
            filter_keywords = []
            if filter_kw1.strip():
                filter_keywords.append(filter_kw1.strip())
            if filter_kw2.strip():
                filter_keywords.append(filter_kw2.strip())
            
            # ì¶”ê°€ í‚¤ì›Œë“œ ì²˜ë¦¬
            if additional_keywords.strip():
                additional_list = [kw.strip() for kw in additional_keywords.split(',') if kw.strip()]
                filter_keywords.extend(additional_list)
            
            if not filter_keywords:
                st.error("ìµœì†Œ í•˜ë‚˜ì˜ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner(f"í‚¤ì›Œë“œ '{', '.join(filter_keywords)}' ê¸°ë°˜ í•„í„°ë§ ì¤‘..."):
                    try:
                        filtered_count, total_count = filter_ocr_by_keywords(
                            keywords=filter_keywords,
                            input_dir=filter_input_dir,
                            output_dir=filter_output_dir
                        )
                        
                        st.success(f"""
                        âœ… í•„í„°ë§ ì™„ë£Œ!
                        - ì „ì²´ íŒŒì¼: {total_count}ê°œ
                        - í•„í„°ë§ëœ íŒŒì¼: {filtered_count}ê°œ
                        - ì œì™¸ëœ íŒŒì¼: {total_count - filtered_count}ê°œ
                        - ì €ì¥ ìœ„ì¹˜: {filter_output_dir}
                        """)
                        
                        if filtered_count == 0:
                            st.warning("âš ï¸ í‚¤ì›Œë“œê°€ í¬í•¨ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. í‚¤ì›Œë“œë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
                        
                    except Exception as e:
                        st.error(f"í•„í„°ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")








    with st.expander("Table Step 3 : OCR Splitting (í‚¤ì›Œë“œ ì €ì¥)"):
        st.write("í…Œì´ë¸” OCR JSONì„ ì‚¬ìš©ì í‚¤ì›Œë“œë¡œ ë¶„í•  ì €ì¥í•©ë‹ˆë‹¤.")
        st.write("í‚¤ì›Œë“œ ì…ë ¥ ì‹œ êµ¬ë¶„ì–´ë§Œ ì‘ì„±í•˜ì„¸ìš”. ì˜ˆ) MEMB, Wall Mark")
        
        kw1 = st.text_input("ì²« ë²ˆì§¸ í‚¤ì›Œë“œ", value="MEMB")
        kw2 = st.text_input("ë‘ ë²ˆì§¸ í‚¤ì›Œë“œ", value="Wall Mark")
        margin = st.number_input("ë¶„í•  ë§ˆì§„(px)", min_value=0, max_value=100, value=5, step=1)
        
        input_dir = os.path.join(TABLE_DIR, "table_OCR_filtered")
        output_dir = os.path.join(TABLE_DIR, "table_OCR_split")
        
        if st.button("ë¶„í•  ì‹¤í–‰ ë° í‚¤ì›Œë“œ ì €ì¥"):
            # í‚¤ì›Œë“œë¥¼ session_stateì— ì €ì¥
            keywords = [kw.strip() for kw in [kw1, kw2] if kw.strip()]
            st.session_state.split_keywords = keywords
            
            # ë¶„í•  ì‹¤í–‰
            n = process_table_ocr_splits(keywords, input_dir, output_dir, margin)
            st.success(f"âœ… {n}ê°œì˜ ë¶„í•  íŒŒì¼ ìƒì„± ì™„ë£Œ â†’ {output_dir}")
            st.success(f"í‚¤ì›Œë“œ ì €ì¥ ì™„ë£Œ: {keywords}")




    with st.expander("Table Step 4.5: í…Œì´ë¸” í–‰ CSV ìƒì„±"):
        if st.button("table_rows.csv ìƒì„±"):
            n = create_table_rows_csv()
            st.success(f"{n}ê°œ í–‰ì´ í¬í•¨ëœ table_rows.csv ìƒì„± ì™„ë£Œ")




    with st.expander("Table Step 5 : í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ì •ë³´ ì €ì¥ (í‚¤ì›Œë“œ ê¸°ë°˜)", expanded=True):
        # Step 3ì—ì„œ ì…ë ¥ë°›ì€ í‚¤ì›Œë“œ ì‚¬ìš© (session_state í™œìš©)
        if 'split_keywords' not in st.session_state:
            st.session_state.split_keywords = ['MEMB', 'Wall Mark']
        
        st.write("Step 3ì—ì„œ ì„¤ì •í•œ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶€ì¬ë³„ ì‹œíŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        st.write(f"í˜„ì¬ í‚¤ì›Œë“œ: {st.session_state.split_keywords}")
        
        # í‚¤ì›Œë“œ ìˆ˜ì • ì˜µì…˜
        if st.checkbox("í‚¤ì›Œë“œ ìˆ˜ì •í•˜ê¸°"):
            kw1 = st.text_input("ì²« ë²ˆì§¸ í‚¤ì›Œë“œ", value=st.session_state.split_keywords[0])
            kw2 = st.text_input("ë‘ ë²ˆì§¸ í‚¤ì›Œë“œ", value=st.session_state.split_keywords[1] if len(st.session_state.split_keywords) > 1 else "")
            additional_keywords = st.text_area("ì¶”ê°€ í‚¤ì›Œë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„)", placeholder="keyword3, keyword4")
            
            if st.button("í‚¤ì›Œë“œ ì—…ë°ì´íŠ¸"):
                keywords = [kw.strip() for kw in [kw1, kw2] if kw.strip()]
                if additional_keywords.strip():
                    keywords.extend([kw.strip() for kw in additional_keywords.split(',') if kw.strip()])
                st.session_state.split_keywords = keywords
                st.success(f"í‚¤ì›Œë“œ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {keywords}")
        
        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        csv_path = st.text_input("CSV File Path", value=os.path.join(TABLE_DIR, "table_rows.csv"))
        excel_path = st.text_input("Output Excel Path", value=os.path.join(TABLE_DIR, "output.xlsx"))
        
        # ë¯¸ë¦¬ë³´ê¸° ë°ì´í„° ìƒíƒœ ì´ˆê¸°í™”
        if 'preview_data' not in st.session_state:
            st.session_state.preview_data = None
        
        # ë¶€ì¬ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ë° í—¤ë” ì„ íƒ
        if st.button("ë¶€ì¬ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ë° í—¤ë” ì„ íƒ"):
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(csv_path):
                st.error(f"CSV íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {csv_path}")
                st.info("ë¨¼ì € Table Step 4.5ì—ì„œ table_rows.csvë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
            else:
                try:
                    st.session_state.preview_data = preview_member_data_for_header_selection(csv_path, st.session_state.split_keywords)
                except Exception as e:
                    st.error(f"ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ì˜¤ë¥˜: {e}")
        
        # ë¯¸ë¦¬ë³´ê¸° ë°ì´í„°ê°€ ìˆìœ¼ë©´ í‘œì‹œ
        if st.session_state.preview_data:
            preview_data = st.session_state.preview_data
            st.subheader(f"ë¶€ì¬ '{preview_data['member_name']}' ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
            st.info(f"ì´ {preview_data['total_members']}ê°œ ë¶€ì¬ ë°œê²¬")
            
            # ë¼ì¸ë“¤ì„ í‘œì‹œí•˜ê³  ì„ íƒí•  ìˆ˜ ìˆê²Œ í•¨
            st.write("ì•„ë˜ì—ì„œ í…Œì´ë¸” í—¤ë”ê°€ ë  í–‰ì„ ì„ íƒí•˜ì„¸ìš”:")
            
            header_options = []
            for i, line in enumerate(preview_data['lines'][:15]):  # ì²˜ìŒ 15ì¤„ë§Œ í‘œì‹œ
                if line.strip():  # ë¹ˆ ì¤„ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                    header_options.append(f"ë¼ì¸ {i}: {line[:100]}...")  # ì²˜ìŒ 100ìë§Œ
            
            if header_options:
                selected_header_idx = st.selectbox(
                    "í—¤ë” í–‰ ì„ íƒ:",
                    range(len(header_options)),
                    format_func=lambda x: header_options[x],
                    key="header_selector"
                )
                
                # ì„ íƒëœ í—¤ë” ë¼ì¸ ë¶„ì„
                selected_line = preview_data['lines'][selected_header_idx]
                st.write("ì„ íƒëœ í—¤ë”:")
                st.code(selected_line)
                
                # í—¤ë” ë¶„ë¦¬í•´ì„œ ë³´ì—¬ì£¼ê¸°
                initial_headers = smart_split(selected_line.strip())
                st.write("ìë™ ë¶„ë¦¬ëœ ì»¬ëŸ¼ë“¤:")
                
                # í¸ì§‘ ê°€ëŠ¥í•œ í—¤ë” ì…ë ¥ í•„ë“œë“¤
                st.write("ì»¬ëŸ¼ í¸ì§‘ (ë³‘í•©í•˜ë ¤ë©´ í•´ë‹¹ ì»¬ëŸ¼ì„ ë¹ˆ ì¹¸ìœ¼ë¡œ ë‘ê³  ì´ì „ ì»¬ëŸ¼ì— í•©ì³ì„œ ì…ë ¥):")
                
                if 'edited_headers' not in st.session_state:
                    st.session_state.edited_headers = initial_headers.copy()
                
                # í—¤ë”ê°€ ë°”ë€Œë©´ í¸ì§‘ëœ í—¤ë”ë„ ì´ˆê¸°í™”
                if len(st.session_state.edited_headers) != len(initial_headers):
                    st.session_state.edited_headers = initial_headers.copy()
                
                edited_headers = []
                cols = st.columns(3)  # 3ì—´ë¡œ ë°°ì¹˜
                for i, header in enumerate(st.session_state.edited_headers):
                    with cols[i % 3]:
                        edited_header = st.text_input(
                            f"ì»¬ëŸ¼ {i+1}", 
                            value=header, 
                            key=f"header_edit_{i}",
                            help="ë¹ˆ ì¹¸ìœ¼ë¡œ ë‘ë©´ ì´ì „ ì»¬ëŸ¼ê³¼ ë³‘í•©ë©ë‹ˆë‹¤"
                        )
                        edited_headers.append(edited_header)
                
                # ë¹ˆ ì¹¸ ì œê±° ë° ë³‘í•© ì²˜ë¦¬
                final_headers = []
                temp_header = ""
                for header in edited_headers:
                    if header.strip():  # ë¹ˆ ì¹¸ì´ ì•„ë‹ˆë©´
                        if temp_header:  # ì´ì „ì— ëˆ„ì ëœ ê²ƒì´ ìˆìœ¼ë©´
                            temp_header += " " + header.strip()
                        else:
                            temp_header = header.strip()
                        final_headers.append(temp_header)
                        temp_header = ""
                    else:  # ë¹ˆ ì¹¸ì´ë©´ ì´ì „ í—¤ë”ì— ëˆ„ì 
                        if final_headers:  # ì´ì „ í—¤ë”ê°€ ìˆìœ¼ë©´
                            continue  # ë‹¤ìŒ ë°˜ë³µì—ì„œ ë³‘í•©
                
                st.write("ìµœì¢… í—¤ë”:")
                for i, header in enumerate(final_headers):
                    st.write(f"{i+1}. `{header}`")
                
                st.write(f"ì´ {len(final_headers)}ê°œ ì»¬ëŸ¼")
                
                # í—¤ë” ì¬ì„¤ì • ë²„íŠ¼
                if st.button("ì›ë˜ëŒ€ë¡œ ë˜ëŒë¦¬ê¸°"):
                    st.session_state.edited_headers = initial_headers.copy()
                    st.experimental_rerun()
                
                # session_stateì— í—¤ë” íŒ¨í„´ ì €ì¥
                if st.button("ì´ í—¤ë”ë¡œ ì„¤ì •"):
                    if len(final_headers) >= 2:
                        first_words = final_headers[:2]
                        header_pattern = " ".join(first_words)
                        st.session_state.custom_header_pattern = header_pattern
                        st.session_state.final_headers = final_headers  # ìµœì¢… í—¤ë”ë„ ì €ì¥
                        st.success(f"í—¤ë” íŒ¨í„´ ì„¤ì • ì™„ë£Œ: '{header_pattern}'")
                        st.success(f"ì´ {len(final_headers)}ê°œ ì»¬ëŸ¼ìœ¼ë¡œ ì„¤ì •ë¨")
                    else:
                        st.error("ìµœì†Œ 2ê°œ ì´ìƒì˜ ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            else:
                st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        st.markdown("---")
        
        # ì„¤ì •ëœ í—¤ë” íŒ¨í„´ í‘œì‹œ
        if 'custom_header_pattern' in st.session_state:
            st.write(f"ì„¤ì •ëœ í—¤ë” íŒ¨í„´: `{st.session_state.custom_header_pattern}`")
            if 'final_headers' in st.session_state:
                st.write("ì„¤ì •ëœ ì»¬ëŸ¼ë“¤:")
                header_display = " | ".join(st.session_state.final_headers)
                st.code(header_display)
        
        # Excel ìƒì„± ë²„íŠ¼
        if st.button("í‚¤ì›Œë“œ ê¸°ë°˜ Excel ìƒì„±"):
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(csv_path):
                st.error(f"CSV íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {csv_path}")
                st.info("ë¨¼ì € Table Step 4.5ì—ì„œ table_rows.csvë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
            elif 'custom_header_pattern' not in st.session_state:
                st.error("ë¨¼ì € í—¤ë”ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            else:
                try:
                    n = process_csv_to_excel_with_custom_header(
                        csv_path=csv_path, 
                        excel_path=excel_path, 
                        keywords=st.session_state.split_keywords,
                        header_pattern=st.session_state.custom_header_pattern
                    )
                    st.success(f"{n} sheets exported to {excel_path}")
                except Exception as e:
                    st.error(f"Error: {e}")




    with st.expander("Table Step 6 : ìµœì¢… ì •ë¦¬ íŒŒì¼ ì €ì¥"):
        excel_input = st.text_input("Input Excel File Path", value=os.path.join(TABLE_DIR, "output.xlsx"))
        summary_csv = st.text_input("Summary CSV Path", value=os.path.join(TABLE_DIR,"summary.csv"))
        if st.button("Export Summary CSV"):
            try:
                m = export_summary_csv(excel_input, summary_csv)
                st.success(f"Summary CSV with {m} rows saved to {summary_csv}")
            except Exception as e:
                st.error(f"Error: {e}")















with tab2: 
    with st.expander("Step 0: PDFâ†’ì´ë¯¸ì§€", expanded=True):
        uploaded = st.file_uploader("PDF ì—…ë¡œë“œ", type=["pdf"])
        if uploaded:
            if st.button("ë³€í™˜ ì‹¤í–‰"):
                try:
                    pdf_bytes = uploaded.read()
                    paths = convert_pdf_to_png(pdf_bytes)
                    st.success(f"{len(paths)}í˜ì´ì§€ ë³€í™˜ ì™„ë£Œ: '{Wall_rawdata_SD}' í™•ì¸í•˜ì„¸ìš”")
                except Exception as e:
                    st.error(f"ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        else:
            st.info("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")


    with st.expander("ë°”ìš´ë”©ë°•ìŠ¤"):
        # "ë°”ìš´ë”©ë°•ìŠ¤ ì‹œì‘" ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ UIê°€ ë‚˜íƒ€ë‚˜ê²Œ
        if "show_box_ui" not in st.session_state:
            st.session_state.show_box_ui = False

        if st.button("ë°”ìš´ë”©ë°•ìŠ¤ ì‹œì‘"):
            st.session_state.show_box_ui = True

        if st.session_state.show_box_ui:
            draw_and_save_bounding_boxes()
            # "ì™„ë£Œí•˜ê¸°" ë²„íŠ¼ì„ ë„£ì–´ì„œ ëˆ„ë¥´ë©´ UI ë‹«í˜
            if st.button("ì™„ë£Œí•˜ê¸°"):
                st.session_state.show_box_ui = False




    with st.expander("í…Œì´ë¸” ì…€ ìë™ í¬ë¡­ íë¦„"):
        # ë‹¨ê³„ 1: OCR
        if st.button("1. ì „ì²´ OCR ì‹¤í–‰"):
            apply_surya_ocr_Wall_SD()


    with st.expander("OCR ë™ì¼ì„ ìƒ ë³´ê¸°"):
        if st.button("ì „ì²´ ì²˜ë¦¬ ë° ì˜ˆì‹œ ë³´ê¸°"):
            img, path = process_all_and_show_one()
            if img is not None:
                st.image(img, caption=path, use_column_width=True)
            else:
                st.warning("ì´ë¯¸ì§€/ë°•ìŠ¤/OCR ì…‹ ë‹¤ ì¡´ì¬í•˜ëŠ” íŒŒì¼ì´ í´ë”ì— ì—†ìŒ")

    with st.expander("ë™ì¼ ì„ ìƒ ì¸ì‹ ë° êµì°¨ì  ì¸ì‹"):
        if st.button("í…ìŠ¤íŠ¸ ì¸ì‹ ë° êµì°¨ì  ì¸ì‹"):
            visualize_lines_batch()




    with st.expander("ğŸ”½ ë°°ì¹˜ ì²˜ë¦¬ ë° ì—‘ì…€ ì €ì¥"):
        st.write("ì´ë¯¸ì§€ í´ë”ì—ì„œ í…Œì´ë¸”ì„ ê²€ì¶œí•˜ê³  ê° ë¶€ì¬ëª…ë³„ ì‹œíŠ¸ë¡œ output.xlsx ë¥¼ ìƒì„±í•©ë‹ˆë‹¤")
        # â‘¡ ë²„íŠ¼ ìƒì„±
        if st.button("â–¶ï¸ ì‹¤í–‰"):
            with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                process_batch()
            st.success("ì™„ë£Œ! output.xlsx íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”")



    with st.expander("í¬ë¡­ëœ ì´ë¯¸ì§€ OCR"):
        # ë‹¨ê³„ 1: OCR
        if st.button("OCR ì‘ë™"):
            apply_surya_ocr_Wall_Crop_SD()


    # with st.expander("ìˆ˜í‰/ìˆ˜ì§ì„  + êµì°¨ì  ì¸ì‹", expanded=True):
    #     img_dir = st.text_input("ì…ë ¥ ì´ë¯¸ì§€ í´ë” ê²½ë¡œ", value=r"D:\wall_drawing\Wall_table_region")
    #     save_dir = st.text_input("ê²°ê³¼ ì €ì¥ í´ë”ëª… (ë¹„ìš°ë©´ ì €ì¥ X)", value="Wall_table_region/lines_detected")
    #     mode = st.radio("ì„  ê²€ì¶œ ë°©ì‹", options=["contour", "hough"], index=0)
    #     min_line_length = st.slider("min_line_length", 20, 300, 80, 5)
    #     max_line_gap = st.slider("max_line_gap", 2, 40, 10, 2)
    #     hough_threshold = st.slider("Hough threshold", 30, 300, 100, 5)
    #     morph_kernel_scale = st.slider("Morph kernel ë¹„ìœ¨", 10, 60, 30, 2)
    #     resize_scale = st.slider("ì´ë¯¸ì§€ ì¶•ì†Œ ë¹„ìœ¨ (1=ì›ë³¸)", 0.3, 1.0, 0.7, 0.05)
    #     block_size = st.slider("adaptiveThreshold blockSize(í™€ìˆ˜)", 7, 31, 15, 2)
    #     C = st.slider("adaptiveThreshold C", -10, 10, -2, 1)

    #     run_btn = st.button("ì˜ˆì‹œ 5ê°œ ë³´ê¸°")
    #     save_btn = st.button("ì „ì²´ ì €ì¥")

    #     if run_btn:
    #         imgs = detect_and_draw_lines_batch(
    #             img_dir=img_dir,
    #             save_dir=None,
    #             min_line_length=min_line_length,
    #             max_line_gap=max_line_gap,
    #             hough_threshold=hough_threshold,
    #             morph_kernel_scale=morph_kernel_scale,
    #             resize_scale=resize_scale,
    #             max_examples=5,
    #             return_imgs=True,
    #             mode=mode,
    #             block_size=block_size | 1,
    #             C=C
    #         )
    #         if not imgs:
    #             st.warning("ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
    #         else:
    #             for fname, img, inter_cnt in imgs:
    #                 st.subheader(f"{fname} (êµì°¨ì : {inter_cnt}ê°œ)")
    #                 st.image(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), caption="ê²€ì¶œ ê²°ê³¼", use_column_width=True)
    #     if save_btn:
    #         detect_and_draw_lines_batch(
    #             img_dir=img_dir,
    #             save_dir=save_dir if save_dir else None,
    #             min_line_length=min_line_length,
    #             max_line_gap=max_line_gap,
    #             hough_threshold=hough_threshold,
    #             morph_kernel_scale=morph_kernel_scale,
    #             resize_scale=resize_scale,
    #             max_examples=None,
    #             return_imgs=False,
    #             mode=mode,
    #             block_size=block_size | 1,
    #             C=C
    #         )
    #         st.success(f"ì „ì²´ ì´ë¯¸ì§€ ê²°ê³¼ ì €ì¥ ì™„ë£Œ! â†’ '{save_dir}' í´ë” í™•ì¸")


    # with st.expander("OCR â†’ ì—‘ì…€ ì¼ê´„ ë³€í™˜"):
    #     if st.button("ì¼ê´„ ë³€í™˜ ì‹¤í–‰"):
    #         batch_ocr_json_to_excel()
    #         st.success("í´ë” ë‚´ ëª¨ë“  OCR json â†’ ì—‘ì…€ ë³€í™˜ ì™„ë£Œ!")


    with st.expander("ìˆ˜í‰/ìˆ˜ì§ì„  + êµì°¨ì  ì¸ì‹", expanded=True):
        img_dir = st.text_input("ì…ë ¥ ì´ë¯¸ì§€ í´ë” ê²½ë¡œ", value=os.path.join(Wall_table_region))
        save_dir = st.text_input("ê²°ê³¼ ì €ì¥ í´ë”ëª… (ë¹„ìš°ë©´ ì €ì¥ X)", value=os.path.join(Wall_table_region,"lines_detected"))
        mode = st.radio("ì„  ê²€ì¶œ ë°©ì‹", options=["contour", "hough"], index=0)
        min_line_length = st.slider("min_line_length", 20, 300, 80, 5)
        max_line_gap = st.slider("max_line_gap", 2, 40, 10, 2)
        hough_threshold = st.slider("Hough threshold", 30, 300, 100, 5)
        morph_kernel_scale = st.slider("Morph kernel ë¹„ìœ¨", 10, 60, 30, 2)
        resize_scale = st.slider("ì´ë¯¸ì§€ ì¶•ì†Œ ë¹„ìœ¨ (1=ì›ë³¸)", 0.3, 1.0, 0.7, 0.05)
        block_size = st.slider("adaptiveThreshold blockSize(í™€ìˆ˜)", 7, 31, 15, 2)
        C = st.slider("adaptiveThreshold C", -10, 10, -2, 1)
        tol = st.slider("êµì°¨ì  í—ˆìš© ì˜¤ì°¨ (tol)", 0, 10, 2, 1)

        run_btn = st.button("ì˜ˆì‹œ 5ê°œ ë³´ê¸°")
        save_btn = st.button("ì „ì²´ ì €ì¥")

        if run_btn:
            imgs = detect_and_draw_lines_batch(
                img_dir=img_dir,
                save_dir=None,
                min_line_length=min_line_length,
                max_line_gap=max_line_gap,
                hough_threshold=hough_threshold,
                morph_kernel_scale=morph_kernel_scale,
                resize_scale=resize_scale,
                max_examples=5,
                return_imgs=True,
                mode=mode,
                block_size=block_size | 1,
                C=C,
                tol=tol
            )
            if not imgs:
                st.warning("ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
            else:
                for fname, img, inter_cnt in imgs:
                    st.subheader(f"{fname} (êµì°¨ì : {inter_cnt}ê°œ)")
                    st.image(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), caption="ê²€ì¶œ ê²°ê³¼", use_column_width=True)

        if save_btn:
            detect_and_draw_lines_batch(
                img_dir=img_dir,
                save_dir=save_dir if save_dir else None,
                min_line_length=min_line_length,
                max_line_gap=max_line_gap,
                hough_threshold=hough_threshold,
                morph_kernel_scale=morph_kernel_scale,
                resize_scale=resize_scale,
                max_examples=None,
                return_imgs=False,
                mode=mode,
                block_size=block_size | 1,
                C=C,
                tol=tol
            )
            st.success(f"ì „ì²´ ì´ë¯¸ì§€ ê²°ê³¼ ì €ì¥ ì™„ë£Œ! â†’ '{save_dir}' í´ë” í™•ì¸")

    # ---------- (3) í‘œ ì¶”ì¶œ ì—‘ì…€í™” expander ì¶”ê°€ ----------

    # with st.expander("2) OCR+êµì°¨ì  ê¸°ë°˜ í‘œ ì—‘ì…€ ì¶”ì¶œ", expanded=True):
    #     ocr_dir = st.text_input("OCR json í´ë”", value=r"D:\wall_drawing\Wall_cell_crop_ocr")
    #     line_dir = st.text_input("ë¼ì¸ pkl í´ë”", value=r"D:\wall_drawing\Wall_table_region\lines_detected")
    #     out_dir  = st.text_input("ì—‘ì…€ ì €ì¥ í´ë”", value=r"D:\wall_drawing\Wall_table_region\Excel_Results")
    #     if st.button("í‘œ ì¶”ì¶œ ì‹¤í–‰"):
    #         batch_extract_dynamic(ocr_dir, line_dir, out_dir)
    #         st.success(f"í‘œ ì¶”ì¶œ ì™„ë£Œ â†’ {out_dir}")

    with st.expander("3) í†µí•© ì—‘ì…€ íŒŒì¼ ìƒì„±", expanded=True):
        img_dir_cons = st.text_input("ì…ë ¥ ì´ë¯¸ì§€ í´ë”", value= Wall_table_region)
        save_line_dir_cons = st.text_input("ë¼ì¸ pkl í´ë”", value=os.path.join(Wall_table_region, "lines_detected"))
        ocr_dir_cons = st.text_input("OCR json í´ë”", value=Wall_cell_crop_ocr)
        consolidated_path = st.text_input("í†µí•© ì—‘ì…€ íŒŒì¼ ê²½ë¡œ", value=os.path.join(Wall_table_region, "All_In_One.xlsx"))
        if st.button("í†µí•© ì—‘ì…€ ì¶”ì¶œ"):
            batch_extract_consolidated(
                img_dir=img_dir_cons,
                save_line_dir=save_line_dir_cons,
                ocr_dir=ocr_dir_cons,
                consolidated_path=consolidated_path,
                mode=mode,
                min_line_length=min_line_length,
                max_line_gap=max_line_gap,
                hough_threshold=hough_threshold,
                morph_kernel_scale=morph_kernel_scale,
                resize_scale=resize_scale,
                block_size=block_size|1,
                C=C
            )
            st.success(f"í†µí•© ì—‘ì…€ íŒŒì¼ ìƒì„± ì™„ë£Œ â†’ {consolidated_path}")

